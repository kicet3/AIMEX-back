"""
νμΈνλ‹ μ„λΉ„μ¤
S3μ—μ„ QA λ°μ΄ν„°λ¥Ό κ°€μ Έμ™€ EXAONE λ¨λΈ νμΈνλ‹ μν–‰
"""

import os
import json
import logging
import tempfile
import shutil
from typing import Optional, Dict, List
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

from app.services.s3_service import get_s3_service
from app.services.vllm_client import get_vllm_client, vllm_health_check
from app.core.encryption import decrypt_sensitive_data
from app.services.hf_token_resolver import get_token_for_influencer
from app.core.config import settings
from app.models.influencer import AIInfluencer
from app.utils.finetuning_utils import (
    create_system_message,
    convert_qa_data_for_finetuning,
    validate_qa_data,
    format_model_name_for_korean,
)
from app.utils.timezone_utils import get_current_kst

logger = logging.getLogger(__name__)


# vLLM μ„λ²„μ FineTuningStatus import
try:
    import sys
    import os

    # vLLM κ²½λ΅ μ¶”κ°€
    vllm_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "..", "vllm"
    )
    sys.path.insert(0, vllm_path)

    from app.models import FineTuningStatus

    logger.info("β… vLLM FineTuningStatus import μ„±κ³µ")

except ImportError as e:
    logger.warning(f"β οΈ vLLM FineTuningStatus import μ‹¤ν¨, λ΅μ»¬ λ²„μ „ μ‚¬μ©: {e}")

    # ν΄λ°±: λ΅μ»¬ λ²„μ „
    class FineTuningStatus(Enum):
        PENDING = "pending"
        PREPARING_DATA = "preparing_data"
        TRAINING = "training"
        UPLOADING = "uploading"
        COMPLETED = "completed"
        FAILED = "failed"


@dataclass
class FineTuningTask:
    task_id: str
    influencer_id: str
    qa_task_id: str
    status: FineTuningStatus
    s3_qa_url: str
    model_name: Optional[str] = None
    hf_repo_id: Optional[str] = None
    hf_model_url: Optional[str] = None
    error_message: Optional[str] = None
    training_epochs: int = 5
    qa_batch_task_id: Optional[str] = None
    system_prompt: Optional[str] = None
    created_at: datetime = None
    updated_at: datetime = None

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.updated_at is None:
            self.updated_at = get_current_kst()


class InfluencerFineTuningService:
    def __init__(self):
        """νμΈνλ‹ μ„λΉ„μ¤ μ΄κΈ°ν™”"""
        self.s3_service = get_s3_service()
        self.tasks: Dict[str, FineTuningTask] = {}

        # κΈ°λ³Έ λ¨λΈ μ„¤μ •
        self.base_model = os.getenv(
            "FINETUNING_BASE_MODEL", "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct"
        )

    def _convert_korean_to_english(self, korean_name: str) -> str:
        """ν•κΈ€ μ΄λ¦„μ„ μλ¬ΈμΌλ΅ λ³€ν™ (κ³µν†µ μ ν‹Έλ¦¬ν‹° μ‚¬μ©)"""
        return format_model_name_for_korean(korean_name)

    async def _get_hf_info_from_influencer(self, influencer_data, db) -> tuple[str, str]:
        """
        μΈν”λ£¨μ–Έμ„μ κ·Έλ£Ή IDλ¥Ό ν†µν•΄ ν—κΉ…νμ΄μ¤ ν† ν°κ³Ό μ‚¬μ©μλ… μ •λ³΄ κ°€μ Έμ¤κΈ°
        Args:
            influencer_data: μΈν”λ£¨μ–Έμ„ λ°μ΄ν„°
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
        Returns:
            (hf_token, hf_username) νν”
        """
        logger.debug(
            f"_get_hf_info_from_influencer νΈμ¶λ¨. influencer_data νƒ€μ…: {type(influencer_data)}"
        )

        try:
            # μ¤‘μ•™ν™”λ ν† ν° λ¦¬μ΅Έλ²„ μ‚¬μ©
            hf_token, hf_username = await get_token_for_influencer(influencer_data, db)
            
            if hf_token and hf_username:
                logger.info(
                    f"β… ν† ν° μ΅°ν μ„±κ³µ: {influencer_data.influencer_name if hasattr(influencer_data, 'influencer_name') else 'Unknown'}"
                )
                return hf_token, hf_username
            else:
                # ν† ν°μ΄ μ—†λ” κ²½μ°
                group_id = getattr(influencer_data, 'group_id', 'Unknown')
                logger.warning(
                    f"κ·Έλ£Ή {group_id}μ— λ“±λ΅λ ν—κΉ…νμ΄μ¤ ν† ν°μ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
                )
                raise Exception(
                    f"κ·Έλ£Ή {group_id}μ— λ“±λ΅λ ν—κΉ…νμ΄μ¤ ν† ν°μ΄ μ—†μµλ‹λ‹¤. κ΄€λ¦¬μμ—κ² λ¬Έμν•μ—¬ ν† ν°μ„ λ“±λ΅ν•΄μ£Όμ„Έμ”."
                )

        except Exception as e:
            logger.error(f"ν—κΉ…νμ΄μ¤ μ •λ³΄ κ°€μ Έμ¤κΈ° μ‹¤ν¨: {e}", exc_info=True)
            raise

    def download_qa_data_from_s3(self, s3_url: str) -> Optional[List[Dict]]:
        """
        S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“
        Args:
            s3_url: S3 QA λ°μ΄ν„° URL
        Returns:
            QA λ°μ΄ν„° λ¦¬μ¤νΈ
        """
        try:
            logger.info(f"S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“ μ‹μ‘: {s3_url}")

            # S3 URLμ—μ„ ν‚¤ μ¶”μ¶
            if "amazonaws.com/" in s3_url:
                s3_key = s3_url.split("amazonaws.com/")[-1]
                logger.info(f"S3 ν‚¤: {s3_key}")
            else:
                logger.error(f"μλ»λ S3 URL ν•μ‹: {s3_url}")
                return None

            # S3μ—μ„ νμΌ λ‚΄μ© κ°€μ Έμ¤κΈ°
            if not self.s3_service.is_available():
                logger.error("S3 μ„λΉ„μ¤λ¥Ό μ‚¬μ©ν•  μ μ—†μµλ‹λ‹¤")
                return None

            response = self.s3_service.s3_client.get_object(
                Bucket=self.s3_service.bucket_name, Key=s3_key
            )

            content = response["Body"].read().decode("utf-8")
            qa_pairs = []

            # λ¨Όμ € μ „μ²΄ λ‚΄μ©μ„ ν•λ‚μ JSONμΌλ΅ νμ‹± μ‹λ„ (μ²λ¦¬λ QA ν•μ‹)
            try:
                data = json.loads(content)
                if isinstance(data, dict) and "qa_pairs" in data:
                    qa_pairs = data["qa_pairs"]
                    logger.info(
                        f"S3μ—μ„ μ²λ¦¬λ QA λ°μ΄ν„° λ΅λ“ μ™„λ£: {len(qa_pairs)}κ° QA μ"
                    )

                    # λΉ„μ–΄μλ” qa_pairs μ²΄ν¬
                    if not qa_pairs:
                        logger.warning(
                            f"QA λ°μ΄ν„°κ°€ λΉ„μ–΄μμ. μ „μ²΄ λ°μ΄ν„° κµ¬μ΅°: {list(data.keys())}"
                        )
                        logger.warning(f"S3 ν‚¤: {s3_key}")
                        # JSONL ν•μ‹μΌλ΅ μ¬μ‹λ„
                        logger.info("qa_pairsκ°€ λΉ„μ–΄μμ–΄ JSONL ν•μ‹μΌλ΅ μ¬μ‹λ„")
                    else:
                        return qa_pairs
            except json.JSONDecodeError:
                logger.info("μ „μ²΄ JSON νμ‹± μ‹¤ν¨, JSONL ν•μ‹μΌλ΅ μ¬μ‹λ„")

            # JSONL ν•μ‹μΌλ΅ νμ‹± (κ° μ¤„μ΄ λ³„λ„μ JSON)
            for line in content.splitlines():
                if not line.strip():  # λΉ μ¤„ κ±΄λ„λ›°κΈ°
                    continue

                try:
                    data = json.loads(line)

                    # Single QA pair as a top-level object
                    if (
                        isinstance(data, dict)
                        and "question" in data
                        and "answer" in data
                    ):
                        qa_pairs.append(
                            {"question": data["question"], "answer": data["answer"]}
                        )

                    # Case 3: OpenAI batch result format
                    elif (
                        "response" in data
                        and isinstance(data["response"], dict)
                        and "body" in data["response"]
                        and isinstance(data["response"]["body"], dict)
                        and "choices" in data["response"]["body"]
                        and isinstance(data["response"]["body"]["choices"], list)
                        and len(data["response"]["body"]["choices"]) > 0
                        and "message" in data["response"]["body"]["choices"][0]
                        and isinstance(
                            data["response"]["body"]["choices"][0]["message"], dict
                        )
                        and "content"
                        in data["response"]["body"]["choices"][0]["message"]
                    ):

                        message_content = data["response"]["body"]["choices"][0][
                            "message"
                        ]["content"]

                        # JSON ν•μ‹ νμ‹± μ‹λ„
                        try:
                            qa_data = json.loads(message_content)
                            if (
                                isinstance(qa_data, dict)
                                and "q" in qa_data
                                and "a" in qa_data
                            ):
                                qa_pairs.append(
                                    {"question": qa_data["q"], "answer": qa_data["a"]}
                                )
                                continue
                        except json.JSONDecodeError:
                            pass

                        # κΈ°μ΅΄ Q:A: ν•μ‹ νμ‹±
                        if "Q:" in message_content and "A:" in message_content:
                            parts = message_content.split("A:", 1)
                            if len(parts) == 2:
                                question = parts[0].replace("Q:", "").strip()
                                answer = parts[1].strip()
                                qa_pairs.append(
                                    {"question": question, "answer": answer}
                                )
                            else:
                                logger.warning(
                                    f"S3 QA λ°μ΄ν„°: OpenAI ν•μ‹μ—μ„ Q:A: νμ‹± μ‹¤ν¨: {message_content}"
                                )
                        else:
                            # Q: λλ” A: ν‚¤μ›λ“κ°€ μ—†λ” κ²½μ°, custom_idμ—μ„ λ„λ©”μΈμ„ μ¶”μ¶ν•κ³  κΈ°λ³Έ μ§λ¬Έ μƒμ„±
                            logger.info(
                                f"S3 QA λ°μ΄ν„°: ν‚¤μ›λ“ μ—†λ” ν•μ‹ μ²λ¦¬ μ‹μ¤‰ - λ°μ΄ν„° κµ¬μ΅°: {list(data.keys())}"
                            )

                            if "custom_id" in data:
                                custom_id = data["custom_id"]
                                logger.info(
                                    f"S3 QA λ°μ΄ν„°: custom_id ν™•μΈ: {custom_id}"
                                )

                                # custom_idμ—μ„ λ„λ©”μΈ μ¶”μ¶
                                # ν•μ‹: "influencer_qa_[name]_[λ„λ©”μΈ]_[index]"
                                parts = custom_id.split("_")
                                if (
                                    len(parts) >= 4
                                ):  # μµμ†ν• influencer_qa_name_domain ν•μ‹
                                    domain = parts[-2]  # λμ—μ„ λ‘ λ²μ§Έ ν•­λ©μ΄ λ„λ©”μΈ
                                    domain_questions = {
                                        "μΌμƒμƒν™": [
                                            "μ¤λ ν•λ£¨λ” μ–΄λ–»κ² λ³΄λ‚΄μ…¨λ‚μ”?",
                                            "μ”μ¦ μ¦κ²¨ν•λ” μ·¨λ―Έκ°€ μμΌμ‹ κ°€μ”?",
                                        ],
                                        "κ³Όν•™κΈ°μ ": [
                                            "μµκ·Ό κ΄€μ‹¬μλ” κΈ°μ  νΈλ λ“κ°€ μμΌμ‹ κ°€μ”?",
                                            "AIλ‚ μΈκ³µμ§€λ¥μ— λ€ν•΄ μ–΄λ–»κ² μƒκ°ν•μ‹λ‚μ”?",
                                        ],
                                        "μ‚¬νμ΄μ": [
                                            "μ”μ¦ μ‚¬νμ—μ„ κ°€μ¥ μ¤‘μ”ν• μ΄μλ” λ¬΄μ—‡μ΄λΌκ³  μƒκ°ν•μ‹λ‚μ”?",
                                            "μ μ€ μ„Έλ€κ°€ μ§λ©΄ν• κ°€μ¥ ν° λ„μ „μ€ λ¬΄μ—‡μΌκΉμ”?",
                                        ],
                                        "μΈλ¬Έν•™": [
                                            "μΈμƒμ—μ„ κ°€μ¥ μ¤‘μ”ν• κ°€μΉλ” λ¬΄μ—‡μ΄λΌκ³  μƒκ°ν•μ‹λ‚μ”?",
                                            "μ—­μ‚¬μ—μ„ λ°°μΈ μ μλ” κµν›μ€ λ¬΄μ—‡μΌκΉμ”?",
                                        ],
                                        "μ¤ν¬μΈ ": [
                                            "μΆ‹μ•„ν•λ” μ¤ν¬μΈ λ‚ μ΄λ™μ΄ μμΌμ‹ κ°€μ”?",
                                            "μ΄λ™μ μ¦κ±°μ›€μ€ λ¬΄μ—‡μ΄λΌκ³  μƒκ°ν•μ‹λ‚μ”?",
                                        ],
                                        "μ—­μ‚¬λ¬Έν™”": [
                                            "μ°λ¦¬λ‚λΌμ μ „ν†µλ¬Έν™” μ¤‘ μλ‘μ¤λ¬μ΄ κ²ƒμ€ λ¬΄μ—‡μΈκ°€μ”?",
                                            "λ¬Έν™”μ λ‹¤μ–‘μ„±μ— λ€ν•΄ μ–΄λ–»κ² μƒκ°ν•μ‹λ‚μ”?",
                                        ],
                                    }

                                    # λ„λ©”μΈμ— λ§λ” μ§λ¬Έ μ‚¬μ©
                                    if domain in domain_questions:
                                        question = domain_questions[domain][
                                            0
                                        ]  # μ²« λ²μ§Έ μ§λ¬Έ μ‚¬μ©
                                        qa_pairs.append(
                                            {
                                                "question": question,
                                                "answer": message_content,
                                            }
                                        )
                                        logger.info(
                                            f"S3 QA λ°μ΄ν„°: λ„λ©”μΈ '{domain}'μ—μ„ QA μ μƒμ„± μ„±κ³µ"
                                        )
                                    else:
                                        # λ„λ©”μΈμ„ μ°Ύμ„ μ μ—†μΌλ©΄ κΈ°λ³Έ μ§λ¬Έ
                                        default_question = "μ΄μ— λ€ν•΄ λ‹µλ³€ν•΄ μ£Όμ„Έμ”."
                                        qa_pairs.append(
                                            {
                                                "question": default_question,
                                                "answer": message_content,
                                            }
                                        )
                                        logger.info(
                                            f"S3 QA λ°μ΄ν„°: μ• μ μ—†λ” λ„λ©”μΈ '{domain}', κΈ°λ³Έ μ§λ¬Έ μ‚¬μ©"
                                        )
                                else:
                                    # custom_id ν•μ‹μ΄ μμƒκ³Ό λ‹¤λ¦„
                                    default_question = "μ΄μ— λ€ν•΄ λ‹µλ³€ν•΄ μ£Όμ„Έμ”."
                                    qa_pairs.append(
                                        {
                                            "question": default_question,
                                            "answer": message_content,
                                        }
                                    )
                                    logger.info(
                                        f"S3 QA λ°μ΄ν„°: custom_id ν•μ‹ λ¶μΌμΉ, κΈ°λ³Έ μ§λ¬Έ μ‚¬μ©"
                                    )

                            else:
                                # custom_idκ°€ μ—†λ” κ²½μ°
                                default_question = "μ΄μ— λ€ν•΄ λ‹µλ³€ν•΄ μ£Όμ„Έμ”."
                                qa_pairs.append(
                                    {
                                        "question": default_question,
                                        "answer": message_content,
                                    }
                                )
                                logger.info(
                                    f"S3 QA λ°μ΄ν„°: custom_id μ—†μ, κΈ°λ³Έ μ§λ¬Έ μ‚¬μ©"
                                )

                    # Case 4: Top-level list of QA pairs (less common for JSONL, but possible)
                    elif isinstance(data, list):
                        for item in data:
                            if (
                                isinstance(item, dict)
                                and "question" in item
                                and "answer" in item
                            ):
                                qa_pairs.append(
                                    {
                                        "question": item["question"],
                                        "answer": item["answer"],
                                    }
                                )
                            else:
                                logger.warning(
                                    f"S3 QA λ°μ΄ν„°: λ¦¬μ¤νΈ λ‚΄λ¶€μ— μ ν¨ν•μ§€ μ•μ€ QA μ λ°κ²¬: {item}"
                                )

                    else:
                        logger.warning(
                            f"S3 QA λ°μ΄ν„°: μ• μ μ—†λ” JSON ν•μ‹ λ°κ²¬ (μ¤„ κ±΄λ„λ›°κΈ°): {line.strip()}"
                        )

                except json.JSONDecodeError as e:
                    logger.warning(
                        f"S3 QA λ°μ΄ν„°: JSON νμ‹± μ¤λ¥ (μ¤„ κ±΄λ„λ›°κΈ°): {e} - μ¤„ λ‚΄μ©: {line.strip()}"
                    )
                    continue

            if not qa_pairs:
                logger.error(
                    f"S3μ—μ„ μ ν¨ν• QA λ°μ΄ν„°λ¥Ό μ¶”μ¶ν•μ§€ λ»ν–μµλ‹λ‹¤. μ΄ λΌμΈ μ: {len(content.splitlines())}"
                )
                logger.error(f"S3 URL: {s3_url}")
                logger.error(f"S3 Key: {s3_key}")

                # μ»¨ν…μΈ  μƒν” μ¶λ ¥ (μ²μ 500μ)
                logger.error(f"μ»¨ν…μΈ  μƒν” (500μ): {content[:500]}...")
                return None

            logger.info(f"S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“ λ° νμ‹± μ™„λ£: {len(qa_pairs)}κ°")
            return qa_pairs

        except Exception as e:
            logger.error(f"S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“ μ‹¤ν¨: {e}", exc_info=True)

            # μ²λ¦¬λ QA νμΌμ΄ μ—†λ” κ²½μ° μ›λ³Έ νμΌ μ‹λ„
            if "NoSuchKey" in str(e) and "processed_qa" in s3_url:
                logger.warning("μ²λ¦¬λ QA νμΌμ΄ μ—†μµλ‹λ‹¤. μ›λ³Έ νμΌλ΅ μ‹λ„ν•©λ‹λ‹¤.")

                # URLμ„ μ›λ³Έ νμΌλ΅ λ³€κ²½
                raw_url = s3_url.replace("qa_pairs/", "qa_results/").replace(
                    f'processed_qa_{s3_url.split("_")[-1].replace(".json", "")}.json',
                    "generated_qa_results.jsonl",
                )

                logger.info(f"μ›λ³Έ νμΌ URLλ΅ μ¬μ‹λ„: {raw_url}")

                # μ¬κ·€ νΈμ¶λ΅ μ›λ³Έ νμΌ λ‹¤μ΄λ΅λ“ μ‹λ„
                return self.download_qa_data_from_s3(raw_url)

            return None

    async def prepare_finetuning_data(
        self, qa_data: List[Dict], influencer_data: AIInfluencer, system_prompt: Optional[str] = None
    ) -> tuple[List[Dict], str]:
        """
        νμΈνλ‹μ© λ°μ΄ν„° μ¤€λΉ„
        Args:
            qa_data: QA λ°μ΄ν„°
            influencer_data: AIInfluencer κ°μ²΄
            system_prompt: μ‹μ¤ν… ν”„λ΅¬ν”„νΈ (μ„ νƒμ )
        Returns:
            (νμΈνλ‹μ© λ°μ΄ν„°, μ‹μ¤ν… λ©”μ‹μ§€) νν”
        """
        try:
            # μΈν”λ£¨μ–Έμ„ μ •λ³΄ μ¶”μ¶
            influencer_name = influencer_data.influencer_name
            personality = getattr(
                influencer_data, "influencer_personality", "μΉκ·Όν•κ³  ν™λ°ν• μ„±κ²©"
            )
            style_info = getattr(influencer_data, "influencer_description", "")

            # μ‹μ¤ν… λ©”μ‹μ§€ μ‚¬μ© μ°μ„ μμ„:
            # 1. λ§¤κ°λ³€μλ΅ μ „λ‹¬λ system_prompt
            # 2. influencer_dataμ system_prompt
            # 3. vLLM μ„λ²„μ—μ„ μƒμ„±
            if system_prompt:
                system_message = system_prompt
            elif hasattr(influencer_data, 'system_prompt') and influencer_data.system_prompt:
                system_message = influencer_data.system_prompt
            else:
                # vLLM μ„λ²„μ—μ„ μ‹μ¤ν… λ©”μ‹μ§€ μƒμ„±
                system_message = await create_system_message(
                    influencer_name, personality, style_info
                )

            # QA λ°μ΄ν„° λ³€ν™ (vLLM μ„λ²„ μ‚¬μ©)
            finetuning_data = await convert_qa_data_for_finetuning(
                qa_data, influencer_name, personality, style_info
            )

            logger.info(f"νμΈνλ‹ λ°μ΄ν„° μ¤€λΉ„ μ™„λ£: {len(finetuning_data)}κ° ν•­λ©")
            return finetuning_data, system_message

        except Exception as e:
            logger.error(f"νμΈνλ‹ λ°μ΄ν„° μ¤€λΉ„ μ‹¤ν¨: {e}")
            raise

    async def run_finetuning(
        self,
        qa_data: List[Dict],
        system_message: str,
        hf_repo_id: str,
        hf_token: str,
        epochs: int = 5,
        task_id: Optional[str] = None,
        system_prompt: str = ""
    ) -> Optional[str]:
        """
        νμΈνλ‹ μ‹¤ν–‰ (VLLM μ„λ²„μ— μ‘μ—… μ μ¶ ν›„ μ¦‰μ‹ λ°ν™)
        Args:
            qa_data: ν›λ ¨ λ°μ΄ν„° (QA μ λ¦¬μ¤νΈ)
            system_message: μ‹μ¤ν… λ©”μ‹μ§€
            hf_repo_id: Hugging Face Repository ID
            hf_token: ν—κΉ…νμ΄μ¤ ν† ν°
            epochs: ν›λ ¨ μ—ν¬ν¬ μ
            task_id: QA μƒμ„± μ‘μ—… ID (μ„ νƒμ )
        Returns:
            task_id (μ„±κ³µ μ‹), None (μ‹¤ν¨ μ‹)
        """
        try:
            logger.info(f"νμΈνλ‹ μ‹μ‘: {hf_repo_id}")

            # VLLM μ„λ²„ μƒνƒ ν™•μΈ
            logger.info(f"π” VLLM μ„λ²„ μƒνƒ ν™•μΈ μ¤‘... (URL: {settings.VLLM_BASE_URL})")
            health_status = await vllm_health_check()
            if not health_status:
                logger.error(f"β VLLM μ„λ²„κ°€ λΉ„ν™μ„±ν™”λμ—κ±°λ‚ μ—°κ²°ν•  μ μ—†μµλ‹λ‹¤. URL: {settings.VLLM_BASE_URL}")
                logger.error(f"   - VLLM_ENABLED: {settings.VLLM_ENABLED}")
                logger.error(f"   - VLLM_HOST: {getattr(settings, 'VLLM_HOST', 'N/A')}")
                logger.error(f"   - VLLM_PORT: {getattr(settings, 'VLLM_PORT', 'N/A')}")
                return None
            else:
                logger.info("β… VLLM μ„λ²„ μ—°κ²° μ„±κ³µ")

            try:
                logger.info(f"π€ VLLM μ„λ²„μ—μ„ νμΈνλ‹ μ‹¤ν–‰: {hf_repo_id}")

                # μΈν”λ£¨μ–Έμ„ μ •λ³΄ μ¶”μ¶ (QA λ°μ΄ν„°μ—μ„)
                influencer_name = hf_repo_id.split("/")[-1].replace("-finetuned", "")
                personality = "μΉκ·Όν•κ³  ν™λ°ν• μ„±κ²©"  # κΈ°λ³Έκ°’

                # μ΄λ―Έ λ³€ν™λ λ°μ΄ν„°μΈμ§€ ν™•μΈ
                is_already_converted = (
                    qa_data
                    and isinstance(qa_data[0], dict)
                    and "messages" in qa_data[0]
                )

                vllm_client = await get_vllm_client()
                result = await vllm_client.start_finetuning(
                    influencer_id=influencer_name,
                    influencer_name=influencer_name,
                    personality=personality,
                    qa_data=qa_data,
                    hf_repo_id=hf_repo_id,
                    hf_token=hf_token,
                    training_epochs=epochs,
                    system_prompt=system_prompt,
                    style_info="",
                    is_converted=is_already_converted,
                    task_id=task_id,
                )

                task_id = result.get("task_id")
                if task_id:
                    # νμΈνλ‹ μ‘μ—…μ΄ μ‹μ‘λλ©΄ task_idλ§ λ°ν™ (ν΄λ§ν•μ§€ μ•μ)
                    # VLLM μ„λ²„κ°€ μ™„λ£ μ‹ μ›Ήν›…μ„ ν†µν•΄ μ•λ ¤μ¤
                    logger.info(f"β… νμΈνλ‹ μ‘μ—… μ μ¶ μ™„λ£: task_id={task_id}")
                    return task_id
                else:
                    raise Exception("VLLM νμΈνλ‹ μ‘μ—… μ‹μ‘ μ‹¤ν¨")

            except Exception as e:
                logger.error(f"VLLM νμΈνλ‹ μ‹¤ν–‰ μ¤‘ μ¤λ¥: {e}")
                return None

        except Exception as e:
            logger.error(f"νμΈνλ‹ μ‹¤ν–‰ μ‹¤ν¨: {e}")
            return None

    # ν΄λ§ λ°©μ‹μ€ λ” μ΄μƒ μ‚¬μ©ν•μ§€ μ•μ (μ›Ήν›… κΈ°λ°μΌλ΅ μ „ν™)
    # async def _wait_for_vllm_finetuning(self, task_id: str, vllm_client, timeout: int = 3600) -> Optional[str]:
    #     """VLLM νμΈνλ‹ μ™„λ£ λ€κΈ°"""
    #     import asyncio
    #
    #     start_time = datetime.now()
    #
    #     while True:
    #         try:
    #             status = await vllm_client.get_finetuning_status(task_id)
    #             current_status = status.get("status")
    #
    #             logger.info(f"VLLM νμΈνλ‹ μƒνƒ: {current_status}")
    #
    #             if current_status == "completed":
    #                 hf_model_url = status.get("hf_model_url")
    #                 logger.info(f"β… VLLM νμΈνλ‹ μ™„λ£: {hf_model_url}")
    #                 return hf_model_url
    #
    #             elif current_status == "failed":
    #                 error_msg = status.get("error_message", "μ• μ μ—†λ” μ¤λ¥")
    #                 logger.error(f"β VLLM νμΈνλ‹ μ‹¤ν¨: {error_msg}")
    #                 return None
    #
    #             # νƒ€μ„μ•„μ›ƒ ν™•μΈ
    #             elapsed = (datetime.now() - start_time).total_seconds()
    #             if elapsed > timeout:
    #                 logger.error(f"β° VLLM νμΈνλ‹ νƒ€μ„μ•„μ›ƒ: {timeout}μ΄")
    #                 return None
    #
    #             # 10μ΄ λ€κΈ°
    #             await asyncio.sleep(10)
    #
    #         except Exception as e:
    #             logger.error(f"VLLM νμΈνλ‹ μƒνƒ ν™•μΈ μ‹¤ν¨: {e}")
    #             return None

    async def start_finetuning_task(
        self,
        influencer_id: str,
        qa_task_id: str,
        s3_qa_url: str,
        influencer_data: AIInfluencer,
        db=None,
        task_id: Optional[str] = None,
    ) -> str:
        """
        νμΈνλ‹ μ‘μ—… μ‹μ‘
        Args:
            influencer_id: μΈν”λ£¨μ–΄μ„ ID
            qa_task_id: QA μƒμ„± μ‘μ—… ID
            s3_qa_url: S3 QA λ°μ΄ν„° URL
            influencer_data: μΈν”λ£¨μ–΄μ„ μ •λ³΄ (λ”•μ…”λ„λ¦¬ λλ” λ¨λΈ μΈμ¤ν„΄μ¤)
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
            task_id: QA μƒμ„± μ‘μ—… ID (μ„ νƒμ )
        Returns:
            νμΈνλ‹ μ‘μ—… ID
        """
        import time

        # νμΈνλ‹ μ‘μ—… ID μƒμ„±
        ft_task_id = f"ft_{influencer_id}_{int(time.time())}"

        # μΈν”λ£¨μ–Έμ„ μ΄λ¦„ μ²λ¦¬
        influencer_name = getattr(influencer_data, "influencer_name", "influencer")

        # ν—κΉ…νμ΄μ¤ ν† ν° μ •λ³΄ κ°€μ Έμ¤κΈ°
        try:
            if db:
                _, hf_username = await self._get_hf_info_from_influencer(influencer_data, db)
            else:
                hf_username = "skn-team"
        except Exception as e:
            logger.warning(f"ν—κΉ…νμ΄μ¤ μ‚¬μ©μλ… μ΅°ν μ‹¤ν¨, κΈ°λ³Έκ°’ μ‚¬μ©: {e}")
            hf_username = "skn-team"

        # ν•κΈ€ μ΄λ¦„μ„ μλ¬ΈμΌλ΅ λ³€ν™
        english_name = self._convert_korean_to_english(influencer_name)

        # μΈν”λ£¨μ–Έμ„ λ¨λΈ repo κ²½λ΅ μƒμ„± (ν—κΉ…νμ΄μ¤ μ‚¬μ©μλ…/μλ¬Έμ΄λ¦„-finetuned)
        model_repo = getattr(influencer_data, "influencer_model_repo", "")

        if model_repo:
            # κΈ°μ΅΄ repo κ²½λ΅κ°€ μμΌλ©΄ μ‚¬μ©
            hf_repo_id = model_repo
            safe_name = model_repo.split("/")[-1] if "/" in model_repo else model_repo
        else:
            # μƒλ΅μ΄ repo κ²½λ΅ μƒμ„±
            safe_name = f"{english_name}-finetuned"
            hf_repo_id = f"{hf_username}/{safe_name}"

        logger.info(
            f"νμΈνλ‹ λ¦¬ν¬μ§€ν† λ¦¬ μ„¤μ •: {hf_repo_id} (μ›λ³Έ: {influencer_name} β†’ μλ¬Έ: {english_name})"
        )
        
        # system_prompt κ°€μ Έμ¤κΈ°
        if hasattr(influencer_data, 'system_prompt') and influencer_data.system_prompt:
            system_message = influencer_data.system_prompt
        else:
            system_message = ""
            
        # μ‘μ—… μƒμ„±
        task = FineTuningTask(
            task_id=ft_task_id,
            influencer_id=influencer_id,
            qa_task_id=qa_task_id,
            status=FineTuningStatus.PENDING,
            s3_qa_url=s3_qa_url,
            model_name=safe_name,
            hf_repo_id=hf_repo_id,
            qa_batch_task_id=task_id,
            system_prompt=system_message
        )

        self.tasks[ft_task_id] = task
        logger.info(f"νμΈνλ‹ μ‘μ—… μƒμ„±: {ft_task_id}")

        return ft_task_id

    async def execute_finetuning_task(
        self, task_id: str, influencer_data: AIInfluencer, hf_token: str, db=None
    ) -> bool:
        """
        νμΈνλ‹ μ‘μ—… μ‹¤ν–‰
        Args:
            task_id: μ‘μ—… ID
            influencer_data: μΈν”λ£¨μ–Έμ„ μ •λ³΄
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
        Returns:
            μ„±κ³µ μ—¬λ¶€
        """
        task = self.tasks.get(task_id)
        if not task:
            logger.error(f"νμΈνλ‹ μ‘μ—…μ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {task_id}")
            return False

        try:
            # 1. λ°μ΄ν„° μ¤€λΉ„ λ‹¨κ³„
            task.status = FineTuningStatus.PREPARING_DATA
            task.updated_at = get_current_kst()

            # S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“
            qa_data = self.download_qa_data_from_s3(task.s3_qa_url)
            if not qa_data:
                raise Exception("S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“ μ‹¤ν¨")

            # νμΈνλ‹μ© λ°μ΄ν„° μ¤€λΉ„
            finetuning_qa_data, system_message = await self.prepare_finetuning_data(
                qa_data, influencer_data, task.system_prompt
            )

            # 2. νμΈνλ‹ μ‹¤ν–‰ λ‹¨κ³„
            task.status = FineTuningStatus.TRAINING
            task.updated_at = get_current_kst()

            vllm_task_id = await self.run_finetuning(
                qa_data=finetuning_qa_data,
                system_message=system_message,
                hf_repo_id=task.hf_repo_id,
                hf_token=hf_token,
                epochs=task.training_epochs,
                task_id=task.qa_batch_task_id,
                system_prompt=task.system_prompt or system_message
            )

            if vllm_task_id:
                # VLLM μ„λ²„μ— μ‘μ—…μ΄ μ μ¶λ¨
                # μ›Ήν›…μ„ ν†µν•΄ μ™„λ£ ν†µμ§€λ¥Ό λ°›μ„ μμ •
                logger.info(
                    f"νμΈνλ‹ μ‘μ—… μ μ¶λ¨: {task_id} β†’ VLLM task_id: {vllm_task_id}"
                )

                # BatchKey ν…μ΄λΈ”μ— VLLM task_id μ—…λ°μ΄νΈ (μ›Ήν›… μ²λ¦¬λ¥Ό μ„ν•΄)
                if task.qa_batch_task_id:
                    from app.database import get_db
                    from app.models.influencer import BatchKey

                    try:
                        db_gen = get_db()
                        db = next(db_gen)
                        batch_key = (
                            db.query(BatchKey)
                            .filter(BatchKey.task_id == task.qa_batch_task_id)
                            .first()
                        )
                        if batch_key:
                            batch_key.vllm_task_id = vllm_task_id
                            db.commit()
                            logger.info(f"BatchKeyμ— VLLM task_id μ €μ¥: {vllm_task_id}")
                    except Exception as e:
                        logger.error(f"BatchKey μ—…λ°μ΄νΈ μ‹¤ν¨: {e}")
                    finally:
                        db_gen.close()

                return True
            else:
                raise Exception(f"νμΈνλ‹ μ‹¤ν–‰ μ‹¤ν¨: VLLM μ‘μ—… μ μ¶ μ‹¤ν¨")

        except Exception as e:
            task.status = FineTuningStatus.FAILED
            task.error_message = str(e)
            task.updated_at = get_current_kst()
            logger.error(f"νμΈνλ‹ μ‘μ—… μ‹¤ν¨: {task_id}, {e}")
            return False

    def get_task_status(self, task_id: str) -> Optional[FineTuningTask]:
        """νμΈνλ‹ μ‘μ—… μƒνƒ μ΅°ν"""
        return self.tasks.get(task_id)

    def get_all_tasks(self) -> Dict[str, FineTuningTask]:
        """λ¨λ“  νμΈνλ‹ μ‘μ—… μ΅°ν"""
        return self.tasks

    def get_tasks_by_influencer(self, influencer_id: str) -> List[FineTuningTask]:
        """νΉμ • μΈν”λ£¨μ–Έμ„μ νμΈνλ‹ μ‘μ—… μ΅°ν"""
        return [
            task for task in self.tasks.values() if task.influencer_id == influencer_id
        ]

    def is_influencer_finetuned(self, influencer_data, db=None) -> bool:
        """
        μΈν”λ£¨μ–Έμ„κ°€ νμΈνλ‹λμ—λ”μ§€ ν™•μΈ
        Args:
            influencer_data: μΈν”λ£¨μ–Έμ„ λ°μ΄ν„° (λ”•μ…”λ„λ¦¬ λλ” λ¨λΈ μΈμ¤ν„΄μ¤)
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
        Returns:
            νμΈνλ‹ μ™„λ£ μ—¬λ¶€
        """
        try:
            # μΈν”λ£¨μ–Έμ„ ID μ¶”μ¶
            if isinstance(influencer_data, dict):
                influencer_id = influencer_data.get("influencer_id")
                model_repo = influencer_data.get("influencer_model_repo", "")
            else:
                influencer_id = getattr(influencer_data, "influencer_id", None)
                model_repo = getattr(influencer_data, "influencer_model_repo", "")

            if not influencer_id:
                return False

            # 1. λ¨λΈ repoκ°€ μ„¤μ •λμ–΄ μλ”μ§€ ν™•μΈ
            if model_repo and model_repo.strip():
                logger.info(
                    f"μΈν”λ£¨μ–Έμ„ {influencer_id}μ— λ¨λΈ repoκ°€ μ„¤μ •λ¨: {model_repo}"
                )
                return True

            # 2. μ™„λ£λ νμΈνλ‹ μ‘μ—…μ΄ μλ”μ§€ ν™•μΈ
            completed_tasks = [
                task
                for task in self.tasks.values()
                if (
                    task.influencer_id == influencer_id
                    and task.status == FineTuningStatus.COMPLETED
                )
            ]

            if completed_tasks:
                logger.info(
                    f"μΈν”λ£¨μ–Έμ„ {influencer_id}μ— μ™„λ£λ νμΈνλ‹ μ‘μ—… λ°κ²¬: {len(completed_tasks)}κ°"
                )
                return True

            # 3. λ°μ΄ν„°λ² μ΄μ¤μ—μ„ μ™„λ£λ νμΈνλ‹ κΈ°λ΅ ν™•μΈ
            if db:
                from app.models.influencer import BatchKey as BatchJob

                completed_finetuning = (
                    db.query(BatchJob)
                    .filter(
                        BatchJob.influencer_id == influencer_id,
                        BatchJob.is_finetuning_started == True,
                        BatchJob.status == "completed",
                    )
                    .first()
                )

                if completed_finetuning:
                    logger.info(
                        f"μΈν”λ£¨μ–Έμ„ {influencer_id}μ— λ°μ΄ν„°λ² μ΄μ¤μ—μ„ μ™„λ£λ νμΈνλ‹ λ°κ²¬"
                    )
                    return True

            logger.info(f"μΈν”λ£¨μ–Έμ„ {influencer_id}λ” μ•„μ§ νμΈνλ‹λμ§€ μ•μ")
            return False

        except Exception as e:
            logger.error(f"νμΈνλ‹ μƒνƒ ν™•μΈ μ¤‘ μ¤λ¥: {e}")
            return False

    async def start_finetuning_for_influencer(
        self, influencer_id: str, s3_qa_file_url: str, db, task_id: Optional[str] = None
    ) -> bool:
        """
        μΈν”λ£¨μ–Έμ„λ¥Ό μ„ν• νμΈνλ‹ μ‹μ‘ (startup serviceμ©)
        Args:
            influencer_id: μΈν”λ£¨μ–Έμ„ ID
            s3_qa_file_url: S3 QA νμΌ URL
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
            task_id: QA μƒμ„± μ‘μ—… ID (μ„ νƒμ )
        Returns:
            μ„±κ³µ μ—¬λ¶€
        """
        try:
            # μΈν”λ£¨μ–Έμ„ μ •λ³΄ κ°€μ Έμ¤κΈ° (μ‹μ¤ν… μ‘μ—…μ΄λ―€λ΅ κ¶ν• μ²΄ν¬ μ—†μ΄ μ§μ ‘ μ΅°ν)
            from app.models.influencer import AIInfluencer
            
            influencer_data = (
                db.query(AIInfluencer)
                .filter(AIInfluencer.influencer_id == influencer_id)
                .first()
            )

            if not influencer_data:
                logger.error(f"μΈν”λ£¨μ–Έμ„λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {influencer_id}")
                return False

            # ν—κΉ…νμ΄μ¤ ν† ν° μ •λ³΄ κ°€μ Έμ¤κΈ°
            hf_token, hf_username = await self._get_hf_info_from_influencer(
                influencer_data, db
            )

            # νμΈνλ‹ μ‘μ—… μ‹μ‘ (λ¨λΈ μΈμ¤ν„΄μ¤ μ§μ ‘ μ‚¬μ©)
            ft_task_id = await self.start_finetuning_task(
                influencer_id=influencer_id,
                qa_task_id=f"startup_restart_{influencer_id}",
                s3_qa_url=s3_qa_file_url,
                influencer_data=influencer_data,  # λ¨λΈ μΈμ¤ν„΄μ¤ μ§μ ‘ μ „λ‹¬
                db=db,
                task_id=task_id
            )

            # νμΈνλ‹ μ‹¤ν–‰
            success = await self.execute_finetuning_task(
                ft_task_id, influencer_data, hf_token, db
            )

            if success:
                logger.info(f"β… μΈν”λ£¨μ–Έμ„ νμΈνλ‹ μλ™ μ‹μ‘ μ„±κ³µ: {influencer_id}")
            else:
                logger.error(f"β μΈν”λ£¨μ–Έμ„ νμΈνλ‹ μλ™ μ‹μ‘ μ‹¤ν¨: {influencer_id}")

            return success

        except Exception as e:
            logger.error(
                f"β μΈν”λ£¨μ–Έμ„ νμΈνλ‹ μ‹μ‘ μ¤‘ μ¤λ¥: {influencer_id}, {str(e)}"
            )
            return False


# μ „μ—­ νμΈνλ‹ μ„λΉ„μ¤ μΈμ¤ν„΄μ¤
finetuning_service = InfluencerFineTuningService()


def get_finetuning_service() -> InfluencerFineTuningService:
    """νμΈνλ‹ μ„λΉ„μ¤ μμ΅΄μ„± μ£Όμ…μ© ν•¨μ"""
    return finetuning_service
