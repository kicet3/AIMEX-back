"""
νμΈνλ‹ μ„λΉ„μ¤
S3μ—μ„ QA λ°μ΄ν„°λ¥Ό κ°€μ Έμ™€ EXAONE λ¨λΈ νμΈνλ‹ μν–‰
"""

import os
import json
import logging
import tempfile
import shutil
import time
from typing import Optional, Dict, List
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

from app.services.s3_service import get_s3_service
from app.services.runpod_finetuning_client import RunPodFineTuningClient
from app.core.encryption import decrypt_sensitive_data
from app.services.hf_token_resolver import get_token_for_influencer
from app.core.config import settings
from app.models.influencer import AIInfluencer
from app.utils.finetuning_utils import (
    create_system_message,
    convert_qa_data_for_finetuning,
    validate_qa_data,
    format_model_name_for_korean,
)
from app.utils.timezone_utils import get_current_kst

logger = logging.getLogger(__name__)


# FineTuningStatus Enum μ •μ
class FineTuningStatus(Enum):
    PENDING = "pending"
    PREPARING_DATA = "preparing_data"
    TRAINING = "training"
    UPLOADING = "uploading"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class FineTuningTask:
    task_id: str
    influencer_id: str
    qa_task_id: str
    status: FineTuningStatus
    s3_qa_url: str
    model_name: Optional[str] = None
    hf_repo_id: Optional[str] = None
    hf_model_url: Optional[str] = None
    error_message: Optional[str] = None
    training_epochs: int = 5
    qa_batch_task_id: Optional[str] = None
    system_prompt: Optional[str] = None
    created_at: datetime = None
    updated_at: datetime = None

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.updated_at is None:
            self.updated_at = get_current_kst()


class InfluencerFineTuningService:
    def __init__(self):
        """νμΈνλ‹ μ„λΉ„μ¤ μ΄κΈ°ν™”"""
        self.s3_service = get_s3_service()
        self.runpod_client = RunPodFineTuningClient()
        self.tasks: Dict[str, FineTuningTask] = {}

        # κΈ°λ³Έ λ¨λΈ μ„¤μ •
        self.base_model = os.getenv(
            "FINETUNING_BASE_MODEL", "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct"
        )

    def _convert_korean_to_english(self, korean_name: str) -> str:
        """ν•κΈ€ μ΄λ¦„μ„ μλ¬ΈμΌλ΅ λ³€ν™ (κ³µν†µ μ ν‹Έλ¦¬ν‹° μ‚¬μ©)"""
        return format_model_name_for_korean(korean_name)

    async def _get_hf_info_from_influencer(self, influencer_data, db) -> tuple[str, str]:
        """
        μΈν”λ£¨μ–Έμ„μ κ·Έλ£Ή IDλ¥Ό ν†µν•΄ ν—κΉ…νμ΄μ¤ ν† ν°κ³Ό μ‚¬μ©μλ… μ •λ³΄ κ°€μ Έμ¤κΈ°
        Args:
            influencer_data: μΈν”λ£¨μ–Έμ„ λ°μ΄ν„°
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
        Returns:
            (hf_token, hf_username) νν”
        """
        logger.debug(
            f"_get_hf_info_from_influencer νΈμ¶λ¨. influencer_data νƒ€μ…: {type(influencer_data)}"
        )

        try:
            # μ¤‘μ•™ν™”λ ν† ν° λ¦¬μ΅Έλ²„ μ‚¬μ©
            hf_token, hf_username = await get_token_for_influencer(influencer_data, db)
            
            if hf_token and hf_username:
                logger.info(
                    f"β… ν† ν° μ΅°ν μ„±κ³µ: {influencer_data.influencer_name if hasattr(influencer_data, 'influencer_name') else 'Unknown'}"
                )
                return hf_token, hf_username
            else:
                # ν† ν°μ΄ μ—†λ” κ²½μ°
                group_id = getattr(influencer_data, 'group_id', 'Unknown')
                logger.warning(
                    f"κ·Έλ£Ή {group_id}μ— λ“±λ΅λ ν—κΉ…νμ΄μ¤ ν† ν°μ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
                )
                raise Exception(
                    f"κ·Έλ£Ή {group_id}μ— λ“±λ΅λ ν—κΉ…νμ΄μ¤ ν† ν°μ΄ μ—†μµλ‹λ‹¤. κ΄€λ¦¬μμ—κ² λ¬Έμν•μ—¬ ν† ν°μ„ λ“±λ΅ν•΄μ£Όμ„Έμ”."
                )

        except Exception as e:
            logger.error(f"ν—κΉ…νμ΄μ¤ μ •λ³΄ κ°€μ Έμ¤κΈ° μ‹¤ν¨: {e}", exc_info=True)
            raise

    def download_qa_data_from_s3(self, s3_url: str) -> Optional[List[Dict]]:
        """
        S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“
        Args:
            s3_url: S3 QA λ°μ΄ν„° URL
        Returns:
            QA λ°μ΄ν„° λ¦¬μ¤νΈ
        """
        try:
            logger.info(f"S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“ μ‹μ‘: {s3_url}")

            # S3 URLμ—μ„ ν‚¤ μ¶”μ¶
            if "amazonaws.com/" in s3_url:
                s3_key = s3_url.split("amazonaws.com/")[-1]
                logger.info(f"S3 ν‚¤: {s3_key}")
            else:
                logger.error(f"μλ»λ S3 URL ν•μ‹: {s3_url}")
                return None

            # S3μ—μ„ νμΌ λ‚΄μ© κ°€μ Έμ¤κΈ°
            if not self.s3_service.is_available():
                logger.error("S3 μ„λΉ„μ¤λ¥Ό μ‚¬μ©ν•  μ μ—†μµλ‹λ‹¤")
                return None

            response = self.s3_service.s3_client.get_object(
                Bucket=self.s3_service.bucket_name, Key=s3_key
            )

            content = response["Body"].read().decode("utf-8")
            qa_pairs = []

            # λ¨Όμ € μ „μ²΄ λ‚΄μ©μ„ ν•λ‚μ JSONμΌλ΅ νμ‹± μ‹λ„ (μ²λ¦¬λ QA ν•μ‹)
            try:
                data = json.loads(content)
                if isinstance(data, dict) and "qa_pairs" in data:
                    qa_pairs = data["qa_pairs"]
                    logger.info(
                        f"S3μ—μ„ μ²λ¦¬λ QA λ°μ΄ν„° λ΅λ“ μ™„λ£: {len(qa_pairs)}κ° QA μ"
                    )

                    # λΉ„μ–΄μλ” qa_pairs μ²΄ν¬
                    if not qa_pairs:
                        logger.warning(
                            f"QA λ°μ΄ν„°κ°€ λΉ„μ–΄μμ. μ „μ²΄ λ°μ΄ν„° κµ¬μ΅°: {list(data.keys())}"
                        )
                        logger.warning(f"S3 ν‚¤: {s3_key}")
                        # JSONL ν•μ‹μΌλ΅ μ¬μ‹λ„
                        logger.info("qa_pairsκ°€ λΉ„μ–΄μμ–΄ JSONL ν•μ‹μΌλ΅ μ¬μ‹λ„")
                    else:
                        return qa_pairs
            except json.JSONDecodeError:
                logger.info("μ „μ²΄ JSON νμ‹± μ‹¤ν¨, JSONL ν•μ‹μΌλ΅ μ¬μ‹λ„")

            # JSONL ν•μ‹μΌλ΅ νμ‹± (κ° μ¤„μ΄ λ³„λ„μ JSON)
            for line in content.splitlines():
                if not line.strip():  # λΉ μ¤„ κ±΄λ„λ›°κΈ°
                    continue

                try:
                    data = json.loads(line)

                    # Single QA pair as a top-level object
                    if (
                        isinstance(data, dict)
                        and "question" in data
                        and "answer" in data
                    ):
                        qa_pairs.append(
                            {"question": data["question"], "answer": data["answer"]}
                        )

                    # Case 3: OpenAI batch result format
                    elif (
                        "response" in data
                        and isinstance(data["response"], dict)
                        and "body" in data["response"]
                        and isinstance(data["response"]["body"], dict)
                        and "choices" in data["response"]["body"]
                        and isinstance(data["response"]["body"]["choices"], list)
                        and len(data["response"]["body"]["choices"]) > 0
                        and "message" in data["response"]["body"]["choices"][0]
                        and isinstance(
                            data["response"]["body"]["choices"][0]["message"], dict
                        )
                        and "content"
                        in data["response"]["body"]["choices"][0]["message"]
                    ):

                        message_content = data["response"]["body"]["choices"][0][
                            "message"
                        ]["content"]

                        # JSON ν•μ‹ νμ‹± μ‹λ„
                        try:
                            qa_data = json.loads(message_content)
                            if (
                                isinstance(qa_data, dict)
                                and "q" in qa_data
                                and "a" in qa_data
                            ):
                                qa_pairs.append(
                                    {"question": qa_data["q"], "answer": qa_data["a"]}
                                )
                                continue
                        except json.JSONDecodeError:
                            pass

                        # κΈ°μ΅΄ Q:A: ν•μ‹ νμ‹±
                        if "Q:" in message_content and "A:" in message_content:
                            parts = message_content.split("A:", 1)
                            if len(parts) == 2:
                                question = parts[0].replace("Q:", "").strip()
                                answer = parts[1].strip()
                                qa_pairs.append(
                                    {"question": question, "answer": answer}
                                )
                            else:
                                logger.warning(
                                    f"S3 QA λ°μ΄ν„°: OpenAI ν•μ‹μ—μ„ Q:A: νμ‹± μ‹¤ν¨: {message_content}"
                                )
                        else:
                            # Q: λλ” A: ν‚¤μ›λ“κ°€ μ—†λ” κ²½μ°, custom_idμ—μ„ λ„λ©”μΈμ„ μ¶”μ¶ν•κ³  κΈ°λ³Έ μ§λ¬Έ μƒμ„±
                            logger.info(
                                f"S3 QA λ°μ΄ν„°: ν‚¤μ›λ“ μ—†λ” ν•μ‹ μ²λ¦¬ μ‹μ¤‰ - λ°μ΄ν„° κµ¬μ΅°: {list(data.keys())}"
                            )

                            if "custom_id" in data:
                                custom_id = data["custom_id"]
                                logger.info(
                                    f"S3 QA λ°μ΄ν„°: custom_id ν™•μΈ: {custom_id}"
                                )

                                # custom_idμ—μ„ λ„λ©”μΈ μ¶”μ¶
                                # ν•μ‹: "influencer_qa_[name]_[λ„λ©”μΈ]_[index]"
                                parts = custom_id.split("_")
                                if (
                                    len(parts) >= 4
                                ):  # μµμ†ν• influencer_qa_name_domain ν•μ‹
                                    domain = parts[-2]  # λμ—μ„ λ‘ λ²μ§Έ ν•­λ©μ΄ λ„λ©”μΈ
                                    domain_questions = {
                                        "μΌμƒμƒν™": [
                                            "μ¤λ ν•λ£¨λ” μ–΄λ–»κ² λ³΄λ‚΄μ…¨λ‚μ”?",
                                            "μ”μ¦ μ¦κ²¨ν•λ” μ·¨λ―Έκ°€ μμΌμ‹ κ°€μ”?",
                                        ],
                                        "κ³Όν•™κΈ°μ ": [
                                            "μµκ·Ό κ΄€μ‹¬μλ” κΈ°μ  νΈλ λ“κ°€ μμΌμ‹ κ°€μ”?",
                                            "AIλ‚ μΈκ³µμ§€λ¥μ— λ€ν•΄ μ–΄λ–»κ² μƒκ°ν•μ‹λ‚μ”?",
                                        ],
                                        "μ‚¬νμ΄μ": [
                                            "μ”μ¦ μ‚¬νμ—μ„ κ°€μ¥ μ¤‘μ”ν• μ΄μλ” λ¬΄μ—‡μ΄λΌκ³  μƒκ°ν•μ‹λ‚μ”?",
                                            "μ μ€ μ„Έλ€κ°€ μ§λ©΄ν• κ°€μ¥ ν° λ„μ „μ€ λ¬΄μ—‡μΌκΉμ”?",
                                        ],
                                        "μΈλ¬Έν•™": [
                                            "μΈμƒμ—μ„ κ°€μ¥ μ¤‘μ”ν• κ°€μΉλ” λ¬΄μ—‡μ΄λΌκ³  μƒκ°ν•μ‹λ‚μ”?",
                                            "μ—­μ‚¬μ—μ„ λ°°μΈ μ μλ” κµν›μ€ λ¬΄μ—‡μΌκΉμ”?",
                                        ],
                                        "μ¤ν¬μΈ ": [
                                            "μΆ‹μ•„ν•λ” μ¤ν¬μΈ λ‚ μ΄λ™μ΄ μμΌμ‹ κ°€μ”?",
                                            "μ΄λ™μ μ¦κ±°μ›€μ€ λ¬΄μ—‡μ΄λΌκ³  μƒκ°ν•μ‹λ‚μ”?",
                                        ],
                                        "μ—­μ‚¬λ¬Έν™”": [
                                            "μ°λ¦¬λ‚λΌμ μ „ν†µλ¬Έν™” μ¤‘ μλ‘μ¤λ¬μ΄ κ²ƒμ€ λ¬΄μ—‡μΈκ°€μ”?",
                                            "λ¬Έν™”μ λ‹¤μ–‘μ„±μ— λ€ν•΄ μ–΄λ–»κ² μƒκ°ν•μ‹λ‚μ”?",
                                        ],
                                    }

                                    # λ„λ©”μΈμ— λ§λ” μ§λ¬Έ μ‚¬μ©
                                    if domain in domain_questions:
                                        question = domain_questions[domain][
                                            0
                                        ]  # μ²« λ²μ§Έ μ§λ¬Έ μ‚¬μ©
                                        qa_pairs.append(
                                            {
                                                "question": question,
                                                "answer": message_content,
                                            }
                                        )
                                        logger.info(
                                            f"S3 QA λ°μ΄ν„°: λ„λ©”μΈ '{domain}'μ—μ„ QA μ μƒμ„± μ„±κ³µ"
                                        )
                                    else:
                                        # λ„λ©”μΈμ„ μ°Ύμ„ μ μ—†μΌλ©΄ κΈ°λ³Έ μ§λ¬Έ
                                        default_question = "μ΄μ— λ€ν•΄ λ‹µλ³€ν•΄ μ£Όμ„Έμ”."
                                        qa_pairs.append(
                                            {
                                                "question": default_question,
                                                "answer": message_content,
                                            }
                                        )
                                        logger.info(
                                            f"S3 QA λ°μ΄ν„°: μ• μ μ—†λ” λ„λ©”μΈ '{domain}', κΈ°λ³Έ μ§λ¬Έ μ‚¬μ©"
                                        )
                                else:
                                    # custom_id ν•μ‹μ΄ μμƒκ³Ό λ‹¤λ¦„
                                    default_question = "μ΄μ— λ€ν•΄ λ‹µλ³€ν•΄ μ£Όμ„Έμ”."
                                    qa_pairs.append(
                                        {
                                            "question": default_question,
                                            "answer": message_content,
                                        }
                                    )
                                    logger.info(
                                        f"S3 QA λ°μ΄ν„°: custom_id ν•μ‹ λ¶μΌμΉ, κΈ°λ³Έ μ§λ¬Έ μ‚¬μ©"
                                    )

                            else:
                                # custom_idκ°€ μ—†λ” κ²½μ°
                                default_question = "μ΄μ— λ€ν•΄ λ‹µλ³€ν•΄ μ£Όμ„Έμ”."
                                qa_pairs.append(
                                    {
                                        "question": default_question,
                                        "answer": message_content,
                                    }
                                )
                                logger.info(
                                    f"S3 QA λ°μ΄ν„°: custom_id μ—†μ, κΈ°λ³Έ μ§λ¬Έ μ‚¬μ©"
                                )

                    # Case 4: Top-level list of QA pairs (less common for JSONL, but possible)
                    elif isinstance(data, list):
                        for item in data:
                            if (
                                isinstance(item, dict)
                                and "question" in item
                                and "answer" in item
                            ):
                                qa_pairs.append(
                                    {
                                        "question": item["question"],
                                        "answer": item["answer"],
                                    }
                                )
                            else:
                                logger.warning(
                                    f"S3 QA λ°μ΄ν„°: λ¦¬μ¤νΈ λ‚΄λ¶€μ— μ ν¨ν•μ§€ μ•μ€ QA μ λ°κ²¬: {item}"
                                )

                    else:
                        logger.warning(
                            f"S3 QA λ°μ΄ν„°: μ• μ μ—†λ” JSON ν•μ‹ λ°κ²¬ (μ¤„ κ±΄λ„λ›°κΈ°): {line.strip()}"
                        )

                except json.JSONDecodeError as e:
                    logger.warning(
                        f"S3 QA λ°μ΄ν„°: JSON νμ‹± μ¤λ¥ (μ¤„ κ±΄λ„λ›°κΈ°): {e} - μ¤„ λ‚΄μ©: {line.strip()}"
                    )
                    continue

            if not qa_pairs:
                logger.error(
                    f"S3μ—μ„ μ ν¨ν• QA λ°μ΄ν„°λ¥Ό μ¶”μ¶ν•μ§€ λ»ν–μµλ‹λ‹¤. μ΄ λΌμΈ μ: {len(content.splitlines())}"
                )
                logger.error(f"S3 URL: {s3_url}")
                logger.error(f"S3 Key: {s3_key}")

                # μ»¨ν…μΈ  μƒν” μ¶λ ¥ (μ²μ 500μ)
                logger.error(f"μ»¨ν…μΈ  μƒν” (500μ): {content[:500]}...")
                return None

            logger.info(f"S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“ λ° νμ‹± μ™„λ£: {len(qa_pairs)}κ°")
            return qa_pairs

        except Exception as e:
            logger.error(f"S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“ μ‹¤ν¨: {e}", exc_info=True)

            # μ²λ¦¬λ QA νμΌμ΄ μ—†λ” κ²½μ° μ›λ³Έ νμΌ μ‹λ„
            if "NoSuchKey" in str(e) and "processed_qa" in s3_url:
                logger.warning("μ²λ¦¬λ QA νμΌμ΄ μ—†μµλ‹λ‹¤. μ›λ³Έ νμΌλ΅ μ‹λ„ν•©λ‹λ‹¤.")

                # URLμ„ μ›λ³Έ νμΌλ΅ λ³€κ²½
                raw_url = s3_url.replace("qa_pairs/", "qa_results/").replace(
                    f'processed_qa_{s3_url.split("_")[-1].replace(".json", "")}.json',
                    "generated_qa_results.jsonl",
                )

                logger.info(f"μ›λ³Έ νμΌ URLλ΅ μ¬μ‹λ„: {raw_url}")

                # μ¬κ·€ νΈμ¶λ΅ μ›λ³Έ νμΌ λ‹¤μ΄λ΅λ“ μ‹λ„
                return self.download_qa_data_from_s3(raw_url)

            return None

    async def prepare_finetuning_data(
        self, qa_data: List[Dict], influencer_data: AIInfluencer, system_prompt: Optional[str] = None
    ) -> tuple[List[Dict], str]:
        """
        νμΈνλ‹μ© λ°μ΄ν„° μ¤€λΉ„
        Args:
            qa_data: QA λ°μ΄ν„°
            influencer_data: AIInfluencer κ°μ²΄
            system_prompt: μ‹μ¤ν… ν”„λ΅¬ν”„νΈ (μ„ νƒμ )
        Returns:
            (νμΈνλ‹μ© λ°μ΄ν„°, μ‹μ¤ν… λ©”μ‹μ§€) νν”
        """
        try:
            # μΈν”λ£¨μ–Έμ„ μ •λ³΄ μ¶”μ¶
            influencer_name = influencer_data.influencer_name
            personality = getattr(
                influencer_data, "influencer_personality", "μΉκ·Όν•κ³  ν™λ°ν• μ„±κ²©"
            )
            style_info = getattr(influencer_data, "influencer_description", "")

            # μ‹μ¤ν… λ©”μ‹μ§€ μ‚¬μ© μ°μ„ μμ„:
            # 1. λ§¤κ°λ³€μλ΅ μ „λ‹¬λ system_prompt
            # 2. influencer_dataμ system_prompt
            # 3. vLLM μ„λ²„μ—μ„ μƒμ„±
            if system_prompt:
                system_message = system_prompt
            elif hasattr(influencer_data, 'system_prompt') and influencer_data.system_prompt:
                system_message = influencer_data.system_prompt
            else:
                # vLLM μ„λ²„μ—μ„ μ‹μ¤ν… λ©”μ‹μ§€ μƒμ„±
                system_message = await create_system_message(
                    influencer_name, personality, style_info
                )

            # QA λ°μ΄ν„° λ³€ν™ (λ°±μ—”λ“μ—μ„ μ§μ ‘ μ²λ¦¬)
            finetuning_data = convert_qa_data_for_finetuning(
                qa_data, influencer_name, personality, style_info
            )

            logger.info(f"νμΈνλ‹ λ°μ΄ν„° μ¤€λΉ„ μ™„λ£: {len(finetuning_data)}κ° ν•­λ©")
            return finetuning_data, system_message

        except Exception as e:
            logger.error(f"νμΈνλ‹ λ°μ΄ν„° μ¤€λΉ„ μ‹¤ν¨: {e}")
            raise

    async def run_finetuning(
        self,
        qa_data: List[Dict],
        system_message: str,
        hf_repo_id: str,
        hf_token: str,
        epochs: int = 5,
        task_id: Optional[str] = None,
        system_prompt: str = "",
        influencer_id: str = ""
    ) -> Optional[str]:
        """
        νμΈνλ‹ μ‹¤ν–‰ (RunPod Serverlessμ— μ‘μ—… μ μ¶)
        Args:
            qa_data: ν›λ ¨ λ°μ΄ν„° (QA μ λ¦¬μ¤νΈ)
            system_message: μ‹μ¤ν… λ©”μ‹μ§€
            hf_repo_id: Hugging Face Repository ID
            hf_token: ν—κΉ…νμ΄μ¤ ν† ν°
            epochs: ν›λ ¨ μ—ν¬ν¬ μ
            task_id: QA μƒμ„± μ‘μ—… ID (μ„ νƒμ )
            system_prompt: μ‹μ¤ν… ν”„λ΅¬ν”„νΈ
            influencer_id: μΈν”λ£¨μ–Έμ„ ID
        Returns:
            RunPod job_id (μ„±κ³µ μ‹), None (μ‹¤ν¨ μ‹)
        """
        try:
            logger.info(f"νμΈνλ‹ μ‹μ‘: {hf_repo_id}")

            # RunPod μ—”λ“ν¬μΈνΈ ν™•μΈ
            endpoint_id = await self.runpod_client.find_or_create_endpoint()
            logger.info(f"π” RunPod μ—”λ“ν¬μΈνΈ ν™•μΈ: {endpoint_id}")

            # RunPod Serverlessλ΅ νμΈνλ‹ μ”μ²­
            logger.info(f"π€ RunPod Serverlessλ΅ νμΈνλ‹ μ”μ²­: {hf_repo_id}")
            
            logger.info(f"π“‹ RunPod νμΈνλ‹ μ”μ²­ νλΌλ―Έν„°:")
            logger.info(f"  - task_id: {task_id or f'ft_{influencer_id}_{int(time.time())}'}")
            logger.info(f"  - qa_data κ°μ: {len(qa_data)}")
            logger.info(f"  - system_message κΈΈμ΄: {len(system_message or system_prompt or '')}")
            logger.info(f"  - hf_repo_id: {hf_repo_id}")
            logger.info(f"  - training_epochs: {epochs}")
            logger.info(f"  - influencer_id: {influencer_id}")
            
            result = await self.runpod_client.start_finetuning(
                task_id=task_id or f"ft_{influencer_id}_{int(time.time())}",
                qa_data=qa_data,
                system_message=system_message or system_prompt,
                hf_token=hf_token,
                hf_repo_id=hf_repo_id,
                training_epochs=epochs,
                influencer_id=influencer_id
            )

            logger.info(f"π“ RunPod μ‘λ‹µ: {result}")
            
            if result.get("success"):
                runpod_job_id = result.get("job_id")
                if runpod_job_id:
                    logger.info(f"β… RunPod νμΈνλ‹ μ‘μ—… μ μ¶ μ™„λ£: job_id={runpod_job_id}")
                    return runpod_job_id
                else:
                    error_msg = f"RunPod μ‘λ‹µμ— job_idκ°€ μ—†μ: {result}"
                    logger.error(error_msg)
                    raise Exception(error_msg)
            else:
                error_msg = f"RunPod νμΈνλ‹ μ‘μ—… μ‹μ‘ μ‹¤ν¨: {result.get('error', 'Unknown error')}"
                logger.error(error_msg)
                raise Exception(error_msg)

        except Exception as e:
            logger.error(f"RunPod νμΈνλ‹ μ‹¤ν–‰ μ¤‘ μ¤λ¥: {e}")
            return None


    async def start_finetuning_task(
        self,
        influencer_id: str,
        qa_task_id: str,
        s3_qa_url: str,
        influencer_data: AIInfluencer,
        db=None,
        task_id: Optional[str] = None,
    ) -> str:
        """
        νμΈνλ‹ μ‘μ—… μ‹μ‘
        Args:
            influencer_id: μΈν”λ£¨μ–΄μ„ ID
            qa_task_id: QA μƒμ„± μ‘μ—… ID
            s3_qa_url: S3 QA λ°μ΄ν„° URL
            influencer_data: μΈν”λ£¨μ–΄μ„ μ •λ³΄ (λ”•μ…”λ„λ¦¬ λλ” λ¨λΈ μΈμ¤ν„΄μ¤)
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
            task_id: QA μƒμ„± μ‘μ—… ID (μ„ νƒμ )
        Returns:
            νμΈνλ‹ μ‘μ—… ID
        """
        import time

        # νμΈνλ‹ μ‘μ—… ID μƒμ„±
        ft_task_id = f"ft_{influencer_id}_{int(time.time())}"

        # μΈν”λ£¨μ–Έμ„ μ΄λ¦„ μ²λ¦¬
        influencer_name = getattr(influencer_data, "influencer_name", "influencer")

        # ν—κΉ…νμ΄μ¤ ν† ν° μ •λ³΄ κ°€μ Έμ¤κΈ°
        try:
            if db:
                _, hf_username = await self._get_hf_info_from_influencer(influencer_data, db)
            else:
                hf_username = "skn-team"
        except Exception as e:
            logger.warning(f"ν—κΉ…νμ΄μ¤ μ‚¬μ©μλ… μ΅°ν μ‹¤ν¨, κΈ°λ³Έκ°’ μ‚¬μ©: {e}")
            hf_username = "skn-team"

        # ν•κΈ€ μ΄λ¦„μ„ μλ¬ΈμΌλ΅ λ³€ν™
        english_name = self._convert_korean_to_english(influencer_name)

        # μΈν”λ£¨μ–Έμ„ λ¨λΈ repo κ²½λ΅ μƒμ„± (ν—κΉ…νμ΄μ¤ μ‚¬μ©μλ…/μλ¬Έμ΄λ¦„-finetuned)
        model_repo = getattr(influencer_data, "influencer_model_repo", "")

        if model_repo:
            # κΈ°μ΅΄ repo κ²½λ΅κ°€ μμΌλ©΄ μ‚¬μ©
            hf_repo_id = model_repo
            safe_name = model_repo.split("/")[-1] if "/" in model_repo else model_repo
        else:
            # μƒλ΅μ΄ repo κ²½λ΅ μƒμ„±
            safe_name = f"EXAONE-{english_name}-finetuned"
            hf_repo_id = f"{hf_username}/{safe_name}"

        logger.info(
            f"νμΈνλ‹ λ¦¬ν¬μ§€ν† λ¦¬ μ„¤μ •: {hf_repo_id} (μ›λ³Έ: {influencer_name} β†’ μλ¬Έ: {english_name})"
        )
        
        # system_prompt κ°€μ Έμ¤κΈ°
        if hasattr(influencer_data, 'system_prompt') and influencer_data.system_prompt:
            system_message = influencer_data.system_prompt
        else:
            system_message = ""
            
        # μ‘μ—… μƒμ„±
        task = FineTuningTask(
            task_id=ft_task_id,
            influencer_id=influencer_id,
            qa_task_id=qa_task_id,
            status=FineTuningStatus.PENDING,
            s3_qa_url=s3_qa_url,
            model_name=safe_name,
            hf_repo_id=hf_repo_id,
            qa_batch_task_id=task_id,
            system_prompt=system_message
        )

        self.tasks[ft_task_id] = task
        logger.info(f"νμΈνλ‹ μ‘μ—… μƒμ„±: {ft_task_id}")

        return ft_task_id

    async def execute_finetuning_task(
        self, task_id: str, influencer_data: AIInfluencer, hf_token: str, db=None
    ) -> bool:
        """
        νμΈνλ‹ μ‘μ—… μ‹¤ν–‰
        Args:
            task_id: μ‘μ—… ID
            influencer_data: μΈν”λ£¨μ–Έμ„ μ •λ³΄
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
        Returns:
            μ„±κ³µ μ—¬λ¶€
        """
        task = self.tasks.get(task_id)
        if not task:
            logger.error(f"νμΈνλ‹ μ‘μ—…μ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {task_id}")
            return False

        try:
            # 1. λ°μ΄ν„° μ¤€λΉ„ λ‹¨κ³„
            task.status = FineTuningStatus.PREPARING_DATA
            task.updated_at = get_current_kst()

            # S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“
            qa_data = self.download_qa_data_from_s3(task.s3_qa_url)
            if not qa_data:
                raise Exception("S3μ—μ„ QA λ°μ΄ν„° λ‹¤μ΄λ΅λ“ μ‹¤ν¨")

            # νμΈνλ‹μ© λ°μ΄ν„° μ¤€λΉ„
            finetuning_qa_data, system_message = await self.prepare_finetuning_data(
                qa_data, influencer_data, task.system_prompt
            )

            # 2. νμΈνλ‹ μ‹¤ν–‰ λ‹¨κ³„
            task.status = FineTuningStatus.TRAINING
            task.updated_at = get_current_kst()

            runpod_job_id = await self.run_finetuning(
                qa_data=finetuning_qa_data,
                system_message=system_message,
                hf_repo_id=task.hf_repo_id,
                hf_token=hf_token,
                epochs=task.training_epochs,
                task_id=task.qa_batch_task_id,
                system_prompt=task.system_prompt or system_message,
                influencer_id=task.influencer_id
            )

            if runpod_job_id:
                # RunPod Serverlessμ— μ‘μ—…μ΄ μ μ¶λ¨
                logger.info(
                    f"νμΈνλ‹ μ‘μ—… μ μ¶λ¨: {task_id} β†’ RunPod job_id: {runpod_job_id}"
                )

                # BatchKey ν…μ΄λΈ”μ— RunPod job_id μ—…λ°μ΄νΈ
                if task.qa_batch_task_id:
                    from app.database import get_db
                    from app.models.influencer import BatchKey

                    try:
                        db_gen = get_db()
                        db = next(db_gen)
                        batch_key = (
                            db.query(BatchKey)
                            .filter(BatchKey.task_id == task.qa_batch_task_id)
                            .first()
                        )
                        if batch_key:
                            batch_key.vllm_task_id = runpod_job_id  # RunPod job_idλ¥Ό μ €μ¥
                            db.commit()
                            logger.info(f"BatchKeyμ— RunPod job_id μ €μ¥: {runpod_job_id}")
                    except Exception as e:
                        logger.error(f"BatchKey μ—…λ°μ΄νΈ μ‹¤ν¨: {e}")
                    finally:
                        db_gen.close()

                return True
            else:
                raise Exception(f"νμΈνλ‹ μ‹¤ν–‰ μ‹¤ν¨: RunPod μ‘μ—… μ μ¶ μ‹¤ν¨")

        except Exception as e:
            task.status = FineTuningStatus.FAILED
            task.error_message = str(e)
            task.updated_at = get_current_kst()
            logger.error(f"νμΈνλ‹ μ‘μ—… μ‹¤ν¨: {task_id}, {e}")
            return False

    def get_task_status(self, task_id: str) -> Optional[FineTuningTask]:
        """νμΈνλ‹ μ‘μ—… μƒνƒ μ΅°ν"""
        return self.tasks.get(task_id)

    def get_all_tasks(self) -> Dict[str, FineTuningTask]:
        """λ¨λ“  νμΈνλ‹ μ‘μ—… μ΅°ν"""
        return self.tasks

    def get_tasks_by_influencer(self, influencer_id: str) -> List[FineTuningTask]:
        """νΉμ • μΈν”λ£¨μ–Έμ„μ νμΈνλ‹ μ‘μ—… μ΅°ν"""
        return [
            task for task in self.tasks.values() if task.influencer_id == influencer_id
        ]

    def is_influencer_finetuned(self, influencer_data, db=None) -> bool:
        """
        μΈν”λ£¨μ–Έμ„κ°€ νμΈνλ‹λμ—λ”μ§€ ν™•μΈ
        Args:
            influencer_data: μΈν”λ£¨μ–Έμ„ λ°μ΄ν„° (λ”•μ…”λ„λ¦¬ λλ” λ¨λΈ μΈμ¤ν„΄μ¤)
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
        Returns:
            νμΈνλ‹ μ™„λ£ μ—¬λ¶€
        """
        try:
            # μΈν”λ£¨μ–Έμ„ ID μ¶”μ¶
            if isinstance(influencer_data, dict):
                influencer_id = influencer_data.get("influencer_id")
                model_repo = influencer_data.get("influencer_model_repo", "")
            else:
                influencer_id = getattr(influencer_data, "influencer_id", None)
                model_repo = getattr(influencer_data, "influencer_model_repo", "")

            if not influencer_id:
                return False

            # 1. λ¨λΈ repoκ°€ μ„¤μ •λμ–΄ μλ”μ§€ ν™•μΈ
            if model_repo and model_repo.strip():
                logger.info(
                    f"μΈν”λ£¨μ–Έμ„ {influencer_id}μ— λ¨λΈ repoκ°€ μ„¤μ •λ¨: {model_repo}"
                )
                return True

            # 2. μ™„λ£λ νμΈνλ‹ μ‘μ—…μ΄ μλ”μ§€ ν™•μΈ
            completed_tasks = [
                task
                for task in self.tasks.values()
                if (
                    task.influencer_id == influencer_id
                    and task.status == FineTuningStatus.COMPLETED
                )
            ]

            if completed_tasks:
                logger.info(
                    f"μΈν”λ£¨μ–Έμ„ {influencer_id}μ— μ™„λ£λ νμΈνλ‹ μ‘μ—… λ°κ²¬: {len(completed_tasks)}κ°"
                )
                return True

            # 3. λ°μ΄ν„°λ² μ΄μ¤μ—μ„ μ™„λ£λ νμΈνλ‹ κΈ°λ΅ ν™•μΈ
            if db:
                from app.models.influencer import BatchKey as BatchJob

                completed_finetuning = (
                    db.query(BatchJob)
                    .filter(
                        BatchJob.influencer_id == influencer_id,
                        BatchJob.is_finetuning_started == True,
                        BatchJob.status == "completed",
                    )
                    .first()
                )

                if completed_finetuning:
                    logger.info(
                        f"μΈν”λ£¨μ–Έμ„ {influencer_id}μ— λ°μ΄ν„°λ² μ΄μ¤μ—μ„ μ™„λ£λ νμΈνλ‹ λ°κ²¬"
                    )
                    return True

            logger.info(f"μΈν”λ£¨μ–Έμ„ {influencer_id}λ” μ•„μ§ νμΈνλ‹λμ§€ μ•μ")
            return False

        except Exception as e:
            logger.error(f"νμΈνλ‹ μƒνƒ ν™•μΈ μ¤‘ μ¤λ¥: {e}")
            return False

    async def start_finetuning_for_influencer(
        self, influencer_id: str, s3_qa_file_url: str, db, task_id: Optional[str] = None
    ) -> bool:
        """
        μΈν”λ£¨μ–Έμ„λ¥Ό μ„ν• νμΈνλ‹ μ‹μ‘ (startup serviceμ©)
        Args:
            influencer_id: μΈν”λ£¨μ–Έμ„ ID
            s3_qa_file_url: S3 QA νμΌ URL
            db: λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ…
            task_id: QA μƒμ„± μ‘μ—… ID (μ„ νƒμ )
        Returns:
            μ„±κ³µ μ—¬λ¶€
        """
        try:
            # μΈν”λ£¨μ–Έμ„ μ •λ³΄ κ°€μ Έμ¤κΈ° (μ‹μ¤ν… μ‘μ—…μ΄λ―€λ΅ κ¶ν• μ²΄ν¬ μ—†μ΄ μ§μ ‘ μ΅°ν)
            from app.models.influencer import AIInfluencer
            
            influencer_data = (
                db.query(AIInfluencer)
                .filter(AIInfluencer.influencer_id == influencer_id)
                .first()
            )

            if not influencer_data:
                logger.error(f"μΈν”λ£¨μ–Έμ„λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {influencer_id}")
                return False

            # ν—κΉ…νμ΄μ¤ ν† ν° μ •λ³΄ κ°€μ Έμ¤κΈ°
            hf_token, hf_username = await self._get_hf_info_from_influencer(
                influencer_data, db
            )

            # νμΈνλ‹ μ‘μ—… μ‹μ‘ (λ¨λΈ μΈμ¤ν„΄μ¤ μ§μ ‘ μ‚¬μ©)
            logger.info(f"π“ νμΈνλ‹ μ‘μ—… μ‹μ‘ μ¤‘...")
            logger.info(f"  - influencer_id: {influencer_id}")
            logger.info(f"  - s3_qa_file_url: {s3_qa_file_url}")
            logger.info(f"  - task_id: {task_id}")
            logger.info(f"  - hf_token μ΅΄μ¬: {'Yes' if hf_token else 'No'}")
            logger.info(f"  - hf_username: {hf_username}")
            
            ft_task_id = await self.start_finetuning_task(
                influencer_id=influencer_id,
                qa_task_id=f"startup_restart_{influencer_id}",
                s3_qa_url=s3_qa_file_url,
                influencer_data=influencer_data,  # λ¨λΈ μΈμ¤ν„΄μ¤ μ§μ ‘ μ „λ‹¬
                db=db,
                task_id=task_id
            )
            
            logger.info(f"π“ νμΈνλ‹ μ‘μ—… ID μƒμ„±λ¨: {ft_task_id}")

            # νμΈνλ‹ μ‹¤ν–‰
            logger.info(f"π€ νμΈνλ‹ μ‹¤ν–‰ μ‹μ‘...")
            success = await self.execute_finetuning_task(
                ft_task_id, influencer_data, hf_token, db
            )
            
            logger.info(f"π“ νμΈνλ‹ μ‹¤ν–‰ κ²°κ³Ό: {'μ„±κ³µ' if success else 'μ‹¤ν¨'}")

            if success:
                logger.info(f"β… μΈν”λ£¨μ–Έμ„ νμΈνλ‹ μλ™ μ‹μ‘ μ„±κ³µ: {influencer_id}")
            else:
                logger.error(f"β μΈν”λ£¨μ–Έμ„ νμΈνλ‹ μλ™ μ‹μ‘ μ‹¤ν¨: {influencer_id}")

            return success

        except Exception as e:
            logger.error(
                f"β μΈν”λ£¨μ–Έμ„ νμΈνλ‹ μ‹μ‘ μ¤‘ μ¤λ¥: {influencer_id}, {str(e)}"
            )
            return False


# μ „μ—­ νμΈνλ‹ μ„λΉ„μ¤ μΈμ¤ν„΄μ¤
finetuning_service = InfluencerFineTuningService()


def get_finetuning_service() -> InfluencerFineTuningService:
    """νμΈνλ‹ μ„λΉ„μ¤ μμ΅΄μ„± μ£Όμ…μ© ν•¨μ"""
    return finetuning_service
