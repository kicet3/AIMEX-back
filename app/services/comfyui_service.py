"""
ComfyUI API ì„œë¹„ìŠ¤

SOLID ì›ì¹™:
- SRP: ComfyUI API ì—°ë™ ë° ì´ë¯¸ì§€ ìƒì„±ë§Œ ë‹´ë‹¹
- OCP: ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì´ë‚˜ ì›Œí¬í”Œë¡œìš° ì¶”ê°€ ì‹œ í™•ì¥ ê°€ëŠ¥
- LSP: ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ ë‹¤ë¥¸ ì´ë¯¸ì§€ ìƒì„± ì„œë¹„ìŠ¤ë¡œ êµì²´ ê°€ëŠ¥
- ISP: í´ë¼ì´ì–¸íŠ¸ë³„ ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬
- DIP: êµ¬ì²´ì ì¸ ComfyUI êµ¬í˜„ì´ ì•„ë‹Œ ì¶”ìƒí™”ì— ì˜ì¡´

Clean Architecture:
- Domain Layer: ì´ë¯¸ì§€ ìƒì„± ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
- Infrastructure Layer: ì™¸ë¶€ ComfyUI API ì—°ë™
"""

import asyncio
import json
import uuid
import requests
from typing import Dict, List, Optional, Any, Callable
from abc import ABC, abstractmethod
from pydantic import BaseModel
import logging
from urllib.parse import urlparse
from .workflow_manager import get_workflow_manager, WorkflowInput
from .workflow_config import get_workflow_config
from .runpod_adapter import get_runpod_adapter

logger = logging.getLogger(__name__)


# ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ì •ì˜ (Clean Architecture - Domain Layer)
class ImageGenerationRequest(BaseModel):
    """ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ëª¨ë¸"""
    prompt: str
    negative_prompt: Optional[str] = "low quality, blurry, distorted"
    width: int = 1024
    height: int = 1024
    steps: int = 20
    cfg_scale: float = 7.0
    seed: Optional[int] = None
    style: str = "realistic"
    workflow_id: Optional[str] = None  # ì‚¬ìš©í•  ì›Œí¬í”Œë¡œìš° ID (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    custom_parameters: Optional[Dict[str, Any]] = None  # ì¶”ê°€ ì»¤ìŠ¤í…€ íŒŒë¼ë¯¸í„°
    user_id: Optional[str] = None  # ì‚¬ìš©ì ID (ê°œì¸í™”ëœ ì›Œí¬í”Œë¡œìš° ì„ íƒìš©)
    use_runpod: bool = False  # RunPod ì‚¬ìš© ì—¬ë¶€


class ImageGenerationResponse(BaseModel):
    """ì´ë¯¸ì§€ ìƒì„± ì‘ë‹µ ëª¨ë¸"""
    job_id: str
    status: str  # "queued", "processing", "completed", "failed"
    images: List[str] = []  # Base64 ì´ë¯¸ì§€ ë˜ëŠ” URL ë¦¬ìŠ¤íŠ¸
    prompt_used: str
    generation_time: Optional[float] = None
    metadata: Dict[str, Any] = {}


# ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤ (SOLID - DIP ì›ì¹™)
class ImageGeneratorInterface(ABC):
    """ì´ë¯¸ì§€ ìƒì„± ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    async def generate_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """ì´ë¯¸ì§€ ìƒì„±"""
        pass
    
    @abstractmethod
    async def get_generation_status(self, job_id: str) -> ImageGenerationResponse:
        """ìƒì„± ìƒíƒœ ì¡°íšŒ"""
        pass


class ComfyUIService(ImageGeneratorInterface):
    """
    ComfyUI API ì„œë¹„ìŠ¤ êµ¬í˜„
    
    SOLID ì›ì¹™ ì¤€ìˆ˜:
    - SRP: ComfyUI API í˜¸ì¶œê³¼ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ë§Œ ë‹´ë‹¹
    - OCP: ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ì¶”ê°€ ì‹œ í™•ì¥ ê°€ëŠ¥
    """
    
    def __init__(self, comfyui_server_url: str = "http://127.0.0.1:8188", runpod_endpoint: str = None):
        self.server_url = comfyui_server_url
        self.runpod_endpoint = runpod_endpoint
        self.client_id = str(uuid.uuid4())
        self.use_mock = True  # ê¸°ë³¸ì ìœ¼ë¡œ Mock ëª¨ë“œ (ComfyUI ì„œë²„ ì—†ì„ ë•Œ)
        
        # ComfyUI ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
        self._test_connection()
        
        # RunPod ì–´ëŒ‘í„° ì´ˆê¸°í™”
        if runpod_endpoint:
            self.runpod_adapter = get_runpod_adapter(runpod_endpoint)
        else:
            self.runpod_adapter = get_runpod_adapter()
        
        logger.info(f"ComfyUI Service initialized (Server: {self.server_url}, RunPod: {runpod_endpoint}, Mock mode: {self.use_mock})")
    
    def _test_connection(self):
        """ComfyUI ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.get(f"{self.server_url}/system_stats", timeout=5)
            if response.status_code == 200:
                self.use_mock = False
                logger.info("ComfyUI server connection successful")
            else:
                logger.warning(f"ComfyUI server responded with status {response.status_code}")
        except requests.exceptions.RequestException as e:
            logger.warning(f"ComfyUI server not available: {e}")
            self.use_mock = True
    
    async def generate_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """
        ì´ë¯¸ì§€ ìƒì„±
        
        Clean Architecture: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ì™¸ë¶€ ì„œë¹„ìŠ¤ ë¶„ë¦¬
        """
        try:
            # RunPod ìš”ì²­ì´ê±°ë‚˜ ë¡œì»¬ ì„œë²„ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì‹¤ì œ ìƒì„±
            if request.use_runpod or not self.use_mock:
                return await self._generate_real_image(request)
            else:
                return await self._generate_mock_image(request)
        except Exception as e:
            logger.error(f"Image generation failed: {e}")
            # RunPod ìš”ì²­ ì‹¤íŒ¨ ì‹œì—ë„ ì˜¤ë¥˜ ë°˜í™˜ (Mockìœ¼ë¡œ í´ë°±í•˜ì§€ ì•ŠìŒ)
            if request.use_runpod:
                return ImageGenerationResponse(
                    job_id=str(uuid.uuid4()),
                    status="failed",
                    images=[],
                    prompt_used=request.prompt,
                    metadata={"error": str(e), "runpod_failed": True}
                )
            # ë¡œì»¬ ì„œë²„ ì‹¤íŒ¨ ì‹œë§Œ Mockìœ¼ë¡œ í´ë°±
            return await self._generate_mock_image(request)
    
    async def get_generation_status(self, job_id: str) -> ImageGenerationResponse:
        """ìƒì„± ìƒíƒœ ì¡°íšŒ"""
        if self.use_mock:
            return await self._get_mock_status(job_id)
        else:
            return await self._get_real_status(job_id)
    
    async def _generate_real_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """ì‹¤ì œ ComfyUI API í˜¸ì¶œ (RunPod ì§€ì›)"""
        
        job_id = str(uuid.uuid4())
        runpod_pod_id = None
        
        try:
            # ComfyUI ì›Œí¬í”Œë¡œìš° JSON ìƒì„± (ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ì‚¬ìš©)
            workflow = await self._create_custom_workflow(request)
            
            # RunPod ì‚¬ìš© ì‹œ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ í™œìš© ë˜ëŠ” ìƒˆë¡œ ìƒì„±
            if request.use_runpod:
                from app.core.config import settings
                
                # ê¸°ì¡´ ì‹¤í–‰ ì¤‘ì¸ Podê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  í™œìš© (ê±´ê°• ì²´í¬ í¬í•¨)
                use_existing = False
                if hasattr(settings, 'RUNPOD_EXISTING_ENDPOINT') and settings.RUNPOD_EXISTING_ENDPOINT:
                    target_url = settings.RUNPOD_EXISTING_ENDPOINT
                    runpod_pod_id = getattr(settings, 'RUNPOD_EXISTING_POD_ID', 'existing-pod')
                    
                    # ê¸°ì¡´ Pod ê±´ê°• ì²´í¬
                    try:
                        health_response = requests.get(f"{target_url}/system_stats", timeout=10)
                        if health_response.status_code == 200:
                            logger.info(f"Using existing RunPod instance: {target_url}")
                            use_existing = True
                        else:
                            logger.warning(f"Existing RunPod instance unhealthy, creating new one")
                    except Exception as e:
                        logger.warning(f"Failed to check existing RunPod health: {e}, creating new one")
                
                if not use_existing:
                    # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                    logger.info(f"Creating new RunPod instance for job {job_id}")
                    
                    from .runpod_service import get_runpod_service
                    runpod_service = get_runpod_service()
                    
                    pod_response = await runpod_service.create_pod(job_id)
                    runpod_pod_id = pod_response.pod_id
                    
                    
                    if pod_response.status != "RUNNING":
                        logger.info(f"Waiting for RunPod instance {runpod_pod_id} to start...")
                        await self._wait_for_pod_ready(runpod_service, runpod_pod_id)
                    
                    target_url = pod_response.endpoint_url
                    if not target_url:
                        logger.info(f"Waiting for RunPod instance {runpod_pod_id} endpoint to be ready...")
                        # Podê°€ ì™„ì „íˆ ì‹œì‘ë  ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ê³  ì—”ë“œí¬ì¸íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        max_attempts = 30
                        for attempt in range(max_attempts):
                            await asyncio.sleep(10)  # 10ì´ˆ ëŒ€ê¸°
                            pod_info = await runpod_service.get_pod_status(runpod_pod_id)
                            if pod_info.endpoint_url:
                                target_url = pod_info.endpoint_url
                                logger.info(f"RunPod endpoint ready: {target_url}")
                                break
                            logger.info(f"Attempt {attempt+1}/{max_attempts}: Waiting for endpoint...")
                        
                        if not target_url:
                            raise RuntimeError(f"RunPod instance {runpod_pod_id} endpoint not available after {max_attempts} attempts")
                    
                    logger.info(f"New RunPod instance ready: {target_url}")
                    
                    # ComfyUI ì„œë²„ê°€ ì™„ì „íˆ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
                    await self._wait_for_comfyui_ready(target_url)
                    
            else:
                target_url = self.server_url
                logger.info(f"Using local ComfyUI server: {target_url}")
            
            # ComfyUI ì„œë²„ì— ì›Œí¬í”Œë¡œìš° ì „ì†¡
            logger.info(f"Sending workflow to ComfyUI server: {target_url}/prompt")
            queue_response = requests.post(
                f"{target_url}/prompt",
                json={
                    "prompt": workflow,
                    "client_id": self.client_id
                },
                timeout=60  # RunPod í™˜ê²½ì—ì„œëŠ” ë” ê¸´ íƒ€ì„ì•„ì›ƒ í•„ìš”
            )
            
            if queue_response.status_code != 200:
                raise Exception(f"Failed to queue workflow: {queue_response.text}")
            
            queue_data = queue_response.json()
            prompt_id = queue_data.get("prompt_id")
            
            logger.info(f"Workflow queued with prompt_id: {prompt_id}")
            
            # ìƒì„± ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
            result = await self._wait_for_completion(prompt_id)
            
            # RunPod ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬ (ì‚¬ìš© í›„ ì¢…ë£Œ)
            if request.use_runpod and runpod_pod_id:
                logger.info(f"Terminating RunPod instance {runpod_pod_id}")
                try:
                    await runpod_service.terminate_pod(runpod_pod_id)
                except Exception as cleanup_error:
                    logger.warning(f"Failed to cleanup RunPod instance: {cleanup_error}")
            
            return ImageGenerationResponse(
                job_id=job_id,
                status="completed",
                images=result.get("images", []),
                prompt_used=request.prompt,
                generation_time=result.get("generation_time"),
                metadata={
                    "prompt_id": prompt_id,
                    "comfyui_server": target_url,
                    "runpod_pod_id": runpod_pod_id,
                    "workflow_type": "custom",
                    "settings": request.dict()
                }
            )
            
        except Exception as e:
            logger.error(f"Image generation failed: {e}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ RunPod ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬
            if request.use_runpod and runpod_pod_id:
                try:
                    from .runpod_service import get_runpod_service
                    runpod_service = get_runpod_service()
                    await runpod_service.terminate_pod(runpod_pod_id)
                    logger.info(f"Cleaned up RunPod instance {runpod_pod_id} after error")
                except Exception as cleanup_error:
                    logger.warning(f"Failed to cleanup RunPod instance after error: {cleanup_error}")
            
            return ImageGenerationResponse(
                job_id=job_id,
                status="failed",
                images=[],
                prompt_used=request.prompt,
                metadata={
                    "error": str(e),
                    "runpod_pod_id": runpod_pod_id,
                    "use_runpod": request.use_runpod
                }
            )
    
    async def _generate_mock_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """Mock ì´ë¯¸ì§€ ìƒì„± (ComfyUI ì„œë²„ ì—†ì„ ë•Œ)"""
        
        # ì‹œë®¬ë ˆì´ì…˜ ì§€ì—°
        await asyncio.sleep(2)
        
        job_id = str(uuid.uuid4())
        
        # Mock ì´ë¯¸ì§€ URL (ì‹¤ì œë¡œëŠ” ìƒì„±ëœ ì´ë¯¸ì§€)
        mock_images = [
            "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==",  # 1x1 í”½ì…€ ì´ë¯¸ì§€
        ]
        
        return ImageGenerationResponse(
            job_id=job_id,
            status="completed",
            images=mock_images,
            prompt_used=request.prompt,
            generation_time=2.0,
            metadata={
                "note": "Mock image generation - ì‹¤ì œ ComfyUI ì„œë²„ ì—°ê²° ì‹œ ì‹¤ì œ ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤",
                "mock_data": True,
                "prompt": request.prompt,
                "settings": request.dict()
            }
        )
    
    async def _get_mock_status(self, job_id: str) -> ImageGenerationResponse:
        """Mock ìƒíƒœ ì¡°íšŒ"""
        return ImageGenerationResponse(
            job_id=job_id,
            status="completed",
            images=["mock_image_url"],
            prompt_used="mock prompt",
            metadata={"mock_data": True}
        )
    
    async def _get_real_status(self, job_id: str) -> ImageGenerationResponse:
        """ì‹¤ì œ ìƒíƒœ ì¡°íšŒ"""
        # ì‹¤ì œ ComfyUI ìƒíƒœ ì¡°íšŒ ë¡œì§
        # êµ¬í˜„ í•„ìš”
        pass
    
    async def _create_custom_workflow(self, request: ImageGenerationRequest) -> Dict[str, Any]:
        """
        ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì›Œí¬í”Œë¡œìš° JSON ìƒì„±
        """
        try:
            workflow_manager = get_workflow_manager()
            workflow_config = get_workflow_config()
            
            # ì›Œí¬í”Œë¡œìš° ID ê²°ì • (ì‚¬ìš©ì ì„¤ì • â†’ ìš”ì²­ â†’ ê¸°ë³¸ê°’ ìˆœ)
            logger.info(f"ğŸ” ìš”ì²­ëœ workflow_id: {request.workflow_id}")
            workflow_id = request.workflow_id
            if not workflow_id:
                workflow_id = workflow_config.get_effective_workflow_id(request.user_id)
                logger.info(f"ğŸ”„ ê¸°ë³¸ workflow_idë¡œ ë³€ê²½: {workflow_id}")
            
            logger.info(f"Using workflow: {workflow_id} for user: {request.user_id}")
            
            # ìš”ì²­ íŒŒë¼ë¯¸í„° ì¤€ë¹„
            parameters = {
                "prompt": request.prompt,
                "negative_prompt": request.negative_prompt,
                "width": request.width,
                "height": request.height,
                "steps": request.steps,
                "cfg_scale": request.cfg_scale,
                "seed": request.seed if request.seed is not None and request.seed >= 0 else __import__('random').randint(0, 2**32-1)
            }
            
            # ì»¤ìŠ¤í…€ íŒŒë¼ë¯¸í„° ì¶”ê°€
            if request.custom_parameters:
                parameters.update(request.custom_parameters)
            
            # ì›Œí¬í”Œë¡œìš° ì…ë ¥ ìƒì„±
            workflow_input = WorkflowInput(
                workflow_id=workflow_id,
                parameters=parameters
            )
            
            # ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš° ìƒì„± (í´ë°± ì²˜ë¦¬ í¬í•¨)
            try:
                workflow = await workflow_manager.generate_executable_workflow(workflow_input)
            except ValueError as e:
                if "Workflow not found" in str(e) and workflow_id == "custom_workflow":
                    # custom_workflowê°€ ì—†ìœ¼ë©´ basic_txt2imgë¡œ í´ë°±
                    logger.warning(f"custom_workflow not found, falling back to basic_txt2img")
                    workflow_input.workflow_id = "basic_txt2img"
                    workflow = await workflow_manager.generate_executable_workflow(workflow_input)
                    workflow_id = "basic_txt2img"  # ë¡œê·¸ìš©
                else:
                    raise
            
            # RunPod ì‚¬ìš© ì‹œ ì›Œí¬í”Œë¡œìš° ì ì‘
            if request.use_runpod and self.runpod_adapter:
                adapted_workflow, warnings = self.runpod_adapter.adapt_workflow_for_runpod(workflow)
                workflow = adapted_workflow
                
                if warnings:
                    logger.warning(f"RunPod adaptations: {warnings}")
            
            logger.info(f"Generated custom workflow: {workflow_id}")
            return workflow
            
        except Exception as e:
            logger.error(f"Failed to create custom workflow: {e}")
            # í´ë°±ìœ¼ë¡œ ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ì‚¬ìš©
            return self._create_default_workflow(request)
    
    def _create_default_workflow(self, request: ImageGenerationRequest) -> Dict[str, Any]:
        """
        ComfyUI ì›Œí¬í”Œë¡œìš° JSON ìƒì„±
        
        ê¸°ë³¸ì ì¸ txt2img ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿
        """
        
        # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ (Stable Diffusion ê¸°ì¤€)
        workflow = {
            "3": {
                "inputs": {
                    "seed": request.seed if request.seed is not None and request.seed >= 0 else __import__('random').randint(0, 2**32-1),
                    "steps": request.steps,
                    "cfg": request.cfg_scale,
                    "sampler_name": "euler",
                    "scheduler": "normal",
                    "denoise": 1,
                    "model": ["4", 0],
                    "positive": ["6", 0],
                    "negative": ["7", 0],
                    "latent_image": ["5", 0]
                },
                "class_type": "KSampler"
            },
            "4": {
                "inputs": {
                    "ckpt_name": "sd_xl_base_1.0.safetensors"  # ê¸°ë³¸ ëª¨ë¸
                },
                "class_type": "CheckpointLoaderSimple"
            },
            "5": {
                "inputs": {
                    "width": request.width,
                    "height": request.height,
                    "batch_size": 1
                },
                "class_type": "EmptyLatentImage"
            },
            "6": {
                "inputs": {
                    "text": request.prompt,
                    "clip": ["4", 1]
                },
                "class_type": "CLIPTextEncode"
            },
            "7": {
                "inputs": {
                    "text": request.negative_prompt or "low quality, blurry",
                    "clip": ["4", 1]
                },
                "class_type": "CLIPTextEncode"
            },
            "8": {
                "inputs": {
                    "samples": ["3", 0],
                    "vae": ["4", 2]
                },
                "class_type": "VAEDecode"
            },
            "9": {
                "inputs": {
                    "filename_prefix": "ComfyUI",
                    "images": ["8", 0]
                },
                "class_type": "SaveImage"
            }
        }
        
        return workflow
    
    async def _wait_for_completion(self, prompt_id: str, timeout: int = 300) -> Dict[str, Any]:
        """
        ComfyUI ìƒì„± ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        
        WebSocket ë˜ëŠ” í´ë§ì„ í†µí•´ ìƒíƒœ í™•ì¸
        """
        
        # WebSocket ì—°ê²°ë¡œ ì‹¤ì‹œê°„ ìƒíƒœ í™•ì¸
        try:
            ws_url = f"ws://127.0.0.1:8188/ws?clientId={self.client_id}"
            
            # ê°„ë‹¨í•œ í´ë§ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ (WebSocket êµ¬í˜„ì€ ë³µì¡í•¨)
            for _ in range(timeout):
                await asyncio.sleep(1)
                
                # íˆìŠ¤í† ë¦¬ í™•ì¸
                history_response = requests.get(f"{self.server_url}/history/{prompt_id}")
                if history_response.status_code == 200:
                    history_data = history_response.json()
                    if prompt_id in history_data:
                        # ì™„ë£Œëœ ê²½ìš° ì´ë¯¸ì§€ URL ì¶”ì¶œ
                        result = history_data[prompt_id]
                        images = self._extract_images_from_history(result)
                        return {
                            "images": images,
                            "generation_time": 1.0  # ì‹¤ì œ ì‹œê°„ ê³„ì‚° í•„ìš”
                        }
            
            # íƒ€ì„ì•„ì›ƒ
            raise Exception(f"Generation timeout after {timeout} seconds")
            
        except Exception as e:
            logger.error(f"Failed to wait for completion: {e}")
            raise
    
    def _extract_images_from_history(self, history_data: Dict[str, Any]) -> List[str]:
        """íˆìŠ¤í† ë¦¬ ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
        
        images = []
        
        try:
            outputs = history_data.get("outputs", {})
            for node_id, node_output in outputs.items():
                if "images" in node_output:
                    for image_info in node_output["images"]:
                        filename = image_info.get("filename")
                        if filename:
                            # ComfyUI ì„œë²„ì˜ ì´ë¯¸ì§€ URL ìƒì„±
                            image_url = f"{self.server_url}/view?filename={filename}"
                            images.append(image_url)
        
        except Exception as e:
            logger.error(f"Failed to extract images: {e}")
        
        return images
    
    async def _wait_for_pod_ready(self, runpod_service, pod_id: str, max_wait_time: int = 300):
        """RunPod ì¸ìŠ¤í„´ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
        import time
        start_time = time.time()
        
        while time.time() - start_time < max_wait_time:
            try:
                pod_status = await runpod_service.get_pod_status(pod_id)
                if pod_status.status == "RUNNING" and pod_status.endpoint_url:
                    logger.info(f"RunPod instance {pod_id} is ready")
                    return
                
                logger.info(f"Waiting for RunPod instance {pod_id} (status: {pod_status.status})")
                await asyncio.sleep(10)  # 10ì´ˆ ëŒ€ê¸°
                
            except Exception as e:
                logger.warning(f"Error checking RunPod status: {e}")
                await asyncio.sleep(5)
        
        raise Exception(f"RunPod instance {pod_id} did not become ready within {max_wait_time} seconds")
    
    async def _wait_for_comfyui_ready(self, comfyui_url: str, max_wait_time: int = 240):
        """ComfyUI ì„œë²„ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
        logger.info(f"Waiting for ComfyUI server to be ready at {comfyui_url}")
        import time
        start_time = time.time()
        
        # ë‹¤ì–‘í•œ ì—”ë“œí¬ì¸íŠ¸ë¡œ ìƒíƒœ í™•ì¸
        check_endpoints = ["/system_stats", "/queue", "/history"]
        
        while time.time() - start_time < max_wait_time:
            try:
                # ì—¬ëŸ¬ ì—”ë“œí¬ì¸íŠ¸ ì¤‘ í•˜ë‚˜ë¼ë„ ì‘ë‹µí•˜ë©´ ì¤€ë¹„ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                for endpoint in check_endpoints:
                    try:
                        logger.debug(f"Checking {comfyui_url}{endpoint}")
                        response = requests.get(f"{comfyui_url}{endpoint}", timeout=15)
                        logger.debug(f"Response: {response.status_code}")
                        if response.status_code == 200:
                            logger.info(f"ComfyUI server is ready at {comfyui_url} (checked via {endpoint})")
                            return True
                    except requests.RequestException as e:
                        logger.debug(f"Endpoint {endpoint} failed: {e}")
                        continue
                
            except Exception as e:
                logger.debug(f"ComfyUI health check error: {e}")
            
            elapsed = time.time() - start_time
            logger.info(f"Waiting for ComfyUI server... ({elapsed:.0f}s elapsed)")
            logger.info(f"Checking URL: {comfyui_url}")
            await asyncio.sleep(20)  # 20ì´ˆë§ˆë‹¤ í™•ì¸
        
        raise TimeoutError(f"ComfyUI server at {comfyui_url} did not become ready within {max_wait_time} seconds")


# ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_comfyui_service_instance = None

def get_comfyui_service() -> ComfyUIService:
    """ComfyUI ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _comfyui_service_instance
    if _comfyui_service_instance is None:
        _comfyui_service_instance = ComfyUIService()
    return _comfyui_service_instance
