"""
ComfyUI API ì„œë¹„ìŠ¤

SOLID ì›ì¹™:
- SRP: ComfyUI API ì—°ë™ ë° ì´ë¯¸ì§€ ìƒì„±ë§Œ ë‹´ë‹¹
- OCP: ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì´ë‚˜ ì›Œí¬í”Œë¡œìš° ì¶”ê°€ ì‹œ í™•ì¥ ê°€ëŠ¥
- LSP: ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ ë‹¤ë¥¸ ì´ë¯¸ì§€ ìƒì„± ì„œë¹„ìŠ¤ë¡œ êµì²´ ê°€ëŠ¥
- ISP: í´ë¼ì´ì–¸íŠ¸ë³„ ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬
- DIP: êµ¬ì²´ì ì¸ ComfyUI êµ¬í˜„ì´ ì•„ë‹Œ ì¶”ìƒí™”ì— ì˜ì¡´

Clean Architecture:
- Domain Layer: ì´ë¯¸ì§€ ìƒì„± ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
- Infrastructure Layer: ì™¸ë¶€ ComfyUI API ì—°ë™
"""

import asyncio
import json
import uuid
import requests
from typing import Dict, List, Optional, Any, Callable
from abc import ABC, abstractmethod
from pydantic import BaseModel
import logging
from urllib.parse import urlparse
from .workflow_manager import get_workflow_manager, WorkflowInput
from .workflow_config import get_workflow_config
from .runpod_adapter import get_runpod_adapter

logger = logging.getLogger(__name__)


# ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ì •ì˜ (Clean Architecture - Domain Layer)
class ImageGenerationRequest(BaseModel):
    """ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ëª¨ë¸"""
    prompt: str
    negative_prompt: Optional[str] = "low quality, blurry, distorted"
    width: int = 1024
    height: int = 1024
    steps: int = 20
    cfg_scale: float = 7.0
    seed: Optional[int] = None
    style: str = "realistic"
    workflow_id: Optional[str] = None  # ì‚¬ìš©í•  ì›Œí¬í”Œë¡œìš° ID (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    custom_parameters: Optional[Dict[str, Any]] = None  # ì¶”ê°€ ì»¤ìŠ¤í…€ íŒŒë¼ë¯¸í„°
    user_id: Optional[str] = None  # ì‚¬ìš©ì ID (ê°œì¸í™”ëœ ì›Œí¬í”Œë¡œìš° ì„ íƒìš©)
    use_runpod: bool = False  # RunPod ì‚¬ìš© ì—¬ë¶€
    pod_id: Optional[str] = None  # RunPod pod_idë¥¼ bodyì—ì„œ ìë™ ë§¤í•‘


class ImageGenerationResponse(BaseModel):
    """ì´ë¯¸ì§€ ìƒì„± ì‘ë‹µ ëª¨ë¸"""
    job_id: str
    status: str  # "queued", "processing", "completed", "failed"
    images: List[str] = []  # Base64 ì´ë¯¸ì§€ ë˜ëŠ” URL ë¦¬ìŠ¤íŠ¸
    prompt_used: str
    generation_time: Optional[float] = None
    metadata: Dict[str, Any] = {}


# ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤ (SOLID - DIP ì›ì¹™)
class ImageGeneratorInterface(ABC):
    """ì´ë¯¸ì§€ ìƒì„± ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    async def generate_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """ì´ë¯¸ì§€ ìƒì„±"""
        pass
    
    @abstractmethod
    async def get_generation_status(self, job_id: str) -> ImageGenerationResponse:
        """ìƒì„± ìƒíƒœ ì¡°íšŒ"""
        pass


class ComfyUIService(ImageGeneratorInterface):
    """
    ComfyUI API ì„œë¹„ìŠ¤ êµ¬í˜„
    
    SOLID ì›ì¹™ ì¤€ìˆ˜:
    - SRP: ComfyUI API í˜¸ì¶œê³¼ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ë§Œ ë‹´ë‹¹
    - OCP: ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ ì¶”ê°€ ì‹œ í™•ì¥ ê°€ëŠ¥
    """
    
    def __init__(self, comfyui_server_url: str = "http://127.0.0.1:8188", runpod_endpoint: str = None):
        self.server_url = comfyui_server_url
        self.runpod_endpoint = runpod_endpoint
        self.client_id = str(uuid.uuid4())
        self.use_mock = False  # Mock ëª¨ë“œ ë¹„í™œì„±í™” (ì‹¤ì œ ì„œë¹„ìŠ¤ë§Œ êµ¬í˜„)
        
        # ComfyUI ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
        self._test_connection()
        
        # RunPod ì–´ëŒ‘í„° ì´ˆê¸°í™”
        if runpod_endpoint:
            self.runpod_adapter = get_runpod_adapter(runpod_endpoint)
        else:
            self.runpod_adapter = get_runpod_adapter()
        
        logger.info(f"ComfyUI Service initialized (Server: {self.server_url}, RunPod: {runpod_endpoint}, Mock mode: {self.use_mock})")
    
    def _test_connection(self):
        """ComfyUI ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.get(f"{self.server_url}/system_stats", timeout=5)
            if response.status_code == 200:
                logger.info("ComfyUI server connection successful")
            else:
                logger.warning(f"ComfyUI server responded with status {response.status_code}")
        except requests.exceptions.RequestException as e:
            logger.warning(f"ComfyUI server not available: {e}")
            # Mock ëª¨ë“œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - ì‹¤ì œ RunPod ì„œë¹„ìŠ¤ë§Œ ì‚¬ìš©
    
    async def generate_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """
        ì´ë¯¸ì§€ ìƒì„±
        
        Clean Architecture: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ì™¸ë¶€ ì„œë¹„ìŠ¤ ë¶„ë¦¬
        """
        try:
            # ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„±ë§Œ ìˆ˜í–‰ (Mock ëª¨ë“œ ì œê±°)
            return await self._generate_real_image(request)
        except Exception as e:
            logger.error(f"Image generation failed: {e}")
            # ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë°˜í™˜ (Mockìœ¼ë¡œ í´ë°±í•˜ì§€ ì•ŠìŒ)
            return ImageGenerationResponse(
                job_id=str(uuid.uuid4()),
                status="failed",
                images=[],
                prompt_used=request.prompt,
                metadata={"error": str(e), "generation_failed": True}
            )
    
    async def get_generation_status(self, job_id: str) -> ImageGenerationResponse:
        """ìƒì„± ìƒíƒœ ì¡°íšŒ"""
        # Mock ëª¨ë“œ ì œê±° - ì‹¤ì œ ìƒíƒœ ì¡°íšŒë§Œ ìˆ˜í–‰
        return await self._get_real_status(job_id)
    
    async def _generate_real_image(self, request: ImageGenerationRequest) -> ImageGenerationResponse:
        """ì‹¤ì œ ComfyUI API í˜¸ì¶œ (RunPod ì§€ì›, pod_idë¡œ ë™ì  endpoint_url ì‚¬ìš©)"""
        import aiohttp
        job_id = str(uuid.uuid4())
        runpod_pod_id = getattr(request, 'pod_id', None)
        target_url = None
        try:
            if runpod_pod_id:
                from app.services.runpod_service import get_runpod_service
                runpod_service = get_runpod_service()
                logger.info(f"[ì´ë¯¸ì§€ ìƒì„±] ì „ë‹¬ë°›ì€ pod_id={runpod_pod_id}ë¡œ RunPod ìƒíƒœ ì¡°íšŒ ë° endpoint_url ì‚¬ìš©")
                pod_status = await runpod_service.get_pod_status(runpod_pod_id)
                logger.info(f"[RunPod] pod_id={runpod_pod_id} ìƒíƒœ ì¡°íšŒ ê²°ê³¼: runtime={pod_status.runtime}")
                logger.info(f"[RunPod] pod_id={runpod_pod_id} endpoint_url={pod_status.endpoint_url}")
                # public ip/port ìƒì„¸ ì¶œë ¥
                if pod_status.runtime and 'ports' in pod_status.runtime:
                    for port in pod_status.runtime['ports']:
                        logger.info(f"[RunPod] pod_id={runpod_pod_id} port info: ip={port.get('ip')}, publicPort={port.get('publicPort')}, isIpPublic={port.get('isIpPublic')}")
                target_url = pod_status.endpoint_url
                if not target_url:
                    raise Exception(f"RunPod pod_id={runpod_pod_id}ì˜ endpoint_urlì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ê¸°ì¡´ ë°©ì‹(ë¡œì»¬ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜)
                logger.info(f"[ì´ë¯¸ì§€ ìƒì„±] pod_idê°€ ì „ë‹¬ë˜ì§€ ì•Šì•„ ë¡œì»¬/í™˜ê²½ë³€ìˆ˜ ComfyUI ì„œë²„ ì‚¬ìš©: {self.server_url}")
                target_url = self.server_url

            # ComfyUI ì›Œí¬í”Œë¡œìš° JSON ìƒì„±
            workflow = await self._create_custom_workflow(request)

            # ComfyUI ì„œë²„ì— ì›Œí¬í”Œë¡œìš° ì „ì†¡
            logger.info(f"[ComfyUI] ì›Œí¬í”Œë¡œìš° ì „ì†¡: {target_url}/prompt")
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{target_url}/prompt",
                    json={"prompt": workflow, "client_id": self.client_id},
                    timeout=aiohttp.ClientTimeout(total=60)
                ) as queue_response:
                    if queue_response.status != 200:
                        raise Exception(f"ComfyUI ì›Œí¬í”Œë¡œìš° í ì‹¤íŒ¨: {await queue_response.text()}")
                    queue_data = await queue_response.json()
                    prompt_id = queue_data.get("prompt_id")
                    logger.info(f"[ComfyUI] ì›Œí¬í”Œë¡œìš° í ì™„ë£Œ: prompt_id={prompt_id}")

            # ìƒì„± ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (ê¸°ì¡´ ë°©ì‹ í™œìš©)
            result = await self._wait_for_completion(prompt_id)
            return ImageGenerationResponse(
                job_id=prompt_id,
                status="completed",
                images=result.get("images", []),
                prompt_used=request.prompt,
                generation_time=1.0,
                metadata={
                    "note": "RunPod ComfyUI API ì‚¬ìš©",
                    "pod_id": runpod_pod_id,
                    "endpoint_url": target_url
                }
            )
        except Exception as e:
            logger.error(f"[ComfyUI] ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    
    async def _get_real_status(self, job_id: str) -> ImageGenerationResponse:
        """ì‹¤ì œ ìƒíƒœ ì¡°íšŒ"""
        try:
            # íˆìŠ¤í† ë¦¬ ì¡°íšŒë¥¼ í†µí•œ ìƒíƒœ í™•ì¸
            history_response = requests.get(f"{self.server_url}/history/{job_id}")
            if history_response.status_code == 200:
                history_data = history_response.json()
                if job_id in history_data:
                    # ì™„ë£Œëœ ì‘ì—…
                    result = history_data[job_id]
                    images = self._extract_images_from_history(result)
                    return ImageGenerationResponse(
                        job_id=job_id,
                        status="completed",
                        images=images,
                        prompt_used="",
                        metadata={"history_data": result}
                    )
            
            # ì§„í–‰ ì¤‘ì¸ ì‘ì—… í™•ì¸
            queue_response = requests.get(f"{self.server_url}/queue")
            if queue_response.status_code == 200:
                queue_data = queue_response.json()
                # íì—ì„œ job_id ì°¾ê¸°
                for item in queue_data.get("queue_running", []) + queue_data.get("queue_pending", []):
                    if len(item) > 1 and item[1] == job_id:
                        return ImageGenerationResponse(
                            job_id=job_id,
                            status="processing",
                            images=[],
                            prompt_used="",
                            metadata={"queue_status": "in_progress"}
                        )
            
            # ìƒíƒœë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
            return ImageGenerationResponse(
                job_id=job_id,
                status="not_found",
                images=[],
                prompt_used="",
                metadata={"error": "Job not found in history or queue"}
            )
            
        except Exception as e:
            logger.error(f"Failed to get real status: {e}")
            return ImageGenerationResponse(
                job_id=job_id,
                status="error",
                images=[],
                prompt_used="",
                metadata={"error": str(e)}
            )
    
    async def _create_custom_workflow(self, request: ImageGenerationRequest) -> Dict[str, Any]:
        """
        ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ ì›Œí¬í”Œë¡œìš° JSON ìƒì„±
        """
        try:
            workflow_manager = get_workflow_manager()
            workflow_config = get_workflow_config()
            
            # ì›Œí¬í”Œë¡œìš° ID ê²°ì • (ì‚¬ìš©ì ì„¤ì • â†’ ìš”ì²­ â†’ ê¸°ë³¸ê°’ ìˆœ)
            logger.info(f"ğŸ” ìš”ì²­ëœ workflow_id: {request.workflow_id}")
            workflow_id = request.workflow_id
            if not workflow_id:
                workflow_id = workflow_config.get_effective_workflow_id(request.user_id)
                logger.info(f"ğŸ”„ ê¸°ë³¸ workflow_idë¡œ ë³€ê²½: {workflow_id}")
            
            logger.info(f"Using workflow: {workflow_id} for user: {request.user_id}")
            
            # ìš”ì²­ íŒŒë¼ë¯¸í„° ì¤€ë¹„
            parameters = {
                "prompt": request.prompt,
                "negative_prompt": request.negative_prompt,
                "width": request.width,
                "height": request.height,
                "steps": request.steps,
                "cfg_scale": request.cfg_scale,
                "seed": request.seed if request.seed is not None and request.seed >= 0 else __import__('random').randint(0, 2**32-1)
            }
            
            # ì»¤ìŠ¤í…€ íŒŒë¼ë¯¸í„° ì¶”ê°€
            if request.custom_parameters:
                parameters.update(request.custom_parameters)
            
            # ì›Œí¬í”Œë¡œìš° ì…ë ¥ ìƒì„±
            workflow_input = WorkflowInput(
                workflow_id=workflow_id,
                parameters=parameters
            )
            
            # ì‹¤í–‰ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš° ìƒì„± (í´ë°± ì²˜ë¦¬ í¬í•¨)
            try:
                workflow = await workflow_manager.generate_executable_workflow(workflow_input)
            except ValueError as e:
                if "Workflow not found" in str(e) and workflow_id == "custom_workflow":
                    # custom_workflowê°€ ì—†ìœ¼ë©´ basic_txt2imgë¡œ í´ë°±
                    logger.warning(f"custom_workflow not found, falling back to basic_txt2img")
                    workflow_input.workflow_id = "basic_txt2img"
                    workflow = await workflow_manager.generate_executable_workflow(workflow_input)
                    workflow_id = "basic_txt2img"  # ë¡œê·¸ìš©
                else:
                    raise
            
            # RunPod ì‚¬ìš© ì‹œ ì›Œí¬í”Œë¡œìš° ì ì‘
            if request.use_runpod and self.runpod_adapter:
                adapted_workflow, warnings = self.runpod_adapter.adapt_workflow_for_runpod(workflow)
                workflow = adapted_workflow
                
                if warnings:
                    logger.warning(f"RunPod adaptations: {warnings}")
            
            logger.info(f"Generated custom workflow: {workflow_id}")
            return workflow
            
        except Exception as e:
            logger.error(f"Failed to create custom workflow: {e}")
            # í´ë°±ìœ¼ë¡œ ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ì‚¬ìš©
            return self._create_default_workflow(request)
    
    def _create_default_workflow(self, request: ImageGenerationRequest) -> Dict[str, Any]:
        """
        ComfyUI ì›Œí¬í”Œë¡œìš° JSON ìƒì„±
        
        ê¸°ë³¸ì ì¸ txt2img ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿
        """
        
        # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° í…œí”Œë¦¿ (Stable Diffusion ê¸°ì¤€)
        workflow = {
            "3": {
                "inputs": {
                    "seed": request.seed if request.seed is not None and request.seed >= 0 else __import__('random').randint(0, 2**32-1),
                    "steps": request.steps,
                    "cfg": request.cfg_scale,
                    "sampler_name": "euler",
                    "scheduler": "normal",
                    "denoise": 1,
                    "model": ["4", 0],
                    "positive": ["6", 0],
                    "negative": ["7", 0],
                    "latent_image": ["5", 0]
                },
                "class_type": "KSampler"
            },
            "4": {
                "inputs": {
                    "ckpt_name": "sd_xl_base_1.0.safetensors"  # ê¸°ë³¸ ëª¨ë¸
                },
                "class_type": "CheckpointLoaderSimple"
            },
            "5": {
                "inputs": {
                    "width": request.width,
                    "height": request.height,
                    "batch_size": 1
                },
                "class_type": "EmptyLatentImage"
            },
            "6": {
                "inputs": {
                    "text": request.prompt,
                    "clip": ["4", 1]
                },
                "class_type": "CLIPTextEncode"
            },
            "7": {
                "inputs": {
                    "text": request.negative_prompt or "low quality, blurry",
                    "clip": ["4", 1]
                },
                "class_type": "CLIPTextEncode"
            },
            "8": {
                "inputs": {
                    "samples": ["3", 0],
                    "vae": ["4", 2]
                },
                "class_type": "VAEDecode"
            },
            "9": {
                "inputs": {
                    "filename_prefix": "ComfyUI",
                    "images": ["8", 0]
                },
                "class_type": "SaveImage"
            }
        }
        
        return workflow
    
    async def _wait_for_completion(self, prompt_id: str, timeout: int = 300) -> Dict[str, Any]:
        """
        ComfyUI ìƒì„± ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        
        WebSocket ë˜ëŠ” í´ë§ì„ í†µí•´ ìƒíƒœ í™•ì¸
        """
        
        # WebSocket ì—°ê²°ë¡œ ì‹¤ì‹œê°„ ìƒíƒœ í™•ì¸
        try:
            ws_url = f"ws://127.0.0.1:8188/ws?clientId={self.client_id}"
            
            # ê°„ë‹¨í•œ í´ë§ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ (WebSocket êµ¬í˜„ì€ ë³µì¡í•¨)
            for _ in range(timeout):
                await asyncio.sleep(1)
                
                # íˆìŠ¤í† ë¦¬ í™•ì¸
                history_response = requests.get(f"{self.server_url}/history/{prompt_id}")
                if history_response.status_code == 200:
                    history_data = history_response.json()
                    if prompt_id in history_data:
                        # ì™„ë£Œëœ ê²½ìš° ì´ë¯¸ì§€ URL ì¶”ì¶œ
                        result = history_data[prompt_id]
                        images = self._extract_images_from_history(result)
                        return {
                            "images": images,
                            "generation_time": 1.0  # ì‹¤ì œ ì‹œê°„ ê³„ì‚° í•„ìš”
                        }
            
            # íƒ€ì„ì•„ì›ƒ
            raise Exception(f"Generation timeout after {timeout} seconds")
            
        except Exception as e:
            logger.error(f"Failed to wait for completion: {e}")
            raise
    
    def _extract_images_from_history(self, history_data: Dict[str, Any]) -> List[str]:
        """íˆìŠ¤í† ë¦¬ ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
        
        images = []
        
        try:
            outputs = history_data.get("outputs", {})
            for node_id, node_output in outputs.items():
                if "images" in node_output:
                    for image_info in node_output["images"]:
                        filename = image_info.get("filename")
                        if filename:
                            # ComfyUI ì„œë²„ì˜ ì´ë¯¸ì§€ URL ìƒì„±
                            image_url = f"{self.server_url}/view?filename={filename}"
                            images.append(image_url)
        
        except Exception as e:
            logger.error(f"Failed to extract images: {e}")
        
        return images
    
    async def _wait_for_pod_ready(self, runpod_service, pod_id: str, max_wait_time: int = 300):
        """RunPod ì¸ìŠ¤í„´ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
        import time
        start_time = time.time()
        
        while time.time() - start_time < max_wait_time:
            try:
                pod_status = await runpod_service.get_pod_status(pod_id)
                if pod_status.status == "RUNNING" and pod_status.endpoint_url:
                    logger.info(f"RunPod instance {pod_id} is ready")
                    return
                
                logger.info(f"Waiting for RunPod instance {pod_id} (status: {pod_status.status})")
                await asyncio.sleep(10)  # 10ì´ˆ ëŒ€ê¸°
                
            except Exception as e:
                logger.warning(f"Error checking RunPod status: {e}")
                await asyncio.sleep(5)
        
        raise Exception(f"RunPod instance {pod_id} did not become ready within {max_wait_time} seconds")
    
    async def _wait_for_comfyui_ready(self, comfyui_url: str, max_wait_time: int = 240):
        """ComfyUI ì„œë²„ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
        logger.info(f"Waiting for ComfyUI server to be ready at {comfyui_url}")
        import time
        start_time = time.time()
        
        # ë‹¤ì–‘í•œ ì—”ë“œí¬ì¸íŠ¸ë¡œ ìƒíƒœ í™•ì¸
        check_endpoints = ["/system_stats", "/queue", "/history"]
        
        while time.time() - start_time < max_wait_time:
            try:
                # ì—¬ëŸ¬ ì—”ë“œí¬ì¸íŠ¸ ì¤‘ í•˜ë‚˜ë¼ë„ ì‘ë‹µí•˜ë©´ ì¤€ë¹„ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                for endpoint in check_endpoints:
                    try:
                        logger.debug(f"Checking {comfyui_url}{endpoint}")
                        response = requests.get(f"{comfyui_url}{endpoint}", timeout=15)
                        logger.debug(f"Response: {response.status_code}")
                        if response.status_code == 200:
                            logger.info(f"ComfyUI server is ready at {comfyui_url} (checked via {endpoint})")
                            return True
                    except requests.RequestException as e:
                        logger.debug(f"Endpoint {endpoint} failed: {e}")
                        continue
                
            except Exception as e:
                logger.debug(f"ComfyUI health check error: {e}")
            
            elapsed = time.time() - start_time
            logger.info(f"Waiting for ComfyUI server... ({elapsed:.0f}s elapsed)")
            logger.info(f"Checking URL: {comfyui_url}")
            await asyncio.sleep(20)  # 20ì´ˆë§ˆë‹¤ í™•ì¸
        
        raise TimeoutError(f"ComfyUI server at {comfyui_url} did not become ready within {max_wait_time} seconds")


# ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
_comfyui_service_instance = None

def get_comfyui_service() -> ComfyUIService:
    """ComfyUI ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _comfyui_service_instance
    if _comfyui_service_instance is None:
        _comfyui_service_instance = ComfyUIService()
    return _comfyui_service_instance
