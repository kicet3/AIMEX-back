"""
ë§íˆ¬ ìƒì„± ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´íˆ¬ ìƒì„± ê´€ë ¨ ê³µí†µ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì œê³µí•©ë‹ˆë‹¤.
- vLLM ì„œë²„ ì—°ë™ (ì–´íˆ¬ ìƒì„± ì „ìš©)
- ìºë¦­í„° ë°ì´í„° êµ¬ì„±
- ì–´íˆ¬ ì‘ë‹µ ë³€í™˜
- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
"""

import logging
from datetime import datetime
from typing import Optional
from fastapi import HTTPException

from app.schemas.influencer import ToneGenerationRequest
from app.utils.data_mapping import create_character_data
from app.services.vllm_client import vllm_health_check, VLLMClient, VLLMServerConfig
from app.core.config import settings
from fastapi import HTTPException

logger = logging.getLogger(__name__)


class ToneGenerationService:
    """ë§íˆ¬ ìƒì„± ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    @staticmethod
    async def generate_conversation_tones(
        request: ToneGenerationRequest, 
        is_regeneration: bool = False
    ) -> dict:
        """ë§íˆ¬ ìƒì„± ê³µí†µ ë¡œì§
        
        Args:
            request: ë§íˆ¬ ìƒì„± ìš”ì²­ ë°ì´í„°
            is_regeneration: ì¬ìƒì„± ì—¬ë¶€
            
        Returns:
            dict: ìƒì„±ëœ ë§íˆ¬ ì‘ë‹µ
            
        Raises:
            HTTPException: ê²€ì¦ ì‹¤íŒ¨, vLLM ì„œë²„ ì˜¤ë¥˜ ë“±
        """
        # ì…ë ¥ ê²€ì¦
        if not request.personality.strip():
            raise HTTPException(status_code=400, detail="ì„±ê²© ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
        
        try:
            # vLLM ì„œë²„ ìƒíƒœ í™•ì¸
            if not await vllm_health_check():
                raise HTTPException(status_code=503, detail="vLLM ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ìºë¦­í„° ë°ì´í„° êµ¬ì„±
            character_data = create_character_data(
                name=request.name,
                description=request.description,
                age=request.age,
                gender=request.gender,
                personality=request.personality,
                mbti=request.mbti
            )
            
            # vLLM ì„œë²„ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë˜í•‘
            vllm_request_data = {
                "character": character_data
            }
            
            log_message = "vLLM ì„œë²„ë¡œ ìºë¦­í„° QA ì¬ìƒì„± ìš”ì²­" if is_regeneration else "vLLM ì„œë²„ë¡œ ìºë¦­í„° QA ìƒì„± ìš”ì²­"
            logger.info(f"{log_message}: {character_data}")
            
            # vLLM ì„œë²„ì—ì„œ ì–´íˆ¬ ìƒì„± (ìƒˆë¡œìš´ ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
            vllm_result = await ToneGenerationService._generate_tones_from_vllm(vllm_request_data)
            
            if is_regeneration:
                logger.info(f"vLLM ì¬ìƒì„± ì‘ë‹µ ì™„ë£Œ: {vllm_result}")
            
            # vLLM ì‘ë‹µì„ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            conversation_examples = ToneGenerationService._convert_vllm_response_to_conversation_examples(vllm_result)
            
            # ì‘ë‹µ êµ¬ì„±
            result = {
                "personality": request.personality,
                "character_info": character_data,
                "question": vllm_result.get("question", ""),
                "conversation_examples": conversation_examples,
                "generated_at": datetime.now().isoformat()
            }
            
            # ì¬ìƒì„±ì¸ ê²½ìš° í”Œë˜ê·¸ ì¶”ê°€
            if is_regeneration:
                result["regenerated"] = True
            
            return result
            
        except HTTPException:
            # FastAPI HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „íŒŒ
            raise
        except Exception as e:
            error_type = "ì¬ìƒì„±" if is_regeneration else "ìƒì„±"
            logger.error(f"ë§íˆ¬ {error_type} ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            raise HTTPException(
                status_code=500, 
                detail=f"ë§íˆ¬ {error_type} ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    @staticmethod
    def _convert_vllm_response_to_conversation_examples(vllm_result: dict) -> list:
        """vLLM ì‘ë‹µì„ conversation_examples í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            vllm_result: vLLM ì„œë²„ ì‘ë‹µ
            
        Returns:
            list: ë³€í™˜ëœ conversation_examples
        """
        conversation_examples = []
        
        try:
            responses = vllm_result.get('responses', {})
            for tone_name, tone_responses in responses.items():
                if tone_responses and len(tone_responses) > 0:
                    tone_response = tone_responses[0]  # ì²« ë²ˆì§¸ ì‘ë‹µ ì‚¬ìš©
                    
                    tone_info = tone_response.get("tone_info", {})
                    tone_description = tone_info.get("description", tone_name)
                    hashtags = tone_info.get("hashtags", f"#{tone_name} #ë§íˆ¬")
                    system_prompt = tone_response.get("system_prompt", f"ë‹¹ì‹ ì€ {tone_name} ë§íˆ¬ë¡œ ëŒ€í™”í•˜ëŠ” AIì…ë‹ˆë‹¤.")
                    
                    conversation_examples.append({
                        "title": tone_description,
                        "example": tone_response.get("text", ""),
                        "tone": tone_description,
                        "hashtags": hashtags,
                        "system_prompt": system_prompt
                    })
        
        except Exception as e:
            logger.error(f"vLLM ì‘ë‹µ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ì–´íˆ¬ ìƒì„± ê¸ˆì§€ - ì˜ˆì™¸ ë°œìƒ
            raise HTTPException(
                status_code=500,
                detail=f"vLLM ì‘ë‹µ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
        
        return conversation_examples
    
    @staticmethod
    async def _generate_tones_from_vllm(vllm_request_data: dict) -> dict:
        """vLLM ì„œë²„ì—ì„œ ì–´íˆ¬ ìƒì„± (ì¬ì‹œë„ ë¡œì§ ì—†ìŒ)
        
        Args:
            vllm_request_data: vLLM ì„œë²„ ìš”ì²­ ë°ì´í„° (character ê°ì²´ í¬í•¨)
            
        Returns:
            dict: vLLM ì„œë²„ ì‘ë‹µ
            
        Raises:
            HTTPException: vLLM ì„œë²„ ì˜¤ë¥˜ ì‹œ ì˜ˆì™¸ ë°œìƒ
        """
        try:
            # vLLM ì„œë²„ ì„¤ì •
            vllm_config = VLLMServerConfig(
                base_url=settings.VLLM_BASE_URL,
                timeout=getattr(settings, 'VLLM_TIMEOUT', 300)
            )
            
            async with VLLMClient(vllm_config) as client:
                # ë¨¼ì € ê³ ì† ì—”ë“œí¬ì¸íŠ¸ ì‹œë„
                try:
                    # ğŸš€ ê³ ì† ì–´íˆ¬ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
                    response = await client.client.post(
                        "/speech/generate_qa_fast",  # ê³ ì† ë³‘ë ¬ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸
                        json=vllm_request_data,
                        timeout=30  # ê³ ì† ì²˜ë¦¬ë¡œ íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                    )
                    response.raise_for_status()
                    logger.info("âœ… ê³ ì† ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©")
                    
                except Exception as fast_error:
                    logger.warning(f"âš ï¸ ê³ ì† ì—”ë“œí¬ì¸íŠ¸ ì‹¤íŒ¨, ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ë¡œ í´ë°±: {fast_error}")
                    
                    # í´ë°±: ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
                    response = await client.client.post(
                        "/speech/generate_qa",  # ê¸°ì¡´ í˜¸í™˜ì„± ì—”ë“œí¬ì¸íŠ¸
                        json=vllm_request_data,
                        timeout=60  # ê¸°ì¡´ ë°©ì‹ì€ ë” ì˜¤ë˜ ê±¸ë¦¼
                    )
                    response.raise_for_status()
                    logger.info("âœ… ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš© (í´ë°±)")
                
                result = response.json()
                # ì„±ëŠ¥ ì •ë³´ ë¡œê¹…
                generation_time = result.get('generation_time_seconds', 0)
                method = result.get('method', 'unknown')
                character_name = vllm_request_data.get('character', {}).get('name', 'Unknown')
                logger.info(f"âœ… ê³ ì† ì–´íˆ¬ ìƒì„± ì„±ê³µ: {character_name} "
                          f"(ì†Œìš”ì‹œê°„: {generation_time:.2f}ì´ˆ, ë°©ì‹: {method})")
                return result
                
        except Exception as e:
            character_name = vllm_request_data.get('character', {}).get('name', 'Unknown')
            logger.error(f"âŒ vLLM ì–´íˆ¬ ìƒì„± ì‹¤íŒ¨ ({character_name}): {e}", exc_info=True)
            
            # ë” ìƒì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì œê³µ
            if hasattr(e, 'response'):
                try:
                    error_detail = e.response.text if hasattr(e.response, 'text') else str(e)
                    logger.error(f"âŒ vLLM ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {error_detail}")
                except:
                    pass
                    
            raise HTTPException(
                status_code=503, 
                detail=f"vLLM ì„œë²„ì—ì„œ ì–´íˆ¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    # ê¸°ë³¸ ì–´íˆ¬ ìƒì„± ë©”ì„œë“œëŠ” ì œê±°ë¨ - vLLM ì„œë²„ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê°œë³„ í•¨ìˆ˜
async def generate_conversation_tones(request: ToneGenerationRequest) -> dict:
    """ë§íˆ¬ ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„±)"""
    return await ToneGenerationService.generate_conversation_tones(request, False)


async def regenerate_conversation_tones(request: ToneGenerationRequest) -> dict:
    """ë§íˆ¬ ì¬ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„±)"""
    return await ToneGenerationService.generate_conversation_tones(request, True)