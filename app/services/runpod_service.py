"""
RunPod ì„œë²„ ê´€ë¦¬ ì„œë¹„ìŠ¤
ComfyUIê°€ ì„¤ì¹˜ëœ ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±/ê´€ë¦¬
"""

import asyncio
import aiohttp
import logging
from typing import Dict, Optional, Any
from pydantic import BaseModel
from app.core.config import settings

logger = logging.getLogger(__name__)


class RunPodPodRequest(BaseModel):
    """RunPod ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ìš”ì²­"""
    name: str
    template_id: str
    gpu_type: str = "NVIDIA RTX A6000"
    gpu_count: int = 1
    container_disk_in_gb: int = 50
    volume_in_gb: int = 0
    ports: str = "8188/http"  # ComfyUI ê¸°ë³¸ í¬íŠ¸
    env: Dict[str, str] = {}


class RunPodPodResponse(BaseModel):
    """RunPod ì¸ìŠ¤í„´ìŠ¤ ì •ë³´"""
    pod_id: str
    status: str  # STARTING, RUNNING, STOPPED, FAILED
    runtime: Optional[Dict[str, Any]] = None
    endpoint_url: Optional[str] = None
    cost_per_hour: Optional[float] = None


class RunPodService:
    """RunPod API ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.api_key = settings.RUNPOD_API_KEY
        self.base_url = "https://api.runpod.io/graphql"
        self.template_id = settings.RUNPOD_TEMPLATE_ID
        
        # Mock ëª¨ë“œ ì œê±° - ì‹¤ì œ API í‚¤ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
        if not self.api_key or not self.template_id:
            raise ValueError(
                f"RunPod ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤: "
                f"API_KEY={'ì„¤ì •ë¨' if self.api_key else 'ì—†ìŒ'}, "
                f"TEMPLATE_ID={'ì„¤ì •ë¨' if self.template_id else 'ì—†ìŒ'}"
            )
        
        logger.info(f"RunPod Service initialized (API Key: {'***' + self.api_key[-4:] if len(self.api_key) > 4 else '***'}, Template: {self.template_id})")
    
    async def create_pod(self, request_id: str) -> RunPodPodResponse:
        """ComfyUI ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (GPU í´ë°± ì§€ì›)"""
        
        # GPU ì¬ì‹œë„ ë¡œì§ (EU-RO-1 ì§€ì—­ì—ì„œ ì‹¤ì œ ê°€ìš©í•œ GPUë§Œ)
        gpu_chain = [
            "NVIDIA GeForce RTX 4090",        # 1ìˆœìœ„: ê³ ì„±ëŠ¥ (24GB)
            "NVIDIA RTX 4000 Ada Generation", # 2ìˆœìœ„: ì›Œí¬ìŠ¤í…Œì´ì…˜ê¸‰ (20GB)
            "NVIDIA RTX A4500",               # 3ìˆœìœ„: ì›Œí¬ìŠ¤í…Œì´ì…˜ (20GB) 
            "NVIDIA RTX 2000 Ada Generation", # 4ìˆœìœ„: íš¨ìœ¨ì  ì„±ëŠ¥ (16GB)
        ]
        
        for attempt in range(4):  # RTX 4090 â†’ RTX 4000 Ada â†’ A4500 â†’ RTX 2000 Ada
            try:
                gpu_type = gpu_chain[attempt]
                
                logger.info(f"Pod ìƒì„± ì‹œë„ #{attempt + 1} - GPU: {gpu_type}")
                
                # ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
                if self.template_id:
                    # ì»¤ìŠ¤í…€ í…œí”Œë¦¿ì„ ì‚¬ìš©í•œ Pod ìƒì„±
                    mutation = """
                    mutation podRentInterruptable($input: PodRentInterruptableInput!) {
                        podRentInterruptable(input: $input) {
                            id
                            desiredStatus
                            runtime {
                                uptimeInSeconds
                                ports {
                                    ip
                                    isIpPublic
                                    privatePort
                                    publicPort
                                }
                            }
                            machine {
                                podHostId
                            }
                        }
                    }
                    """
                    
                    variables = {
                        "input": {
                            "bidPerGpu": 0.3,  # ì‹œê°„ë‹¹ ìµœëŒ€ ë¹„ìš© (USD)
                            "gpuCount": 1,
                            "volumeInGb": 200,  # Volume Disk 200GB
                            "volumeId": settings.RUNPOD_VOLUME_ID,
                            "containerDiskInGb": 20,  # Container Disk 20GB
                            "minVcpuCount": 4,
                            "minMemoryInGb": 20,
                            "gpuTypeId": gpu_type,
                            "name": f"AIMEX_ComfyUI_Cutom_py312_cu124-{request_id[:8]}",
                            "templateId": self.template_id,  # ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ID ì‚¬ìš©
                            "ports": "8188/http,7860/http,22/tcp",  # ì¶”ê°€ í¬íŠ¸
                            "dataCenterId": "EU-RO-1",  # EU-RO-1 ì§€ì—­ìœ¼ë¡œ ê°•ì œ ì„¤ì •
                            "startPod": True,  # ìƒì„±ê³¼ ë™ì‹œì— ìë™ ì‹œì‘
                            "env": [
                                {"key": "CUDA_VERSION", "value": "12.4"},
                                {"key": "RUNPOD_AI_API_KEY", "value": "your-api-key"},
                                {"key": "COMFYUI_FLAGS", "value": "--listen 0.0.0.0 --port 8188"},
                                {"key": "AUTO_DOWNLOAD_MODELS", "value": "true"}
                            ]
                        }
                    }
                else:
                    # ê¸°ë³¸ ComfyUI ì´ë¯¸ì§€ ì‚¬ìš© (í´ë°±)
                    mutation = """
                mutation podRentInterruptable($input: PodRentInterruptableInput!) {
                    podRentInterruptable(input: $input) {
                        id
                        desiredStatus
                        runtime {
                            uptimeInSeconds
                            ports {
                                ip
                                isIpPublic
                                privatePort
                                publicPort
                            }
                        }
                        machine {
                            podHostId
                        }
                    }
                }
                    """
                    
                    variables = {
                        "input": {
                            "bidPerGpu": 0.2,  # ì‹œê°„ë‹¹ ìµœëŒ€ ë¹„ìš© (USD)
                            "gpuCount": 1,
                            "volumeInGb": 200,
                            "volumeId": settings.RUNPOD_VOLUME_ID,
                            "containerDiskInGb": 50,
                            "minVcpuCount": 2,
                            "minMemoryInGb": 15,
                            "gpuTypeId": gpu_type,
                            "name": f"comfyui-{request_id[:8]}",
                            "imageName": settings.AIMEX_DOCKER_IMAGE or "hyunmin94/aimex-comfyui:optimized-v2",  # AIMEX ì»¤ìŠ¤í…€ ì´ë¯¸ì§€
                            "dockerArgs": "",
                            "ports": "8188/http",
                            "volumeMountPath": "/workspace",
                            "dataCenterId": "EU-RO-1",  # EU-RO-1 ì§€ì—­ìœ¼ë¡œ ê°•ì œ ì„¤ì •
                            "startPod": True,  # ìƒì„±ê³¼ ë™ì‹œì— ìë™ ì‹œì‘
                            "env": [
                                {"key": "CUDA_VERSION", "value": "12.4"},
                                {"key": "JUPYTER_PASSWORD", "value": "rp123456789"},
                                {"key": "ENABLE_TENSORBOARD", "value": "1"}
                            ]
                        }
                    }
                
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.api_key}"
                }
                
                async with aiohttp.ClientSession() as session:
                    payload = {
                        "query": mutation,
                        "variables": variables
                    }
                    
                    async with session.post(
                        self.base_url,
                        json=payload,
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=30)
                    ) as response:
                        if response.status != 200:
                            raise Exception(f"RunPod API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                        
                        data = await response.json()
                        
                        if "errors" in data:
                            error_msg = data['errors'][0].get('message', 'Unknown error')
                            if "no longer any instances available" in error_msg and attempt == 0:
                                logger.warning(f"GPU {gpu_type} ì¸ìŠ¤í„´ìŠ¤ ì—†ìŒ - í´ë°± ì‹œë„")
                                continue  # ë‹¤ìŒ attemptë¡œ ì§„í–‰
                            else:
                                raise Exception(f"RunPod GraphQL ì˜¤ë¥˜: {data['errors']}")
                        
                        pod_data = data["data"]["podRentInterruptable"]
                        
                        # ì—”ë“œí¬ì¸íŠ¸ URL êµ¬ì„±
                        endpoint_url = None
                        if pod_data.get("runtime") and pod_data["runtime"].get("ports"):
                            for port in pod_data["runtime"]["ports"]:
                                if port["privatePort"] == 8188:
                                    # ComfyUIëŠ” HTTP í”„ë¡œí† ì½œ ì‚¬ìš©
                                    endpoint_url = f"http://{port['ip']}:{port['publicPort']}"
                                    break
                        
                        logger.info(f"âœ… RunPod ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ - GPU: {gpu_type}, Pod ID: {pod_data['id']}")
                        
                        # Pod ìƒì„± í›„ ìë™ìœ¼ë¡œ ì‹œì‘
                        pod_id = pod_data["id"]
                        logger.info(f"ğŸš€ Pod {pod_id} ìë™ ì‹œì‘ ì‹œë„...")
                        
                        start_success = await self._start_pod(pod_id)
                        if start_success:
                            logger.info(f"âœ… Pod {pod_id} ìë™ ì‹œì‘ ì„±ê³µ")
                        else:
                            logger.warning(f"âš ï¸ Pod {pod_id} ìë™ ì‹œì‘ ì‹¤íŒ¨, ìˆ˜ë™ ì‹œì‘ í•„ìš”")
                        
                        return RunPodPodResponse(
                            pod_id=pod_id,
                            status="STARTING" if start_success else pod_data["desiredStatus"],
                            runtime=pod_data.get("runtime", {}),
                            endpoint_url=endpoint_url,
                            cost_per_hour=0.2
                        )
                        
            except Exception as e:
                if attempt < 3 and "no longer any instances available" in str(e):
                    logger.warning(f"ì‹œë„ #{attempt + 1} ({gpu_type}) ì‹¤íŒ¨ - ë‹¤ìŒ GPUë¡œ ì¬ì‹œë„: {e}")
                    continue
                else:
                    logger.error(f"RunPod ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ (ì‹œë„ #{attempt + 1}): {e}")
                    if attempt == 3:  # ë§ˆì§€ë§‰ ì‹œë„ (4ë²ˆì§¸)
                        raise RuntimeError("ì§€ê¸ˆ ì‚¬ìš©ê°€ëŠ¥í•œ ìì›ì´ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                    elif "no longer any instances available" not in str(e):
                        # ì¸ìŠ¤í„´ìŠ¤ ë¶€ì¡±ì´ ì•„ë‹Œ ë‹¤ë¥¸ ì˜¤ë¥˜ë©´ ì¦‰ì‹œ ì‹¤íŒ¨
                        raise RuntimeError(f"RunPod Pod ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
        logger.error("ëª¨ë“  GPU ì˜µì…˜ìœ¼ë¡œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨")
        raise RuntimeError("ì§€ê¸ˆ ì‚¬ìš©ê°€ëŠ¥í•œ ìì›ì´ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
    
    async def get_pod_status(self, pod_id: str) -> RunPodPodResponse:
        """Pod ìƒíƒœ ì¡°íšŒ"""
        
        try:
            # GraphQL ì¿¼ë¦¬ - Pod ìƒíƒœ ì¡°íšŒ
            query = """
            query pod($input: PodFilter!) {
                pod(input: $input) {
                    id
                    desiredStatus
                    lastStatusChange
                    runtime {
                        uptimeInSeconds
                        ports {
                            ip
                            isIpPublic
                            privatePort
                            publicPort
                        }
                    }
                }
            }
            """
            
            variables = {
                "input": {
                    "podId": pod_id
                }
            }
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            async with aiohttp.ClientSession() as session:
                payload = {
                    "query": query,
                    "variables": variables
                }
                
                async with session.post(
                    self.base_url,
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status != 200:
                        raise Exception(f"RunPod API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                    
                    data = await response.json()
                    pod_data = data["data"]["pod"]
                    
                    # ì—”ë“œí¬ì¸íŠ¸ URL êµ¬ì„±
                    endpoint_url = None
                    if pod_data.get("runtime") and pod_data["runtime"].get("ports"):
                        for port in pod_data["runtime"]["ports"]:
                            if port["privatePort"] == 8188:
                                # ComfyUIëŠ” HTTP í”„ë¡œí† ì½œ ì‚¬ìš©
                                endpoint_url = f"http://{port['ip']}:{port['publicPort']}"
                                break
                    
                    return RunPodPodResponse(
                        pod_id=pod_data["id"],
                        status=pod_data["desiredStatus"],
                        runtime=pod_data.get("runtime", {}),
                        endpoint_url=endpoint_url
                    )
                    
        except Exception as e:
            logger.error(f"RunPod ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"RunPod ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    async def _start_pod(self, pod_id: str) -> bool:
        """Pod ì‹œì‘ (ìë™í™”ìš©)"""
        
        if not pod_id:
            logger.error("Pod IDê°€ ì œê³µë˜ì§€ ì•ŠìŒ")
            return False
        
        try:
            logger.info(f"RunPod {pod_id} ì‹œì‘ API í˜¸ì¶œ ì¤‘...")
            
            # GraphQL ë®¤í…Œì´ì…˜ - Pod ì‹œì‘ (ìƒˆë¡œ ìƒì„±ëœ Podìš©)
            mutation = """
            mutation podStart($input: PodStartInput!) {
                podStart(input: $input)
            }
            """
            
            variables = {
                "input": {
                    "podId": pod_id
                }
            }
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            async with aiohttp.ClientSession() as session:
                payload = {
                    "query": mutation,
                    "variables": variables
                }
                
                async with session.post(
                    self.base_url,
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    response_text = await response.text()
                    logger.info(f"RunPod ì‹œì‘ API ì‘ë‹µ: {response.status} - {response_text}")
                    
                    if response.status != 200:
                        logger.error(f"RunPod ì‹œì‘ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                        return False
                    
                    try:
                        data = await response.json()
                        if "errors" in data:
                            logger.error(f"RunPod ì‹œì‘ GraphQL ì˜¤ë¥˜: {data['errors']}")
                            return False
                            
                        result = data.get("data", {}).get("podStart", False)
                        
                        if result:
                            logger.info(f"âœ… RunPod {pod_id} ì‹œì‘ ìš”ì²­ ì„±ê³µ")
                            return True
                        else:
                            logger.error(f"âŒ RunPod {pod_id} ì‹œì‘ ìš”ì²­ ì‹¤íŒ¨: {data}")
                            return False
                            
                    except Exception as json_error:
                        logger.error(f"RunPod ì‹œì‘ ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {json_error}")
                        return False
                    
        except asyncio.TimeoutError:
            logger.error(f"RunPod {pod_id} ì‹œì‘ API íƒ€ì„ì•„ì›ƒ")
            return False
        except Exception as e:
            logger.error(f"RunPod {pod_id} ì‹œì‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False

    async def terminate_pod(self, pod_id: str) -> bool:
        """Pod ì¢…ë£Œ (ê°•í™”ëœ ë¡œì§)"""
        
        if not pod_id:
            logger.error("Pod IDê°€ ì œê³µë˜ì§€ ì•ŠìŒ")
            return False
        
        try:
            logger.info(f"RunPod {pod_id} ì¢…ë£Œ API í˜¸ì¶œ ì¤‘...")
            
            # GraphQL ë®¤í…Œì´ì…˜ - Pod ì¢…ë£Œ
            mutation = """
            mutation podTerminate($input: PodTerminateInput!) {
                podTerminate(input: $input)
            }
            """
            
            variables = {
                "input": {
                    "podId": pod_id
                }
            }
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            async with aiohttp.ClientSession() as session:
                payload = {
                    "query": mutation,
                    "variables": variables
                }
                
                async with session.post(
                    self.base_url,
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=15)  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
                ) as response:
                    response_text = await response.text()
                    logger.info(f"RunPod API ì‘ë‹µ: {response.status} - {response_text}")
                    
                    if response.status != 200:
                        logger.error(f"RunPod ì¢…ë£Œ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status} - {response_text}")
                        return False
                    
                    try:
                        data = await response.json()
                        result = data.get("data", {}).get("podTerminate", False)
                        
                        if result:
                            logger.info(f"âœ… RunPod {pod_id} ì¢…ë£Œ ìš”ì²­ ì„±ê³µ")
                            
                            # ì¢…ë£Œ í™•ì¸ì„ ìœ„í•´ ì ì‹œ ëŒ€ê¸° í›„ ìƒíƒœ í™•ì¸
                            await asyncio.sleep(3)
                            final_status = await self._verify_termination(pod_id)
                            
                            if final_status:
                                logger.info(f"âœ… RunPod {pod_id} ì™„ì „ ì¢…ë£Œ í™•ì¸ë¨")
                                return True
                            else:
                                logger.warning(f"âš ï¸ RunPod {pod_id} ì¢…ë£Œ ìš”ì²­ì€ ì„±ê³µí–ˆìœ¼ë‚˜ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨")
                                return result  # ì¼ë‹¨ API ì‘ë‹µì„ ë¯¿ê³  True ë°˜í™˜
                        else:
                            logger.error(f"âŒ RunPod {pod_id} ì¢…ë£Œ ìš”ì²­ ì‹¤íŒ¨: {data}")
                            return False
                            
                    except Exception as json_error:
                        logger.error(f"RunPod ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {json_error} - ì›ë³¸: {response_text}")
                        return False
                    
        except asyncio.TimeoutError:
            logger.error(f"RunPod {pod_id} ì¢…ë£Œ API íƒ€ì„ì•„ì›ƒ")
            return False
        except Exception as e:
            logger.error(f"RunPod {pod_id} ì¢…ë£Œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False
    
    async def _verify_termination(self, pod_id: str) -> bool:
        """Pod ì¢…ë£Œ í™•ì¸"""
        try:
            status = await self.get_pod_status(pod_id)
            
            # STOPPED, TERMINATED ë“±ì˜ ìƒíƒœë©´ ì„±ê³µ
            terminated_states = ["STOPPED", "TERMINATED", "TERMINATING"]
            is_terminated = status.status in terminated_states
            
            logger.info(f"Pod {pod_id} ì¢…ë£Œ í™•ì¸: ìƒíƒœ={status.status}, ì¢…ë£Œë¨={is_terminated}")
            return is_terminated
            
        except Exception as e:
            logger.warning(f"Pod {pod_id} ì¢…ë£Œ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False  # í™•ì¸ ì‹¤íŒ¨ëŠ” ì¢…ë£Œ ì‹¤íŒ¨ë¡œ ê°„ì£¼í•˜ì§€ ì•ŠìŒ
    
    async def wait_for_ready(self, pod_id: str, max_wait_time: int = 300) -> bool:
        """Podê°€ ì‹œì‘ë˜ê³  ComfyUIê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
        
        check_interval = 15  # 15ì´ˆë§ˆë‹¤ í™•ì¸ (ì‹œì‘ ì‹œê°„ ê³ ë ¤)
        checks = max_wait_time // check_interval
        
        for i in range(checks):
            try:
                status = await self.get_pod_status(pod_id)
                logger.info(f"Pod {pod_id} ìƒíƒœ í™•ì¸ #{i+1}: {status.status}")
                
                if status.status == "RUNNING" and status.endpoint_url:
                    logger.info(f"Pod {pod_id} ì‹¤í–‰ ì¤‘, ComfyUI ì—°ê²° í™•ì¸...")
                    # ComfyUI API ì‘ë‹µ í™•ì¸
                    if await self._check_comfyui_ready(status.endpoint_url):
                        logger.info(f"âœ… Pod {pod_id} ë° ComfyUI ì¤€ë¹„ ì™„ë£Œ!")
                        return True
                    else:
                        logger.info(f"Pod {pod_id} ì‹¤í–‰ ì¤‘ì´ì§€ë§Œ ComfyUI ì•„ì§ ì¤€ë¹„ ì•ˆë¨")
                
                elif status.status in ["FAILED", "TERMINATED", "STOPPED"]:
                    logger.error(f"âŒ Pod {pod_id} ì‹¤íŒ¨ ìƒíƒœ: {status.status}")
                    return False
                
                elif status.status in ["STARTING", "CREATED"]:
                    logger.info(f"ğŸ”„ Pod {pod_id} ì‹œì‘ ì¤‘... ({status.status})")
                
                else:
                    logger.info(f"ğŸ”„ Pod {pod_id} ìƒíƒœ: {status.status}, ê³„ì† ëŒ€ê¸°...")
                
            except Exception as e:
                logger.warning(f"Pod {pod_id} ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            
            await asyncio.sleep(check_interval)
        
        logger.error(f"âŒ Pod {pod_id} ì¤€ë¹„ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ({max_wait_time}ì´ˆ)")
        return False
    
    async def _check_comfyui_ready(self, endpoint_url: str) -> bool:
        """ComfyUI API ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{endpoint_url}/history",
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    return response.status == 200
        except:
            return False
    
    async def _get_optimal_gpu_type(self) -> str:
        """ìµœì ì˜ GPU íƒ€ì… ì„ íƒ (RTX 4090 â†’ RTX A5000 í´ë°±)"""
        
        # GPU ê°€ìš©ì„± ì¡°íšŒ
        try:
            gpu_availability = await self._check_gpu_availability()
            
            # GPU ìš°ì„ ìˆœìœ„: RTX 4090 â†’ A6000 â†’ A5000 â†’ A40
            gpu_priorities = [
                ("RTX_4090", "NVIDIA GeForce RTX 4090", "RTX 4090"),
                ("RTX_A6000", "NVIDIA RTX A6000", "RTX A6000"),
                ("RTX_A5000", "NVIDIA RTX A5000", "RTX A5000"),
                ("RTX_A40", "NVIDIA A40", "RTX A40")
            ]
            
            for gpu_key, gpu_id, gpu_name in gpu_priorities:
                if gpu_availability.get(gpu_key, False):
                    logger.info(f"{gpu_name} ì‚¬ìš© ê°€ëŠ¥ - ì„ íƒë¨")
                    return gpu_id
            
            # ëª¨ë“  GPU ì‚¬ìš© ë¶ˆê°€
            available_gpus = [k for k, v in gpu_availability.items() if v]
            logger.error(f"ìš°ì„ ìˆœìœ„ GPU ëª¨ë‘ ì‚¬ìš© ë¶ˆê°€. ê°€ìš© GPU: {available_gpus}")
            raise Exception("í˜„ì¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìì›ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!")
            
        except Exception as e:
            logger.error(f"GPU íƒ€ì… ì„ íƒ ì‹¤íŒ¨: {e}")
            raise Exception("í˜„ì¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìì›ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!")

    async def _get_fallback_gpu_type(self, failed_gpu: str) -> str:
        """ì‹¤íŒ¨í•œ GPUì— ëŒ€í•œ í´ë°± GPU íƒ€ì… ë°˜í™˜"""
        # GPU í´ë°± ì²´ì¸: RTX 4090 â†’ A6000 â†’ A5000 â†’ A40
        if "RTX 4090" in failed_gpu:
            logger.info("RTX 4090 ì‹¤íŒ¨ - RTX A6000ìœ¼ë¡œ í´ë°±")
            return "NVIDIA RTX A6000"
        elif "RTX A6000" in failed_gpu or "A6000" in failed_gpu:
            logger.info("RTX A6000 ì‹¤íŒ¨ - RTX A5000ìœ¼ë¡œ í´ë°±")
            return "NVIDIA RTX A5000"
        elif "RTX A5000" in failed_gpu or "A5000" in failed_gpu:
            logger.info("RTX A5000 ì‹¤íŒ¨ - A40ìœ¼ë¡œ í´ë°±")
            return "NVIDIA A40"
        else:
            logger.info("ëª¨ë“  í´ë°± GPU ì‹¤íŒ¨ - ì˜µì…˜ ì—†ìŒ")
            raise Exception("í˜„ì¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìì›ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!")
    
    async def _check_gpu_availability(self) -> dict:
        """GPU ê°€ìš©ì„± í™•ì¸"""
        
        # RunPod GPU íƒ€ì… ì¡°íšŒ ì¿¼ë¦¬ (stockStatus í•„ë“œëŠ” ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°)
        query = """
        query {
            gpuTypes {
                id
                displayName
                memoryInGb
                secureCloud
                communityCloud
                lowestPrice(input: {gpuCount: 1}) {
                    minimumBidPrice
                    uninterruptablePrice
                }
            }
        }
        """
        
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            async with aiohttp.ClientSession() as session:
                payload = {"query": query}
                
                async with session.post(
                    self.base_url,
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status != 200:
                        response_text = await response.text()
                        logger.error(f"GPU ê°€ìš©ì„± ì¡°íšŒ ì‹¤íŒ¨: {response.status}")
                        logger.error(f"ì‘ë‹µ ë‚´ìš©: {response_text}")
                        return {}
                    
                    data = await response.json()
                    gpu_types = data.get("data", {}).get("gpuTypes", [])
                    
                    availability = {}
                    for gpu in gpu_types:
                        display_name = gpu.get("displayName", "")
                        lowest_price = gpu.get("lowestPrice", {})
                        
                        # ê°€ê²© ì •ë³´ê°€ ìˆìœ¼ë©´ ê°€ìš©í•˜ë‹¤ê³  íŒë‹¨
                        min_bid_price = lowest_price.get("minimumBidPrice")
                        uninterruptable_price = lowest_price.get("uninterruptablePrice", 0)
                        
                        has_price = (
                            (min_bid_price is not None and min_bid_price > 0) or 
                            (uninterruptable_price is not None and uninterruptable_price > 0)
                        )
                        
                        # GPU íƒ€ì…ë³„ í™•ì¸ (ìš°ì„ ìˆœìœ„ ìˆœ)
                        if "RTX 4090" in display_name or "4090" in display_name:
                            availability["RTX_4090"] = has_price
                        elif "RTX A6000" in display_name or "A6000" in display_name:
                            availability["RTX_A6000"] = has_price
                        elif "RTX A5000" in display_name or "A5000" in display_name:
                            availability["RTX_A5000"] = has_price
                        elif "A40" in display_name:
                            availability["RTX_A40"] = has_price
                    
                    logger.info(f"GPU ê°€ìš©ì„±: {availability}")
                    return availability
                    
        except Exception as e:
            logger.error(f"GPU ê°€ìš©ì„± ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    
    async def debug_all_gpu_types(self) -> dict:
        """ë””ë²„ê¹…ìš©: ëª¨ë“  GPU íƒ€ì…ê³¼ ì‹¤ì œ ID ì¶œë ¥"""
        query = """
        query {
            gpuTypes {
                id
                displayName
                memoryInGb
                secureCloud
                communityCloud
                lowestPrice(input: {gpuCount: 1}) {
                    minimumBidPrice
                    uninterruptablePrice
                }
            }
        }
        """
        
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            async with aiohttp.ClientSession() as session:
                payload = {"query": query}
                
                async with session.post(
                    self.base_url,
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status != 200:
                        return {"error": f"Status {response.status}"}
                    
                    data = await response.json()
                    gpu_types = data.get("data", {}).get("gpuTypes", [])
                    
                    # RTX 4090 ê´€ë ¨ GPUë“¤ë§Œ í•„í„°ë§í•˜ì—¬ ìƒì„¸ ì •ë³´ ì¶œë ¥
                    rtx_gpus = {}
                    for gpu in gpu_types:
                        display_name = gpu.get("displayName", "")
                        gpu_id = gpu.get("id", "")
                        lowest_price = gpu.get("lowestPrice", {})
                        
                        # RTX, 4090, A6000, A5000, A40 ê´€ë ¨ GPUë§Œ ìˆ˜ì§‘
                        if any(keyword in display_name.upper() for keyword in ["RTX", "4090", "A6000", "A5000", "A40"]):
                            min_bid_price = lowest_price.get("minimumBidPrice")
                            uninterruptable_price = lowest_price.get("uninterruptablePrice")
                            has_price = (
                                (min_bid_price is not None and min_bid_price > 0) or 
                                (uninterruptable_price is not None and uninterruptable_price > 0)
                            )
                            
                            rtx_gpus[display_name] = {
                                "id": gpu_id,
                                "memory": gpu.get("memoryInGb", 0),
                                "available": has_price,
                                "min_bid": min_bid_price,
                                "uninterruptable": uninterruptable_price
                            }
                    
                    logger.info("=== RTX GPU ë””ë²„ê¹… ì •ë³´ ===")
                    for name, info in rtx_gpus.items():
                        logger.info(f"GPU: {name}")
                        logger.info(f"  ID: {info['id']}")
                        logger.info(f"  ë©”ëª¨ë¦¬: {info['memory']}GB")
                        logger.info(f"  ê°€ìš©: {info['available']}")
                        logger.info(f"  ìµœì†Œ ë¹„ìš©: {info['min_bid']}")
                        logger.info(f"  ê³ ì • ë¹„ìš©: {info['uninterruptable']}")
                        logger.info("---")
                    
                    return rtx_gpus
                    
        except Exception as e:
            logger.error(f"GPU ë””ë²„ê¹… ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    async def _get_full_gpu_list(self) -> list:
        """ì „ì²´ GPU ëª©ë¡ ì¡°íšŒ (ë””ë²„ê¹…ìš©)"""
        query = """
        query {
            gpuTypes {
                id
                displayName
                memoryInGb
                secureCloud
                communityCloud
                lowestPrice(input: {gpuCount: 1}) {
                    minimumBidPrice
                    uninterruptablePrice
                }
            }
        }
        """
        
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            async with aiohttp.ClientSession() as session:
                payload = {"query": query}
                
                async with session.post(
                    self.base_url,
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status != 200:
                        return []
                    
                    data = await response.json()
                    return data.get("data", {}).get("gpuTypes", [])
                    
        except Exception as e:
            logger.error(f"GPU ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    


# ì‹±ê¸€í†¤ íŒ¨í„´
_runpod_service_instance = None

def get_runpod_service() -> RunPodService:
    """RunPod ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _runpod_service_instance
    if _runpod_service_instance is None:
        _runpod_service_instance = RunPodService()
    return _runpod_service_instance