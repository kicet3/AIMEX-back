#!/usr/bin/env python3
"""
OpenAI λ°°μΉ μ‘μ—… λ¨λ‹ν„°λ§ μ„λΉ„μ¤
ν΄λ§ λ¨λ“μ—μ„ μ£ΌκΈ°μ μΌλ΅ λ°°μΉ μƒνƒλ¥Ό ν™•μΈν•κ³  μ™„λ£λ μ‘μ—…μ„ μ²λ¦¬ν•©λ‹λ‹¤.
"""

import asyncio
import logging
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from sqlalchemy.orm import Session

from app.core.config import settings
from app.database import get_db
from app.models.influencer import BatchKey
from app.services.influencers.qa_generator import InfluencerQAGenerator
from app.services.finetuning_service import get_finetuning_service

logger = logging.getLogger(__name__)


class BatchMonitor:
    """OpenAI λ°°μΉ μ‘μ—… λ¨λ‹ν„°λ§ ν΄λμ¤"""
    
    def __init__(self):
        self.qa_generator = InfluencerQAGenerator()
        self.finetuning_service = get_finetuning_service()
        self.is_running = False
        self.monitor_task: Optional[asyncio.Task] = None
    
    async def start_monitoring(self):
        """λ¨λ‹ν„°λ§ μ‹μ‘"""
        if settings.OPENAI_MONITORING_MODE != 'polling':
            logger.info("π“Ά ν΄λ§ λ¨λ“κ°€ μ•„λ‹λ―€λ΅ λ°°μΉ λ¨λ‹ν„°λ§μ„ μ‹μ‘ν•μ§€ μ•μµλ‹λ‹¤")
            return
        
        if self.is_running:
            logger.warning("β οΈ λ°°μΉ λ¨λ‹ν„°λ§μ΄ μ΄λ―Έ μ‹¤ν–‰ μ¤‘μ…λ‹λ‹¤")
            return
        
        self.is_running = True
        logger.info(f"π”„ λ°°μΉ λ¨λ‹ν„°λ§ μ‹μ‘ - κ°„κ²©: {settings.OPENAI_POLLING_INTERVAL_MINUTES}λ¶„")
        
        self.monitor_task = asyncio.create_task(self._monitor_loop())
    
    async def stop_monitoring(self):
        """λ¨λ‹ν„°λ§ μ¤‘μ§€"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
        
        logger.info("βΉοΈ λ°°μΉ λ¨λ‹ν„°λ§μ΄ μ¤‘μ§€λμ—μµλ‹λ‹¤")
    
    async def _monitor_loop(self):
        """λ¨λ‹ν„°λ§ λ£¨ν”„"""
        while self.is_running:
            try:
                await self._check_batch_status()
                
                # λ‹¤μ μ²΄ν¬κΉμ§€ λ€κΈ°
                interval_seconds = settings.OPENAI_POLLING_INTERVAL_MINUTES * 60
                await asyncio.sleep(interval_seconds)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"β λ°°μΉ λ¨λ‹ν„°λ§ μ¤‘ μ¤λ¥ λ°μƒ: {e}", exc_info=True)
                # μ¤λ¥ λ°μƒ μ‹ 30μ΄ ν›„ μ¬μ‹λ„
                await asyncio.sleep(30)
    
    async def check_and_update_single_job(self, batch_key: BatchKey, db: Session):
        """κ°λ³„ λ°°μΉ μ‘μ—…μ ν„μ¬ μƒνƒλ¥Ό ν™•μΈν•κ³  DBλ¥Ό μ—…λ°μ΄νΈ"""
        try:
            if not batch_key.openai_batch_id:
                logger.warning(f"β οΈ OpenAI λ°°μΉ IDκ°€ μ—†μ: {batch_key.batch_key_id}")
                return

            # OpenAI λ°°μΉ μƒνƒ ν™•μΈ
            batch_status = self.qa_generator.check_batch_status(batch_key.openai_batch_id)
            current_status = batch_status.get('status')
            logger.debug(f"π“‹ λ°°μΉ {batch_key.batch_key_id} ν„μ¬ μƒνƒ: {current_status}")

            # μƒνƒμ— λ”°λ¥Έ μ²λ¦¬
            if current_status == 'completed':
                await self._handle_completed_batch(batch_key, db, batch_status)
            elif current_status == 'failed':
                await self._handle_failed_batch(batch_key, batch_status, db)
            elif current_status in ['validating', 'in_progress']:
                await self._handle_processing_batch(batch_key, db)
            else:
                logger.debug(f"π“ λ°°μΉ {batch_key.batch_key_id}λ” μ—¬μ „ν {current_status} μƒνƒμ…λ‹λ‹¤")

        except Exception as e:
            logger.error(f"β λ°°μΉ {batch_key.batch_key_id} μ²λ¦¬ μ¤‘ μ¤λ¥: {e}", exc_info=True)
            db.rollback() # μ¤λ¥ λ°μƒ μ‹ λ΅¤λ°±

    async def _check_batch_status(self):
        """λ¨λ“  μ§„ν–‰ μ¤‘μΈ λ°°μΉ μ‘μ—… μƒνƒ ν™•μΈ"""
        logger.debug("π” λ°°μΉ μƒνƒ ν™•μΈ μ‹μ‘")
        
        db: Session = next(get_db())
        try:
            # μ§„ν–‰ μ¤‘μΈ λ°°μΉ μ‘μ—… μ΅°ν (λ¨λ“  λ―Έμ™„λ£ μƒνƒ ν¬ν•¨)
            pending_batches = db.query(BatchKey).filter(
                BatchKey.status.in_(['pending', 'processing', 'batch_submitted', 'batch_processing', 'in_progress'])
            ).all()
            
            if not pending_batches:
                logger.debug("π“­ μ§„ν–‰ μ¤‘μΈ λ°°μΉ μ‘μ—…μ΄ μ—†μµλ‹λ‹¤")
                return
            
            logger.info(f"π“ {len(pending_batches)}κ°μ μ§„ν–‰ μ¤‘μΈ λ°°μΉ μ‘μ—… ν™•μΈ μ¤‘")
            
            for batch_key in pending_batches:
                await self.check_and_update_single_job(batch_key, db)
                
        except Exception as e:
            logger.error(f"β _check_batch_status μ²λ¦¬ μ¤‘ μ¤λ¥: {e}", exc_info=True)
            db.rollback() # μ¤λ¥ λ°μƒ μ‹ λ΅¤λ°±
        finally:
            db.close()
    
    async def _handle_completed_batch(self, batch_key: BatchKey, db: Session, batch_status: Dict):
        """μ™„λ£λ λ°°μΉ μ²λ¦¬"""
        logger.info(f"β… λ°°μΉ μ™„λ£ κ°μ§€: {batch_key.batch_key_id}")
        logger.info(f"π“ λ°°μΉ μƒμ„Έ μ •λ³΄: task_id={batch_key.task_id}, influencer_id={batch_key.influencer_id}, openai_batch_id={batch_key.openai_batch_id}")
        
        try:
            # QA μƒμ„± μ™„λ£ μ²λ¦¬
            logger.info(f"π”„ QA μƒμ„± μ™„λ£ μ²λ¦¬ μ‹μ‘: task_id={batch_key.task_id}")
            success = self.qa_generator.complete_qa_generation(batch_key.task_id, db)
            
            if success:
                # λ°°μΉ μƒνƒ μ—…λ°μ΄νΈ
                batch_key.status = 'completed'
                batch_key.completed_at = datetime.now()
                batch_key.is_processed = True
                batch_key.output_file_id = batch_status.get('output_file_id') # output_file_id μ €μ¥
                batch_key.is_uploaded_to_s3 = False # S3 μ—…λ΅λ“ ν•„μ” ν‘μ‹
                
                db.commit()
                
                logger.info(f"π‰ λ°°μΉ {batch_key.batch_key_id} QA μƒμ„± μ™„λ£ μ²λ¦¬λ¨")
                
                # νμΈνλ‹ μ‹μ‘ (AUTO_FINETUNING_ENABLEDκ°€ trueμΈ κ²½μ°)
                if settings.AUTO_FINETUNING_ENABLED:
                    logger.info(f"π€ μλ™ νμΈνλ‹ μ‹μ‘: batch_key_id={batch_key.batch_key_id}")
                    await self._start_finetuning(batch_key, db) # db μ„Έμ… μ „λ‹¬
                else:
                    logger.info(f"βΈοΈ μλ™ νμΈνλ‹ λΉ„ν™μ„±ν™”λ¨: AUTO_FINETUNING_ENABLED={settings.AUTO_FINETUNING_ENABLED}")
                
            else:
                logger.error(f"β λ°°μΉ {batch_key.batch_key_id} QA μƒμ„± μ™„λ£ μ²λ¦¬ μ‹¤ν¨")
                
        except Exception as e:
            logger.error(f"β μ™„λ£λ λ°°μΉ {batch_key.batch_key_id} μ²λ¦¬ μ¤‘ μ¤λ¥: {e}", exc_info=True)
            db.rollback() # μ¤λ¥ λ°μƒ μ‹ λ΅¤λ°±
    
    async def _handle_failed_batch(self, batch_key: BatchKey, batch_status: Dict, db: Session):
        """μ‹¤ν¨ν• λ°°μΉ μ²λ¦¬"""
        logger.error(f"β λ°°μΉ μ‹¤ν¨ κ°μ§€: {batch_key.batch_key_id}")
        
        try:
            batch_key.status = 'failed'
            batch_key.error_message = f"OpenAI λ°°μΉ μ‘μ—… μ‹¤ν¨: {batch_status.get('status', 'Unknown error')}"
            batch_key.completed_at = datetime.now()
            
            db.commit()
            
            logger.error(f"π’¥ λ°°μΉ {batch_key.batch_key_id} μ‹¤ν¨λ΅ ν‘μ‹λ¨")
        except Exception as e:
            logger.error(f"β μ‹¤ν¨ λ°°μΉ {batch_key.batch_key_id} μ²λ¦¬ μ¤‘ μ¤λ¥: {e}", exc_info=True)
            db.rollback() # μ¤λ¥ λ°μƒ μ‹ λ΅¤λ°±
    
    async def _handle_processing_batch(self, batch_key: BatchKey, db: Session):
        """μ§„ν–‰ μ¤‘μΈ λ°°μΉ μƒνƒ μ—…λ°μ΄νΈ"""
        try:
            if batch_key.status != 'batch_processing':
                batch_key.status = 'batch_processing'
                db.commit()
                logger.debug(f"π”„ λ°°μΉ {batch_key.batch_key_id} μƒνƒλ¥Ό processingμΌλ΅ μ—…λ°μ΄νΈ")
        except Exception as e:
            logger.error(f"β μ§„ν–‰ μ¤‘μΈ λ°°μΉ {batch_key.batch_key_id} μ²λ¦¬ μ¤‘ μ¤λ¥: {e}", exc_info=True)
            db.rollback() # μ¤λ¥ λ°μƒ μ‹ λ΅¤λ°±
    
    async def _start_finetuning(self, batch_key: BatchKey, db: Session):
        """νμΈνλ‹ μ‹μ‘"""
        try:
            if batch_key.is_finetuning_started:
                logger.info(f"β„ΉοΈ λ°°μΉ {batch_key.batch_key_id}λ” μ΄λ―Έ νμΈνλ‹μ΄ μ‹μ‘λ¨")
                return
            
            logger.info(f"π€ λ°°μΉ {batch_key.batch_key_id}μ— λ€ν• νμΈνλ‹ μ‹μ‘")
            
            # S3 URL ν™•μΈ λ° μμ •
            s3_qa_url = batch_key.s3_qa_file_url
            
            # μλ»λ URLμΈ κ²½μ° μμ • (μ„μ‹ μ΅°μΉ)
            if s3_qa_url and 'generated_qa_results.jsonl' in s3_qa_url:
                logger.warning(f"β οΈ μλ»λ S3 URL κ°μ§€, μ²λ¦¬λ QA URLλ΅ λ³€κ²½ μ‹λ„")
                # processed_qa νμΌ URLλ΅ λ³€κ²½
                s3_qa_url = s3_qa_url.replace('qa_results/', 'qa_pairs/').replace('generated_qa_results.jsonl', f'processed_qa_{batch_key.task_id.split("_")[-1]}.json')
                logger.info(f"π“ μμ •λ S3 URL: {s3_qa_url}")
            
            # νμΈνλ‹ μ„λΉ„μ¤ νΈμ¶ (task_id μ „λ‹¬)
            result = await self.finetuning_service.start_finetuning_for_influencer(
                batch_key.influencer_id,
                s3_qa_url,
                db,
                task_id=batch_key.task_id
            )
            
            if result:
                # νμΈνλ‹ μ‹μ‘ ν”λκ·Έ μ—…λ°μ΄νΈ
                batch_key.is_finetuning_started = True
                db.commit()
                logger.info(f"β… λ°°μΉ {batch_key.batch_key_id} νμΈνλ‹ μ‹μ‘ μ™„λ£")
            
        except Exception as e:
            logger.error(f"β λ°°μΉ {batch_key.batch_key_id} νμΈνλ‹ μ‹μ‘ μ‹¤ν¨: {e}", exc_info=True)
            db.rollback() # μ¤λ¥ λ°μƒ μ‹ λ΅¤λ°±


# μ „μ—­ λ¨λ‹ν„° μΈμ¤ν„΄μ¤
batch_monitor = BatchMonitor()


async def start_batch_monitoring():
    """λ°°μΉ λ¨λ‹ν„°λ§ μ‹μ‘"""
    await batch_monitor.start_monitoring()


async def stop_batch_monitoring():
    """λ°°μΉ λ¨λ‹ν„°λ§ μ¤‘μ§€"""
    await batch_monitor.stop_monitoring()


def get_batch_monitor() -> BatchMonitor:
    """λ°°μΉ λ¨λ‹ν„° μμ΅΄μ„± μ£Όμ…"""
    return batch_monitor