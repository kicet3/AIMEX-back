#!/usr/bin/env python3
"""
ì¸í”Œë£¨ì–¸ì„œ ì „ìš© QA ìƒì„± ì„œë¹„ìŠ¤
speech_generatorì™€ generate_qa ë¡œì§ì„ í™œìš©í•˜ì—¬ ì¸í”Œë£¨ì–¸ì„œë³„ 2000ìŒì˜ QA ìƒì„±
"""

import json
import os
import time
import random
import tempfile
import logging
import requests
from typing import List, Dict, Optional
from openai import OpenAI
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
from sqlalchemy.orm import Session

from app.database import get_db
from app.services.influencers.crud import get_influencer_by_id
from app.models.influencer import BatchKey
from app.core.config import settings
# Backend ë‚´ë¶€ ëª¨ë¸ ì‚¬ìš©
from app.models.vllm_models import Gender, VLLMCharacterProfile

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
CharacterProfile = VLLMCharacterProfile

class SpeechGenerator:
    """vLLM ì„œë²„ ëŒ€ì‹  HTTP API í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©"""
    def __init__(self, *args, **kwargs):
        pass
    
    def generate_character_random_tones_sync(self, *args, **kwargs):
        raise RuntimeError("ì´ ë©”ì„œë“œëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. vLLM ì„œë²„ APIë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")


class QAGenerationStatus(Enum):
    PENDING = "pending"
    TONE_GENERATION = "tone_generation"      # ì–´íˆ¬ ìƒì„± ì¤‘
    DOMAIN_PREPARATION = "domain_preparation" # ë„ë©”ì¸ë³„ ì§ˆë¬¸ ì¤€ë¹„
    PROCESSING = "processing"  
    BATCH_SUBMITTED = "batch_submitted"
    BATCH_PROCESSING = "batch_processing"
    BATCH_COMPLETED = "batch_completed"
    BATCH_UPLOAD = "batch_upload"            # S3 ì—…ë¡œë“œ ì¤‘
    PROCESSING_RESULTS = "processing_results"
    COMPLETED = "completed"
    FINALIZED = "finalized"
    FAILED = "failed"


class InfluencerQAGenerator:
    def __init__(self, api_key: Optional[str] = None):
        """
        ì¸í”Œë£¨ì–¸ì„œìš© QA ìƒì„±ê¸°
        Args:
            api_key: OpenAI API í‚¤
        """
        self.client = OpenAI(api_key=api_key or os.getenv('OPENAI_API_KEY'))
        self.speech_generator = SpeechGenerator(api_key)
        
    def influencer_to_character_profile(self, influencer_data: dict, style_preset: dict = None, mbti: dict = None) -> CharacterProfile:
        """
        ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ë¥¼ CharacterProfileë¡œ ë³€í™˜
        Args:
            influencer_data: DBì—ì„œ ê°€ì ¸ì˜¨ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°
            style_preset: ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ ë°ì´í„°
            mbti: MBTI ë°ì´í„°
        Returns:
            CharacterProfile ê°ì²´
        """
        # ì„±ë³„ ë§¤í•‘ (influencer_gender: 1=ë‚¨ì„±, 2=ì—¬ì„±, 3=ì¤‘ì„±)
        gender_map = {
            1: Gender.MALE,
            2: Gender.FEMALE, 
            3: Gender.NON_BINARY
        }
        
        # ë‚˜ì´ëŒ€ ë§¤í•‘ (influencer_age_group: 1=10ëŒ€, 2=20ëŒ€, 3=30ëŒ€, 4=40ëŒ€, 5=50ëŒ€+)
        age_group_map = {
            1: 15,  # 10ëŒ€
            2: 25,  # 20ëŒ€  
            3: 35,  # 30ëŒ€
            4: 45,  # 40ëŒ€
            5: 55   # 50ëŒ€+
        }
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        name = influencer_data.get('influencer_name', 'ì¸í”Œë£¨ì–¸ì„œ')
        description = influencer_data.get('influencer_description', '')
        
        # ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ì—ì„œ ì •ë³´ ì¶”ì¶œ
        if style_preset:
            gender = gender_map.get(style_preset.get('influencer_gender'), Gender.NON_BINARY)
            age_group = style_preset.get('influencer_age_group')
            age_range = f"{age_group_map.get(age_group, 25)}ëŒ€" if age_group else "ì•Œ ìˆ˜ ì—†ìŒ"
            personality = style_preset.get('influencer_personality', 'ì¹œê·¼í•˜ê³  í™œë°œí•œ ì„±ê²©')
            
            # ì„¤ëª…ì— ìŠ¤íƒ€ì¼ ì •ë³´ ì¶”ê°€
            if not description:
                hairstyle = style_preset.get('influencer_hairstyle', '')
                style = style_preset.get('influencer_style', '')
                speech = style_preset.get('influencer_speech', '')
                description = f"í—¤ì–´ìŠ¤íƒ€ì¼: {hairstyle}, ìŠ¤íƒ€ì¼: {style}, ë§íˆ¬: {speech}"
        else:
            gender = Gender.NON_BINARY
            age_range = "ì•Œ ìˆ˜ ì—†ìŒ"
            personality = 'ì¹œê·¼í•˜ê³  í™œë°œí•œ ì„±ê²©'
            
        # MBTI ì •ë³´ ì¶”ì¶œ
        if mbti:
            mbti_type = mbti.get('mbti_name')
            if not mbti_type:
                mbti_type = "ì•Œ ìˆ˜ ì—†ìŒ"
            # ì„±ê²©ì— MBTI íŠ¹ì„± ì¶”ê°€
            mbti_traits = mbti.get('mbti_traits', '')
            if mbti_traits:
                personality += f" ({mbti_traits})"
        else:
            mbti_type = None
            
        return CharacterProfile(
            name=name,
            description=description,
            age_range=age_range,
            gender=gender,
            personality=personality,
            mbti=mbti_type
        )
    
    def create_qa_batch_requests(self, character: CharacterProfile, num_requests: int = None, system_prompt: str = None) -> List[Dict]:
        """
        ì¸í”Œë£¨ì–¸ì„œ ìºë¦­í„°ë¥¼ ìœ„í•œ QA ìƒì„± ë°°ì¹˜ ìš”ì²­ ìƒì„±
        VLLM ì„œë²„ì—ì„œ ì§ì ‘ OpenAI Batch API í˜•ì‹ì˜ JSONLì„ ìƒì„±
        Args:
            character: ìºë¦­í„° í”„ë¡œí•„
            num_requests: ìƒì„±í•  QA ê°œìˆ˜ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ QA_GENERATION_COUNT ì‚¬ìš©)
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        Returns:
            ë°°ì¹˜ ìš”ì²­ ë¦¬ìŠ¤íŠ¸ (OpenAI Batch API í˜•ì‹)
        """
        if num_requests is None:
            num_requests = settings.QA_GENERATION_COUNT
        
        print(f"QA ìƒì„± ìš”ì²­: {num_requests}ê°œ (í™˜ê²½ë³€ìˆ˜ QA_GENERATION_COUNT: {settings.QA_GENERATION_COUNT})")
        
        # VLLM ì„œë²„ URL ì„¤ì •
        vllm_server_url = getattr(settings, 'VLLM_SERVER_URL', 'http://localhost:8001')
        
        # VLLM ì„œë²„ì— ìš”ì²­í•  ìºë¦­í„° í”„ë¡œí•„ ë°ì´í„° ì¤€ë¹„
        character_data = {
            "name": character.name,
            "description": character.description,
            "age_range": character.age_range,
            "gender": character.gender.value if hasattr(character.gender, 'value') else character.gender if character.gender else "ì—†ìŒ",
            "personality": character.personality,
            "mbti": character.mbti
        }
        
        # VLLM ì„œë²„ì—ì„œ JSONL ìƒì„± ì‘ì—… ì‹œì‘ (ìƒˆë¡œìš´ QA ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
        try:
            print(f"VLLM ì„œë²„ì— {num_requests}ê°œ QA JSONL ìƒì„± ì‘ì—… ì‹œì‘ ìš”ì²­...")
            
            # ìƒˆë¡œìš´ QA ìƒì„± ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            response = requests.post(
                f"{vllm_server_url}/qa/generate_qa_for_influencer",
                json={
                    "character": character_data,
                    "num_qa_pairs": num_requests,
                    "domains": ["ì¼ìƒìƒí™œ", "ê³¼í•™ê¸°ìˆ ", "ì‚¬íšŒì´ìŠˆ", "ì¸ë¬¸í•™", "ìŠ¤í¬ì¸ ", "ì—­ì‚¬ë¬¸í™”"],
                    "system_prompt": system_prompt
                },
                timeout=30
            )
            
            if response.status_code == 200:
                task_data = response.json()
                task_id = task_data.get('task_id')
                
                print(f"VLLM ì„œë²„ QA JSONL ìƒì„± ì‘ì—… ì‹œì‘ ì„±ê³µ: task_id={task_id}")
                
                # ì‘ì—… ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (ìƒˆë¡œìš´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
                batch_requests = self._wait_for_qa_completion(vllm_server_url, task_id)
                
                if batch_requests:
                    print(f"QA JSONL ìƒì„± ì™„ë£Œ: {len(batch_requests)}ê°œ ë°°ì¹˜ ìš”ì²­")
                    return batch_requests
                else:
                    print("QA JSONL ìƒì„± ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    raise Exception("vLLM ì„œë²„ì—ì„œ QA JSONL ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
            else:
                print(f"VLLM ì„œë²„ QA JSONL ìƒì„± ì‘ì—… ì‹œì‘ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                raise Exception(f"vLLM ì„œë²„ QA JSONL ìƒì„± ì‘ì—… ì‹œì‘ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                
        except Exception as e:
            print(f"VLLM ì„œë²„ QA JSONL ìƒì„± ì˜¤ë¥˜: {e}")
            raise Exception(f"vLLM ì„œë²„ QA JSONL ìƒì„± ì˜¤ë¥˜: {e}")
    
    def _wait_for_qa_completion(self, vllm_server_url: str, task_id: str, max_wait_time: int = 1800) -> List[Dict]:
        """
        QA ìƒì„± ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜ (ìƒˆë¡œìš´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
        Args:
            vllm_server_url: VLLM ì„œë²„ URL
            task_id: ì‘ì—… ID
            max_wait_time: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ 30ë¶„)
        Returns:
            OpenAI Batch API í˜•ì‹ì˜ ë°°ì¹˜ ìš”ì²­ ë¦¬ìŠ¤íŠ¸
        """
        import time
        
        start_time = time.time()
        check_interval = 5  # 5ì´ˆë§ˆë‹¤ ìƒíƒœ í™•ì¸
        
        print(f"QA ìƒì„± ì‘ì—… ì™„ë£Œ ëŒ€ê¸° ì¤‘: task_id={task_id}")
        
        while time.time() - start_time < max_wait_time:
            try:
                # ìƒˆë¡œìš´ QA ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
                status_response = requests.get(
                    f"{vllm_server_url}/qa/qa_status/{task_id}",
                    timeout=10
                )
                
                if status_response.status_code == 200:
                    status_data = status_response.json()
                    status = status_data.get('status')
                    progress = status_data.get('progress', 0)
                    completed = status_data.get('completed', 0)
                    total_qa_pairs = status_data.get('total_qa_pairs', 0)
                    domains = status_data.get('domains', [])
                    
                    print(f"QA ìƒì„± ì§„í–‰ ìƒí™©: {progress:.1f}% ({completed}/{total_qa_pairs}), ë„ë©”ì¸: {', '.join(domains)}")
                    
                    if status == "completed":
                        # ìƒˆë¡œìš´ QA ê²°ê³¼ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
                        result_response = requests.get(
                            f"{vllm_server_url}/qa/qa_results/{task_id}",
                            timeout=30
                        )
                        
                        if result_response.status_code == 200:
                            result_data = result_response.json()
                            batch_requests = result_data.get('batch_requests', [])
                            total_requests = result_data.get('total_requests', 0)
                            domains = result_data.get('domains', [])
                            
                            print(f"QA ìƒì„± ì™„ë£Œ: {total_requests}ê°œ ë°°ì¹˜ ìš”ì²­, ë„ë©”ì¸: {', '.join(domains)}")
                            return batch_requests
                        else:
                            print(f"QA ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {result_response.status_code}")
                            return []
                    
                    elif status == "failed":
                        error_msg = status_data.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                        print(f"QA ìƒì„± ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {error_msg}")
                        return []
                    
                    # ì•„ì§ ì§„í–‰ ì¤‘ì´ë©´ ëŒ€ê¸°
                    time.sleep(check_interval)
                    
                else:
                    print(f"QA ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {status_response.status_code}")
                    time.sleep(check_interval)
                    
            except Exception as e:
                print(f"QA ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
                time.sleep(check_interval)
        
        print(f"QA ìƒì„± ì‘ì—… ì‹œê°„ ì´ˆê³¼: {max_wait_time}ì´ˆ")
        return []

    # í´ë°± QA ìš”ì²­ ìƒì„± ë©”ì„œë“œëŠ” ì œê±°ë¨ - vLLM ì„œë²„ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ

    def _create_qa_batch_requests_from_results(self, qa_results: List[Dict], character: CharacterProfile, system_prompt: str) -> List[Dict]:
        """
        VLLM ì„œë²„ì—ì„œ ìƒì„±ëœ QA ê²°ê³¼ë¥¼ ë°°ì¹˜ ìš”ì²­ìœ¼ë¡œ ë³€í™˜
        Args:
            qa_results: VLLM ì„œë²„ì—ì„œ ìƒì„±ëœ QA ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            character: ìºë¦­í„° í”„ë¡œí•„
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        Returns:
            ë°°ì¹˜ ìš”ì²­ ë¦¬ìŠ¤íŠ¸
        """
        batch_requests = []
        
        for i, qa_result in enumerate(qa_results):
            question = qa_result.get('question', '')
            responses = qa_result.get('responses', {})
            
            # ê° ë§íˆ¬ë³„ ì‘ë‹µì„ ê°œë³„ ë°°ì¹˜ ìš”ì²­ìœ¼ë¡œ ìƒì„±
            for tone_name, tone_responses in responses.items():
                if tone_responses and len(tone_responses) > 0:
                    tone_response = tone_responses[0]  # ì²« ë²ˆì§¸ ì‘ë‹µ ì‚¬ìš©
                    answer_text = tone_response.get('text', '')
                    
                    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ìºë¦­í„° ì •ë³´ë¥¼ ê²°í•©
                    enhanced_system_prompt = f"{system_prompt}\n\nìºë¦­í„° ì •ë³´:\n- ì´ë¦„: {character.name}\n- ì„±ê²©: {character.personality}\n- ë§íˆ¬: {tone_name}"
                    
                    request = {
                        "custom_id": f"influencer_qa_{character.name}_{i + 1}_{tone_name}",
                        "method": "POST",
                        "url": "/v1/chat/completions",
                        "body": {
                            "model": "gpt-4o-mini",
                            "messages": [
                                {
                                    "role": "system",
                                    "content": enhanced_system_prompt
                                },
                                {
                                    "role": "user",
                                    "content": f"Q: {question}\nA: {answer_text}\n\nìœ„ QA ìŒì„ ê²€í† í•˜ê³  ê°œì„ í•´ì£¼ì„¸ìš”."
                                }
                            ],
                            "max_tokens": 500,
                            "temperature": 0.7
                        }
                    }
                    
                    batch_requests.append(request)
        
        return batch_requests
    
    def save_batch_file(self, requests: List[Dict], task_id: str) -> str:
        """ë°°ì¹˜ ìš”ì²­ì„ JSONL íŒŒì¼ë¡œ ì €ì¥"""
        filename = f"influencer_qa_batch_{task_id}.jsonl"
        # OSì— ë§ëŠ” ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        temp_dir = tempfile.gettempdir()
        filepath = os.path.join(temp_dir, filename)
        
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±
        os.makedirs(temp_dir, exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for request in requests:
                f.write(json.dumps(request, ensure_ascii=False) + '\n')
        
        print(f"ë°°ì¹˜ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        return filepath
    
    def submit_batch_job(self, batch_file_path: str, task_id: str) -> str:
        """OpenAI ë°°ì¹˜ ì‘ì—… ì œì¶œ"""
        print(f"ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {batch_file_path}")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        with open(batch_file_path, 'rb') as f:
            batch_input_file = self.client.files.create(
                file=f,
                purpose="batch"
            )
        
        print(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {batch_input_file.id}")
        
        # ëª¨ë‹ˆí„°ë§ ë°©ì‹ í™•ì¸
        use_webhook = settings.OPENAI_MONITORING_MODE == 'webhook'
        
        batch_create_params = {
            "input_file_id": batch_input_file.id,
            "endpoint": "/v1/chat/completions",
            "completion_window": "24h",
            "metadata": {
                "description": f"Influencer QA pairs generation - Task ID: {task_id}",
                "task_id": task_id
            }
        }
        
        # ì›¹í›… ëª¨ë“œì¼ ë•Œë§Œ ì›¹í›… URL ì¶”ê°€
        if use_webhook:
            batch_create_params["metadata"]["webhook_url"] = settings.OPENAI_WEBHOOK_URL
            print(f"ğŸ¯ ì›¹í›… ëª¨ë“œë¡œ ë°°ì¹˜ ì‘ì—… ìƒì„± ì¤‘... (URL: {settings.OPENAI_WEBHOOK_URL})")
        else:
            print(f"ğŸ”„ í´ë§ ëª¨ë“œë¡œ ë°°ì¹˜ ì‘ì—… ìƒì„± ì¤‘... (ê°„ê²©: {settings.OPENAI_POLLING_INTERVAL_MINUTES}ë¶„)")
        
        # ë°°ì¹˜ ì‘ì—… ìƒì„±
        batch = self.client.batches.create(**batch_create_params)
        
        print(f"ë°°ì¹˜ ì‘ì—… ìƒì„± ì™„ë£Œ: {batch.id}")
        return batch.id
    
    def check_batch_status(self, batch_id: str) -> Dict:
        """ë°°ì¹˜ ì‘ì—… ìƒíƒœ í™•ì¸"""
        batch = self.client.batches.retrieve(batch_id)
        return {
            "id": batch.id,
            "status": batch.status,
            "request_counts": batch.request_counts.__dict__ if batch.request_counts else None,
            "created_at": batch.created_at,
            "completed_at": batch.completed_at,
            "output_file_id": batch.output_file_id if hasattr(batch, 'output_file_id') else None,
            "error_file_id": batch.error_file_id if hasattr(batch, 'error_file_id') else None
        }
    
    def download_batch_results(self, batch_id: str, task_id: str) -> Optional[str]:
        """ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
        batch = self.client.batches.retrieve(batch_id)
        
        if batch.status != "completed":
            print(f"ë°°ì¹˜ ì‘ì—…ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ: {batch.status}")
            return None
        
        if not batch.output_file_id:
            print("ì¶œë ¥ íŒŒì¼ IDê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        result_file_name = f"influencer_qa_results_{task_id}.jsonl"
        temp_dir = tempfile.gettempdir()
        result_file_path = os.path.join(temp_dir, result_file_name)
        
        file_response = self.client.files.content(batch.output_file_id)
        
        with open(result_file_path, 'wb') as f:
            f.write(file_response.content)
        
        print(f"ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {result_file_path}")
        return result_file_path
    
    def process_qa_results(self, result_file_path: str) -> List[Dict]:
        """ê²°ê³¼ íŒŒì¼ì—ì„œ QA ìŒ ì¶”ì¶œ"""
        qa_pairs = []
        
        with open(result_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                result = json.loads(line)
                
                if result.get('response', {}).get('status_code') == 200:
                    # ì‘ë‹µ ì»¨í…ì¸  ê°€ì ¸ì˜¤ê¸°
                    content = result['response']['body']['choices'][0]['message']['content'].strip()
                    
                    try:
                        # JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹± ì‹œë„ ({"q": "...", "a": "..."} í˜•ì‹)
                        qa_data = json.loads(content)
                        if isinstance(qa_data, dict) and 'q' in qa_data and 'a' in qa_data:
                            qa_pairs.append({
                                "question": qa_data['q'],
                                "answer": qa_data['a'],
                                "custom_id": result.get('custom_id')
                            })
                            continue
                    except json.JSONDecodeError:
                        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
                        pass
                    
                    # ê¸°ì¡´ í˜•ì‹ (Q: ... A: ...) ì²˜ë¦¬
                    if 'Q:' in content and 'A:' in content:
                        parts = content.split('A:', 1)
                        if len(parts) == 2:
                            question = parts[0].replace('Q:', '').strip()
                            answer = parts[1].strip()
                            qa_pairs.append({
                                "question": question,
                                "answer": answer,
                                "custom_id": result.get('custom_id')
                            })
                    else:
                        # JSONë„ ì•„ë‹ˆê³  Q:A: í˜•ì‹ë„ ì•„ë‹Œ ê²½ìš°
                        print(f"QA íŒŒì‹± ì‹¤íŒ¨ - ì»¨í…ì¸ : {content[:100]}...")
        
        return qa_pairs
    
    def save_qa_pairs_to_db(self, influencer_id: str, qa_pairs: List[Dict], db: Session):
        """ìƒì„±ëœ QA ìŒì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        # TODO: QA ìŒì„ ì €ì¥í•  í…Œì´ë¸”ì´ í•„ìš” (ì˜ˆ: influencer_qa_pairs)
        # í˜„ì¬ëŠ” JSON íŒŒì¼ë¡œ ì„ì‹œ ì €ì¥
        filename = f"influencer_{influencer_id}_qa_pairs.json"
        temp_dir = tempfile.gettempdir()
        filepath = os.path.join(temp_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(qa_pairs, f, ensure_ascii=False, indent=2)
        
        print(f"QA ìŒ {len(qa_pairs)}ê°œê°€ {filepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def start_qa_generation(self, influencer_id: str, db: Session, user_id: str = None) -> str:
        """
        ì¸í”Œë£¨ì–¸ì„œë¥¼ ìœ„í•œ QA ìƒì„± ì‹œì‘
        Args:
            influencer_id: ì¸í”Œë£¨ì–¸ì„œ ID
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            user_id: ì‚¬ìš©ì ID (ê¶Œí•œ í™•ì¸ìš©)
        Returns:
            ì‘ì—… ID
        """
        # ì‘ì—… ID ìƒì„±
        task_id = f"qa_{influencer_id}_{int(time.time())}"
        print(f"ğŸ¨ QA Generator: ì‘ì—… ì‹œì‘ - task_id={task_id}, influencer_id={influencer_id}")

        # BatchKey ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ DBì— ì‘ì—… ê¸°ë¡
        import uuid
        batch_key_entry = BatchKey(
            batch_key_id=str(uuid.uuid4()),
            batch_key=task_id,  # batch_key í•„ë“œì— task_id ê°’ ì„¤ì •
            task_id=task_id,
            influencer_id=influencer_id,
            status=QAGenerationStatus.PENDING.value,
            total_qa_pairs=settings.QA_GENERATION_COUNT
        )
        db.add(batch_key_entry)
        
        try:
            db.commit()
            db.refresh(batch_key_entry)

            # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì‚¬ìš©ì ê¶Œí•œ í™•ì¸)
            if user_id:
                # ì‚¬ìš©ì ê¶Œí•œìœ¼ë¡œ ì¸í”Œë£¨ì–¸ì„œ ì¡°íšŒ
                influencer_data = get_influencer_by_id(db, user_id, influencer_id)
            else:
                # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì˜ ê²½ìš° ì§ì ‘ ì¡°íšŒ (ê¶Œí•œ ìš°íšŒ)
                from app.models.influencer import AIInfluencer
                influencer_data = db.query(AIInfluencer).filter(AIInfluencer.influencer_id == influencer_id).first()
            
            if not influencer_data:
                raise Exception(f"ì¸í”Œë£¨ì–¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {influencer_id}")

            # ìƒíƒœ ì—…ë°ì´íŠ¸: PROCESSING
            batch_key_entry.status = QAGenerationStatus.PROCESSING.value
            db.commit()
            
            # ì¸í”Œë£¨ì–¸ì„œ â†’ ìºë¦­í„° í”„ë¡œí•„ ë³€í™˜
            character = self.influencer_to_character_profile(
                influencer_data.__dict__,
                influencer_data.style_preset.__dict__ if influencer_data.style_preset else None,
                influencer_data.mbti.__dict__ if influencer_data.mbti else None
            )
            
            # ì €ì¥ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            system_prompt = getattr(influencer_data, 'system_prompt', None)
            if system_prompt:
                print(f"âœ… ì €ì¥ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©: {system_prompt[:100]}...")
            else:
                print("âš ï¸ ì €ì¥ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì—†ì–´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
            
            # ë°°ì¹˜ ìš”ì²­ ìƒì„± (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬í•¨)
            batch_requests = self.create_qa_batch_requests(character, system_prompt=system_prompt)
            
            # ë°°ì¹˜ íŒŒì¼ ì €ì¥
            batch_file_path = self.save_batch_file(batch_requests, task_id)
            
            # ë°°ì¹˜ ì‘ì—… ì œì¶œ
            batch_id = self.submit_batch_job(batch_file_path, task_id)
            
            # DBì— ë°°ì¹˜ ì •ë³´ ì—…ë°ì´íŠ¸
            batch_key_entry.openai_batch_id = batch_id
            batch_key_entry.input_file_id = batch_file_path
            batch_key_entry.status = QAGenerationStatus.BATCH_SUBMITTED.value
            db.commit()
            
            print(f"âœ… ë°°ì¹˜ ì‘ì—… DBì— ì €ì¥ ë° ìƒíƒœ ì—…ë°ì´íŠ¸: task_id={task_id}, batch_id={batch_id}")
            
            print(f"ğŸ‰ QA Generator: ì‘ì—… ì™„ë£Œ - Task ID: {task_id}, Batch ID: {batch_id}, QA ê°œìˆ˜: {settings.QA_GENERATION_COUNT}")
            return task_id
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ QA Generator: ì‘ì—… ì‹¤íŒ¨ - {error_msg}")
            import traceback
            print(f"ğŸ” QA Generator: ìƒì„¸ ì—ëŸ¬ ì •ë³´ - {traceback.format_exc()}")
            
            # DBì— ì˜¤ë¥˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            db.rollback() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¡¤ë°±
            batch_key_entry.status = QAGenerationStatus.FAILED.value
            batch_key_entry.error_message = error_msg
            db.commit()
            
            return task_id
    
    def complete_qa_generation(self, task_id: str, db: Session) -> bool:
        """QA ìƒì„± ì™„ë£Œ ì²˜ë¦¬ - í´ë§/ì›¹í›… ëª¨ë“œ ëª¨ë‘ ì§€ì›"""
        logger = logging.getLogger(__name__)
        logger.info(f"ğŸ”„ QA ìƒì„± ì™„ë£Œ ì²˜ë¦¬ ì‹œì‘: task_id={task_id}")
        
        try:
            # BatchKeyì—ì„œ ë°°ì¹˜ ì •ë³´ ì¡°íšŒ
            batch_key = db.query(BatchKey).filter(BatchKey.task_id == task_id).first()
            if not batch_key:
                logger.error(f"âŒ BatchKeyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: task_id={task_id}")
                return False
            
            if not batch_key.openai_batch_id:
                logger.error(f"âŒ OpenAI ë°°ì¹˜ IDê°€ ì—†ìŒ: task_id={task_id}")
                return False
            
            logger.info(f"ğŸ“¦ ë°°ì¹˜ ì •ë³´ í™•ì¸: batch_id={batch_key.openai_batch_id}, influencer_id={batch_key.influencer_id}")
            
            # ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
            result_file_path = self.download_batch_results(batch_key.openai_batch_id, task_id)
            if not result_file_path:
                raise Exception("ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            
            logger.info(f"ğŸ“¥ ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {result_file_path}")
            
            # QA ìŒ ì²˜ë¦¬
            qa_pairs = self.process_qa_results(result_file_path)
            logger.info(f"ğŸ” QA ìŒ ì²˜ë¦¬ ì™„ë£Œ: {len(qa_pairs)}ê°œ")
            
            # DBì— ì €ì¥
            self.save_qa_pairs_to_db(batch_key.influencer_id, qa_pairs, db)
            logger.info(f"ğŸ’¾ QA ìŒ DB ì €ì¥ ì™„ë£Œ")
            
            # S3ì— ì—…ë¡œë“œ
            logger.info(f"â˜ï¸ S3 ì—…ë¡œë“œ ì‹œì‘: influencer_id={batch_key.influencer_id}, task_id={task_id}")
            try:
                from app.services.s3_service import get_s3_service
                s3_service = get_s3_service()
                
                if s3_service.is_available():
                    # S3ì— QA ê²°ê³¼ ì—…ë¡œë“œ
                    s3_urls = s3_service.upload_qa_results(
                        influencer_id=batch_key.influencer_id,
                        task_id=task_id,
                        qa_pairs=qa_pairs,
                        raw_results_file=result_file_path
                    )
                    
                    # S3 URL ì €ì¥
                    if s3_urls:
                        batch_key.s3_qa_file_url = s3_urls.get('processed_qa_url')
                        batch_key.s3_processed_file_url = s3_urls.get('raw_results_url')
                        batch_key.is_uploaded_to_s3 = True
                        logger.info(f"âœ… S3 ì—…ë¡œë“œ ì„±ê³µ: QA URL={batch_key.s3_qa_file_url}")
                    else:
                        logger.warning(f"âš ï¸ S3 ì—…ë¡œë“œ ì‹¤íŒ¨: URLì´ ë°˜í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                        batch_key.is_uploaded_to_s3 = False
                else:
                    logger.warning(f"âš ï¸ S3 ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ íŒŒì¼ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    batch_key.is_uploaded_to_s3 = False
                    
            except Exception as s3_error:
                logger.error(f"âŒ S3 ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {s3_error}", exc_info=True)
                # S3 ì—…ë¡œë“œ ì‹¤íŒ¨í•´ë„ ì „ì²´ í”„ë¡œì„¸ìŠ¤ëŠ” ê³„ì† ì§„í–‰
                batch_key.is_uploaded_to_s3 = False
            
            # BatchKey ìƒíƒœ ì—…ë°ì´íŠ¸
            batch_key.status = QAGenerationStatus.COMPLETED.value
            batch_key.generated_qa_pairs = len(qa_pairs)
            batch_key.completed_at = datetime.now()
            batch_key.is_processed = True
            db.commit()
            logger.info(f"ğŸ§  BatchKey ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ (DB)")
            
            logger.info(f"âœ… QA ìƒì„± ì™„ë£Œ - Task ID: {task_id}, QA ìŒ: {len(qa_pairs)}ê°œ, S3 ì—…ë¡œë“œ: {batch_key.is_uploaded_to_s3}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ QA ìƒì„± ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: task_id={task_id}, error={e}", exc_info=True)
            
            # DBì— ì˜¤ë¥˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            if batch_key:
                db.rollback() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¡¤ë°±
                batch_key.status = QAGenerationStatus.FAILED.value
                batch_key.error_message = f"ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
                db.commit()
            
            return False