"""
í”„ë¡¬í”„íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸ API ì—”ë“œí¬ì¸íŠ¸

ComfyUI ì‹¤í–‰ ì—†ì´ í”„ë¡¬í”„íŠ¸ ìµœì í™” ê²°ê³¼ë§Œ í™•ì¸í•  ìˆ˜ ìˆëŠ” í…ŒìŠ¤íŠ¸ìš© API
"""

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import logging

from app.core.security import get_current_user
from app.services.prompt_optimization_service import get_prompt_optimization_service

logger = logging.getLogger(__name__)

router = APIRouter()


# ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
class PromptTestRequest(BaseModel):
    """í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ìš”ì²­"""
    prompt: str
    selected_styles: Optional[Dict[str, str]] = {}


class PromptTestResponse(BaseModel):
    """í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‘ë‹µ"""
    success: bool
    original_prompt: str
    selected_styles: Dict[str, str]
    optimized_prompt: str
    character_count: int
    estimated_tokens: int
    style_keywords_applied: List[str]
    optimization_method: str
    message: str


@router.post("/test-prompt", response_model=PromptTestResponse)
async def test_prompt_optimization(
    request: PromptTestRequest,
    current_user: Dict = Depends(get_current_user)
):
    """
    í”„ë¡¬í”„íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸
    
    ComfyUI ì‹¤í–‰ ì—†ì´ í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ + ìŠ¤íƒ€ì¼ ì„ íƒì´ 
    ì–´ë–»ê²Œ Flux.1-dev ìµœì í™” ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜ë˜ëŠ”ì§€ í™•ì¸
    """
    try:
        user_id = current_user.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="ì‚¬ìš©ì IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"ğŸ§ª í”„ë¡¬í”„íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹œì‘ - ì‚¬ìš©ì: {user_id}")
        logger.info(f"ğŸ“ ì›ë³¸ í”„ë¡¬í”„íŠ¸: '{request.prompt}'")
        logger.info(f"ğŸ¨ ì„ íƒëœ ìŠ¤íƒ€ì¼: {request.selected_styles}")
        
        # í”„ë¡¬í”„íŠ¸ ìµœì í™” ì„œë¹„ìŠ¤ í˜¸ì¶œ
        prompt_service = get_prompt_optimization_service()
        
        # ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ ìˆ˜ì§‘ (ë‚´ë¶€ ë©”ì„œë“œ ì ‘ê·¼)
        style_keywords_dict = prompt_service._collect_flux_style_keywords(request.selected_styles)
        style_keywords_applied = []
        for category, keywords in style_keywords_dict.items():
            style_keywords_applied.extend(keywords.split(", "))
        
        # ìµœì í™” ì‹¤í–‰
        try:
            optimized_prompt = await prompt_service.optimize_flux_prompt(
                user_prompt=request.prompt,
                selected_styles=request.selected_styles
            )
            optimization_method = "openai_flux_optimization"
            
        except Exception as optimization_error:
            logger.warning(f"âš ï¸ OpenAI ìµœì í™” ì‹¤íŒ¨, í´ë°± ëª¨ë“œ ì‚¬ìš©: {optimization_error}")
            # í´ë°± ëª¨ë“œ ì‹œë®¬ë ˆì´ì…˜
            optimized_prompt = prompt_service._flux_fallback_prompt(
                request.prompt, 
                request.selected_styles
            )
            optimization_method = "fallback_translation"
        
        # í† í° ìˆ˜ ì¶”ì • (ëŒ€ëµì ìœ¼ë¡œ 4ê¸€ì = 1í† í°)
        estimated_tokens = len(optimized_prompt) // 4
        
        # ìµœì í™” í’ˆì§ˆ í‰ê°€
        character_count = len(optimized_prompt)
        
        if character_count <= 350 and estimated_tokens <= 77:
            quality_message = "âœ… Flux.1-devì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤."
        elif character_count > 350:
            quality_message = "âš ï¸ í”„ë¡¬í”„íŠ¸ê°€ ë‹¤ì†Œ ê¸´ í¸ì…ë‹ˆë‹¤. ë” ê°„ê²°í•˜ê²Œ ì¡°ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        else:
            quality_message = "ğŸ” í”„ë¡¬í”„íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        
        logger.info(f"âœ… í”„ë¡¬í”„íŠ¸ ìµœì í™” ì™„ë£Œ")
        logger.info(f"   ìµœì í™” ê²°ê³¼: '{optimized_prompt[:50]}...'")
        logger.info(f"   ê¸¸ì´: {character_count}ì, ì¶”ì • í† í°: {estimated_tokens}")
        
        return PromptTestResponse(
            success=True,
            original_prompt=request.prompt,
            selected_styles=request.selected_styles,
            optimized_prompt=optimized_prompt,
            character_count=character_count,
            estimated_tokens=estimated_tokens,
            style_keywords_applied=style_keywords_applied,
            optimization_method=optimization_method,
            message=quality_message
        )
        
    except Exception as e:
        logger.error(f"âŒ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"í”„ë¡¬í”„íŠ¸ ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
        )


@router.post("/test-multiple-prompts")
async def test_multiple_prompts(
    prompts_data: List[PromptTestRequest],
    current_user: Dict = Depends(get_current_user)
):
    """
    ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ì¼ê´„ í…ŒìŠ¤íŠ¸
    
    ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ì™€ ìŠ¤íƒ€ì¼ ì¡°í•©ì„ í•œ ë²ˆì— í…ŒìŠ¤íŠ¸
    """
    try:
        user_id = current_user.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="ì‚¬ìš©ì IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"ğŸ§ª ì¼ê´„ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ - {len(prompts_data)}ê°œ í”„ë¡¬í”„íŠ¸")
        
        results = []
        prompt_service = get_prompt_optimization_service()
        
        for i, prompt_data in enumerate(prompts_data, 1):
            try:
                logger.info(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i}/{len(prompts_data)}: '{prompt_data.prompt}'")
                
                # ê°œë³„ í”„ë¡¬í”„íŠ¸ ìµœì í™”
                optimized_prompt = await prompt_service.optimize_flux_prompt(
                    user_prompt=prompt_data.prompt,
                    selected_styles=prompt_data.selected_styles
                )
                
                # ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ ìˆ˜ì§‘
                style_keywords_dict = prompt_service._collect_flux_style_keywords(prompt_data.selected_styles)
                style_keywords_applied = []
                for keywords in style_keywords_dict.values():
                    style_keywords_applied.extend(keywords.split(", "))
                
                results.append({
                    "test_number": i,
                    "original_prompt": prompt_data.prompt,
                    "selected_styles": prompt_data.selected_styles,
                    "optimized_prompt": optimized_prompt,
                    "character_count": len(optimized_prompt),
                    "estimated_tokens": len(optimized_prompt) // 4,
                    "style_keywords_applied": style_keywords_applied,
                    "success": True
                })
                
            except Exception as e:
                logger.error(f"âŒ í”„ë¡¬í”„íŠ¸ {i} ìµœì í™” ì‹¤íŒ¨: {e}")
                results.append({
                    "test_number": i,
                    "original_prompt": prompt_data.prompt,
                    "selected_styles": prompt_data.selected_styles,
                    "optimized_prompt": "",
                    "character_count": 0,
                    "estimated_tokens": 0,
                    "style_keywords_applied": [],
                    "success": False,
                    "error": str(e)
                })
        
        successful_tests = sum(1 for r in results if r["success"])
        
        logger.info(f"âœ… ì¼ê´„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {successful_tests}/{len(prompts_data)} ì„±ê³µ")
        
        return {
            "success": True,
            "total_tests": len(prompts_data),
            "successful_tests": successful_tests,
            "failed_tests": len(prompts_data) - successful_tests,
            "results": results,
            "message": f"{successful_tests}/{len(prompts_data)}ê°œ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì™„ë£Œ"
        }
        
    except Exception as e:
        logger.error(f"âŒ ì¼ê´„ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"ì¼ê´„ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
        )


@router.get("/test-examples")
async def get_test_examples():
    """
    í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ìš© ì˜ˆì‹œ ë°ì´í„° ì œê³µ
    """
    examples = [
        {
            "prompt": "ì•„ë¦„ë‹¤ìš´ ì—¬ì„±ì˜ ì´ˆìƒí™”",
            "selected_styles": {
                "ëŒ€ë¶„ë¥˜": "ì‚¬ëŒ",
                "ì„¸ë¶€ìŠ¤íƒ€ì¼": "ì‚¬ì‹¤ì ", 
                "ë¶„ìœ„ê¸°": "ë”°ëœ»í•œ"
            },
            "description": "ì‚¬ì‹¤ì ì¸ ì—¬ì„± ì´ˆìƒí™” (ë”°ëœ»í•œ ë¶„ìœ„ê¸°)"
        },
        {
            "prompt": "ê³ ì–‘ì´ê°€ ì°½ê°€ì—ì„œ í–‡ì‚´ì„ ë°›ìœ¼ë©° ì ìëŠ” ëª¨ìŠµ",
            "selected_styles": {
                "ëŒ€ë¶„ë¥˜": "ë™ë¬¼",
                "ì„¸ë¶€ìŠ¤íƒ€ì¼": "ë””ì§€í„¸ì•„íŠ¸",
                "ë¶„ìœ„ê¸°": "ë°ì€"
            },
            "description": "ë””ì§€í„¸ì•„íŠ¸ ìŠ¤íƒ€ì¼ì˜ ê³ ì–‘ì´ (ë°ì€ ë¶„ìœ„ê¸°)"
        },
        {
            "prompt": "ë¯¸ë˜ë„ì‹œì˜ ë„¤ì˜¨ì‚¬ì¸ì´ ë¹›ë‚˜ëŠ” ì•¼ê²½",
            "selected_styles": {
                "ëŒ€ë¶„ë¥˜": "ê±´ë¬¼",
                "ì„¸ë¶€ìŠ¤íƒ€ì¼": "íŒíƒ€ì§€",
                "ë¶„ìœ„ê¸°": "ì–´ë‘ìš´"
            },
            "description": "íŒíƒ€ì§€ ìŠ¤íƒ€ì¼ì˜ ë¯¸ë˜ë„ì‹œ (ì–´ë‘ìš´ ë¶„ìœ„ê¸°)"
        },
        {
            "prompt": "ì‚°ì†ì˜ ì‘ì€ ì˜¤ë‘ë§‰ê³¼ ì£¼ë³€ ìì—° í’ê²½",
            "selected_styles": {
                "ëŒ€ë¶„ë¥˜": "í’ê²½",
                "ì„¸ë¶€ìŠ¤íƒ€ì¼": "ìˆ˜ì±„í™”",
                "ë¶„ìœ„ê¸°": "ì‹ ë¹„ë¡œìš´"
            },
            "description": "ìˆ˜ì±„í™” ìŠ¤íƒ€ì¼ì˜ ìì—° í’ê²½ (ì‹ ë¹„ë¡œìš´ ë¶„ìœ„ê¸°)"
        },
        {
            "prompt": "ë¹ˆí‹°ì§€í•œ ì±…ìƒ ìœ„ì˜ ì˜¤ë˜ëœ ì±…ê³¼ ì´›ë¶ˆ",
            "selected_styles": {
                "ëŒ€ë¶„ë¥˜": "ì‚¬ë¬¼",
                "ì„¸ë¶€ìŠ¤íƒ€ì¼": "ìœ í™”",
                "ë¶„ìœ„ê¸°": "ì°¨ê°€ìš´"
            },
            "description": "ìœ í™” ìŠ¤íƒ€ì¼ì˜ ì •ë¬¼í™” (ì°¨ê°€ìš´ ë¶„ìœ„ê¸°)"
        }
    ]
    
    return {
        "success": True,
        "examples": examples,
        "message": f"{len(examples)}ê°œì˜ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
    }