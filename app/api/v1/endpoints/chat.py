from fastapi import APIRouter, Depends, HTTPException, status, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from typing import List
from datetime import datetime
import logging
import json
import uuid
from pydantic import BaseModel
from app.database import get_db
from app.models.influencer import (
    AIInfluencer,
    InfluencerAPI,
    APICallAggregation,
)
from app.models.chat_message import ChatMessage
from app.models.user import User
from app.core.security import get_current_user
from app.utils.timezone_utils import get_current_kst
from app.core.security import get_current_user, get_current_user_by_api_key

logger = logging.getLogger(__name__)

router = APIRouter()


# ì±—ë´‡ APIì— ëŒ€í•œ CORS ì„¤ì •
@router.options("/chatbot")
async def chatbot_options():
    """ì±—ë´‡ API CORS preflight ìš”ì²­ ì²˜ë¦¬"""
    return {"message": "OK"}


# API í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ì±—ë´‡ ìš”ì²­ ìŠ¤í‚¤ë§ˆ
class ChatbotRequest(BaseModel):
    message: str
    session_id: str | None = None


class ChatbotResponse(BaseModel):
    response: str
    session_id: str
    influencer_name: str


# ì±„íŒ… ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ
class ChatMessageSchema(BaseModel):
    session_id: str
    influencer_id: str
    message_content: str
    created_at: str
    end_at: str | None = None

    class Config:
        from_attributes = True


class ChatMessageCreate(BaseModel):
    influencer_id: str
    message_content: str
    message_type: str = "user"  # user ë˜ëŠ” ai
    end_at: str | None = None


# ë¹„ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´)
@router.post("/chatbot", response_model=ChatbotResponse)
async def chatbot_chat(
    request: ChatbotRequest,
    influencer: AIInfluencer = Depends(get_current_user_by_api_key),
    db: Session = Depends(get_db),
):
    """
    API í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ë¹„ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
    ì¸í”Œë£¨ì–¸ì„œì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì™„ì „í•œ ì‘ë‹µì„ í•œ ë²ˆì— ë°˜í™˜)
    """
    try:
        # API ì‚¬ìš©ëŸ‰ ì¶”ì 
        await track_api_usage(db, str(influencer.influencer_id))

        # VLLM ì„œë¹„ìŠ¤ í˜¸ì¶œ
        try:
            from app.services.vllm_client import (
                vllm_generate_response,
                vllm_health_check,
            )

            # VLLM ì„œë²„ ìƒíƒœ í™•ì¸
            if not await vllm_health_check():
                logger.warning("VLLM ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            else:
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                system_message = (
                    str(influencer.system_prompt)
                    if influencer.system_prompt is not None
                    else f"ë‹¹ì‹ ì€ {influencer.influencer_name}ì…ë‹ˆë‹¤. ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."
                )

                # VLLM ì„œë²„ì—ì„œ ì‘ë‹µ ìƒì„±
                # chatbot.pyì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
                if influencer.influencer_id:
                    model_id = str(influencer.influencer_id)
                    
                    # HF í† í° ê°€ì ¸ì˜¤ê¸° (chatbot.pyì™€ ë™ì¼í•œ ë°©ì‹)
                    from app.models.user import HFTokenManage
                    from app.core.encryption import decrypt_sensitive_data
                    
                    hf_token = None
                    if hasattr(influencer, 'group_id') and influencer.group_id:
                        hf_token_manage = db.query(HFTokenManage).filter(
                            HFTokenManage.group_id == influencer.group_id
                        ).order_by(HFTokenManage.created_at.desc()).first()
                        
                        if hf_token_manage:
                            hf_token = decrypt_sensitive_data(str(hf_token_manage.hf_token_value))
                    
                    # VLLM í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    from app.services.vllm_client import get_vllm_client
                    vllm_client = await get_vllm_client()
                    
                    # ì–´ëŒ‘í„° ë¡œë“œ (chatbot.pyì™€ ë™ì¼í•œ ë°©ì‹)
                    try:
                        await vllm_client.load_adapter(model_id=model_id, hf_repo_name=influencer.influencer_model_repo, hf_token=hf_token)
                        logger.info(f"âœ… VLLM ì–´ëŒ‘í„° ë¡œë“œ ì™„ë£Œ: {model_id}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ì–´ëŒ‘í„° ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {e}")
                        # ì–´ëŒ‘í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
                        model_id = str(influencer.influencer_id)
                else:
                    model_id = str(influencer.influencer_id)
                
                response_text = await vllm_generate_response(
                    user_message=request.message,
                    system_message=system_message,
                    influencer_name=str(influencer.influencer_name),
                    model_id=model_id,
                    max_new_tokens=200,
                    temperature=0.7,
                )

                logger.info(f"âœ… VLLM ì‘ë‹µ ìƒì„± ì„±ê³µ: {influencer.influencer_name}")

        except Exception as e:
            logger.error(f"âŒ VLLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # VLLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì‚¬ìš©
            response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

        # ì„¸ì…˜ ID ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
        session_id = request.session_id or f"session_{datetime.now().timestamp()}"

        return ChatbotResponse(
            response=response_text,
            session_id=session_id,
            influencer_name=str(influencer.influencer_name),
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Chatbot error: {str(e)}",
        )


# ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸ (ìƒˆë¡œ ì¶”ê°€)
@router.post("/chatbot/stream")
async def chatbot_chat_stream(
    request: ChatbotRequest,
    influencer: AIInfluencer = Depends(get_current_user_by_api_key),
    db: Session = Depends(get_db),
):
    """
    API í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
    ì¸í”Œë£¨ì–¸ì„œì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì‹¤ì‹œê°„ìœ¼ë¡œ í† í°ì„ ìŠ¤íŠ¸ë¦¬ë°)
    """
    try:
        # API ì‚¬ìš©ëŸ‰ ì¶”ì 
        await track_api_usage(db, str(influencer.influencer_id))

        async def generate_stream():
            try:
                # VLLM ì„œë¹„ìŠ¤ í˜¸ì¶œ
                from app.services.vllm_client import (
                    vllm_health_check,
                    get_vllm_client,
                )

                # VLLM ì„œë²„ ìƒíƒœ í™•ì¸
                if not await vllm_health_check():
                    logger.warning("VLLM ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    error_response = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                    yield f"data: {json.dumps({'text': error_response})}\n\n"
                    yield f"data: {json.dumps({'done': True})}\n\n"
                    return

                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                system_message = (
                    str(influencer.system_prompt)
                    if influencer.system_prompt is not None
                    else f"ë‹¹ì‹ ì€ {influencer.influencer_name}ì…ë‹ˆë‹¤. ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."
                )

                # VLLM ì„œë²„ì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                if influencer.influencer_id:
                    model_id = str(influencer.influencer_id)
                    
                    # HF í† í° ê°€ì ¸ì˜¤ê¸°
                    from app.models.user import HFTokenManage
                    from app.core.encryption import decrypt_sensitive_data
                    
                    hf_token = None
                    if hasattr(influencer, 'group_id') and influencer.group_id:
                        hf_token_manage = db.query(HFTokenManage).filter(
                            HFTokenManage.group_id == influencer.group_id
                        ).order_by(HFTokenManage.created_at.desc()).first()
                        
                        if hf_token_manage:
                            hf_token = decrypt_sensitive_data(str(hf_token_manage.hf_token_value))
                    
                    # VLLM í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    vllm_client = await get_vllm_client()
                    
                    # ì–´ëŒ‘í„° ë¡œë“œ
                    try:
                        await vllm_client.load_adapter(model_id=model_id, hf_repo_name=influencer.influencer_model_repo, hf_token=hf_token)
                        logger.info(f"âœ… VLLM ì–´ëŒ‘í„° ë¡œë“œ ì™„ë£Œ: {model_id}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ì–´ëŒ‘í„° ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {e}")
                        # ì–´ëŒ‘í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
                        model_id = str(influencer.influencer_id)
                else:
                    model_id = str(influencer.influencer_id)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                token_count = 0
                async for token in vllm_client.generate_response_stream(
                    user_message=request.message,
                    system_message=system_message,
                    influencer_name=str(influencer.influencer_name),
                    model_id=model_id,
                    max_new_tokens=200,
                    temperature=0.7,
                ):
                    # ê° í† í°ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
                    logger.debug(f"ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° í† í° ì „ì†¡: {repr(token)}")
                    yield f"data: {json.dumps({'text': token}, ensure_ascii=False)}\n\n"
                    token_count += 1
                    
                    # ë„ˆë¬´ ë§ì€ í† í°ì´ ì˜¤ë©´ ì¤‘ë‹¨ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
                    if token_count > 1000:
                        logger.warning(f"âš ï¸ í† í° ìˆ˜ê°€ ë„ˆë¬´ ë§ì•„ ì¤‘ë‹¨: {token_count}")
                        break
                
                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹ í˜¸
                yield f"data: {json.dumps({'done': True}, ensure_ascii=False)}\n\n"
                logger.info(f"âœ… VLLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì™„ë£Œ: {influencer.influencer_name}")

            except Exception as e:
                logger.error(f"âŒ VLLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
                # VLLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì‚¬ìš©
                error_response = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                yield f"data: {json.dumps({'text': error_response}, ensure_ascii=False)}\n\n"
                yield f"data: {json.dumps({'done': True}, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            generate_stream(),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/plain; charset=utf-8",
            }
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Chatbot streaming error: {str(e)}",
        )


async def track_api_usage(db: Session, influencer_id: str):
    """API ì‚¬ìš©ëŸ‰ ì¶”ì """
    try:
        logger.info(f"ğŸ“Š API ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹œì‘ - influencer_id: {influencer_id}")
        
        # API í‚¤ ì¡°íšŒ
        api_key = (
            db.query(InfluencerAPI)
            .filter(InfluencerAPI.influencer_id == influencer_id)
            .first()
        )
        
        if not api_key:
            logger.warning(f"âš ï¸ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - influencer_id: {influencer_id}")
            return
        
        logger.info(f"ğŸ”‘ API í‚¤ ì¡°íšŒ ì„±ê³µ - api_id: {api_key.api_id}")
        
        today = datetime.now().date()

        # ì˜¤ëŠ˜ ë‚ ì§œì˜ API í˜¸ì¶œ ì§‘ê³„ ì¡°íšŒ
        aggregation = (
            db.query(APICallAggregation)
            .filter(
                APICallAggregation.api_id == api_key.api_id,
                APICallAggregation.created_at >= today,
            )
            .first()
        )

        if aggregation:
            # ê¸°ì¡´ ì§‘ê³„ ì—…ë°ì´íŠ¸
            old_count = aggregation.daily_call_count
            aggregation.daily_call_count += 1
            aggregation.updated_at = datetime.now()
            logger.info(f"âœ… ê¸°ì¡´ ì§‘ê³„ ì—…ë°ì´íŠ¸ - api_id: {api_key.api_id}, ì´ì „: {old_count}, í˜„ì¬: {aggregation.daily_call_count}")
        else:
            # ìƒˆë¡œìš´ ì§‘ê³„ ìƒì„±
            aggregation = APICallAggregation(
                api_id=api_key.api_id,
                influencer_id=influencer_id,
                daily_call_count=1,
                created_at=datetime.now(),
                updated_at=datetime.now(),
            )
            db.add(aggregation)
            logger.info(f"ğŸ†• ìƒˆë¡œìš´ ì§‘ê³„ ìƒì„± - api_id: {api_key.api_id}, influencer_id: {influencer_id}")

        db.commit()
        logger.info(f"ğŸ’¾ API ì‚¬ìš©ëŸ‰ ì¶”ì  ì™„ë£Œ - influencer_id: {influencer_id}, api_id: {api_key.api_id}")

    except Exception as e:
        # API ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹¤íŒ¨ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
        logger.error(f"âŒ API usage tracking failed: {e}")
        db.rollback()


# ê¸°ì¡´ ì‚¬ìš©ì ì¸ì¦ ê¸°ë°˜ ì—”ë“œí¬ì¸íŠ¸ë“¤ (ê´€ë¦¬ìš©)
@router.get("", response_model=List[ChatMessageSchema])
async def get_chat_messages(
    influencer_id: str,
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=100),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """ì±„íŒ… ë©”ì‹œì§€ ëª©ë¡ ì¡°íšŒ"""
    # ì¸í”Œë£¨ì–¸ì„œ ì†Œìœ ê¶Œ í™•ì¸
    influencer = (
        db.query(AIInfluencer)
        .filter(
            AIInfluencer.influencer_id == influencer_id,
            AIInfluencer.user_id == current_user.user_id,
        )
        .first()
    )

    if influencer is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND, detail="Influencer not found"
        )

    messages = (
        db.query(ChatMessage)
        .filter(ChatMessage.influencer_id == influencer_id)
        .offset(skip)
        .limit(limit)
        .all()
    )

    return messages


@router.post("", response_model=ChatMessageSchema)
async def create_chat_message(
    message_data: ChatMessageCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """ìƒˆ ì±„íŒ… ë©”ì‹œì§€ ìƒì„±"""
    # ì¸í”Œë£¨ì–¸ì„œ ì†Œìœ ê¶Œ í™•ì¸
    influencer = (
        db.query(AIInfluencer)
        .filter(
            AIInfluencer.influencer_id == message_data.influencer_id,
            AIInfluencer.user_id == current_user.user_id,
        )
        .first()
    )

    if influencer is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND, detail="Influencer not found"
        )

    message = ChatMessage(
        chat_message_id=str(uuid.uuid4()),
        session_id=message_data.session_id if hasattr(message_data, 'session_id') else str(uuid.uuid4()),
        influencer_id=message_data.influencer_id,
        message_content=message_data.message_content,
        message_type=message_data.message_type,
        created_at=get_current_kst(),
        end_at=message_data.end_at,
    )

    db.add(message)
    db.commit()
    db.refresh(message)

    return message


@router.get("/{session_id}", response_model=ChatMessageSchema)
async def get_chat_message(
    session_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """íŠ¹ì • ì±„íŒ… ë©”ì‹œì§€ ì¡°íšŒ"""
    message = db.query(ChatMessage).filter(ChatMessage.session_id == session_id).first()

    if message is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND, detail="Chat message not found"
        )

    # ì¸í”Œë£¨ì–¸ì„œ ì†Œìœ ê¶Œ í™•ì¸
    influencer = (
        db.query(AIInfluencer)
        .filter(
            AIInfluencer.influencer_id == message.influencer_id,
            AIInfluencer.user_id == current_user.user_id,
        )
        .first()
    )

    if influencer is None:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not authorized to access this chat message",
        )

    return message
