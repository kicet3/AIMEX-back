from fastapi import APIRouter, Depends, HTTPException, status, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from typing import List
from datetime import datetime
import logging
import json
import uuid
from pydantic import BaseModel
from app.database import get_db
from app.models.influencer import (
    AIInfluencer,
    InfluencerAPI,
    APICallAggregation,
)
from app.models.chat_message import ChatMessage
from app.models.user import User
from app.core.security import get_current_user
from app.utils.timezone_utils import get_current_kst
from app.core.security import get_current_user, get_current_user_by_api_key

logger = logging.getLogger(__name__)

router = APIRouter()


# ì±—ë´‡ APIì— ëŒ€í•œ CORS ì„¤ì •
@router.options("/chatbot")
async def chatbot_options():
    """ì±—ë´‡ API CORS preflight ìš”ì²­ ì²˜ë¦¬"""
    return {"message": "OK"}

@router.options("/chatbot/user")
async def chatbot_user_options():
    """ì‚¬ìš©ì ì±—ë´‡ API CORS preflight ìš”ì²­ ì²˜ë¦¬"""
    return {"message": "OK"}


# API í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ì±—ë´‡ ìš”ì²­ ìŠ¤í‚¤ë§ˆ
class ChatbotRequest(BaseModel):
    message: str
    session_id: str | None = None

# JWT í† í°ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ì±—ë´‡ ìš”ì²­ ìŠ¤í‚¤ë§ˆ
class ChatbotWithInfluencerRequest(BaseModel):
    message: str
    influencer_id: str
    session_id: str | None = None


class ChatbotResponse(BaseModel):
    response: str
    session_id: str
    influencer_name: str


# ì±„íŒ… ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ
class ChatMessageSchema(BaseModel):
    session_id: str
    influencer_id: str
    message_content: str
    created_at: str
    end_at: str | None = None

    class Config:
        from_attributes = True


class ChatMessageCreate(BaseModel):
    influencer_id: str
    message_content: str
    message_type: str = "user"  # user ë˜ëŠ” ai
    end_at: str | None = None


# ë¹„ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´)
@router.post("/chatbot", response_model=ChatbotResponse)
async def chatbot_chat(
    request: ChatbotRequest,
    influencer: AIInfluencer = Depends(get_current_user_by_api_key),
    db: Session = Depends(get_db),
):
    """
    API í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ë¹„ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
    ì¸í”Œë£¨ì–¸ì„œì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì™„ì „í•œ ì‘ë‹µì„ í•œ ë²ˆì— ë°˜í™˜)
    """
    try:
        # API ì‚¬ìš©ëŸ‰ ì¶”ì 
        await track_api_usage(db, str(influencer.influencer_id))

        # RunPod ì„œë¹„ìŠ¤ í˜¸ì¶œ
        try:
            from app.services.runpod_manager import get_vllm_manager
            
            # vLLM ë§¤ë‹ˆì € ê°€ì ¸ì˜¤ê¸°
            vllm_manager = get_vllm_manager()

            # RunPod ì„œë²„ ìƒíƒœ í™•ì¸
            if not await vllm_manager.health_check():
                logger.warning("RunPod ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            else:
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                system_message = (
                    str(influencer.system_prompt)
                    if influencer.system_prompt is not None
                    else f"ë‹¹ì‹ ì€ {influencer.influencer_name}ì…ë‹ˆë‹¤. ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."
                )

                # RunPod ì„œë²„ì—ì„œ ì‘ë‹µ ìƒì„±
                lora_adapter = None
                hf_repo = None
                hf_token = None
                
                logger.info(f"ğŸ” Influencer ì •ë³´: id={influencer.influencer_id}, model_repo={influencer.influencer_model_repo}")
                
                if influencer.influencer_id:
                    # LoRA ì–´ëŒ‘í„° ì´ë¦„ ì„¤ì • (ì¸í”Œë£¨ì–¸ì„œ ID ì‚¬ìš©)
                    lora_adapter = str(influencer.influencer_id)
                    
                    if influencer.influencer_model_repo:
                        # DBì— ì €ì¥ëœ HF ë ˆí¬ì§€í† ë¦¬ ê²½ë¡œ ì‚¬ìš©
                        hf_repo = str(influencer.influencer_model_repo)
                        logger.info(f"ğŸ”§ LoRA ì–´ëŒ‘í„° ì‚¬ìš©: {lora_adapter}, HF repo: {hf_repo}")
                    else:
                        # model_repoê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ íŒ¨í„´ ì‚¬ìš© (ì„ì‹œ)
                        # ì˜ˆ: eb4f7078-e069-4e05-845f-6b052ef8739c -> username/model-eb4f7078
                        # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì— ì •í™•í•œ HF repo ê²½ë¡œê°€ ìˆì–´ì•¼ í•¨
                        logger.warning(f"âš ï¸ Influencer model_repoê°€ ì—†ìŒ: id={influencer.influencer_id}")
                        logger.warning(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ì— HuggingFace repository ê²½ë¡œë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤!")
                        # HF repo ì—†ì´ëŠ” ì‘ë™í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                        lora_adapter = None
                
                # HF í† í° ê°€ì ¸ì˜¤ê¸°
                if hf_repo:
                    try:
                        from app.services.hf_token_resolver import get_token_for_influencer
                        hf_token, hf_username = await get_token_for_influencer(influencer, db)
                        if hf_token:
                            logger.info(f"ğŸ”‘ HF í† í° ì‚¬ìš© (user: {hf_username})")
                    except Exception as e:
                        logger.warning(f"âš ï¸ HF í† í° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                
                # RunPod í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­
                result = await vllm_manager.generate_text(
                    prompt=request.message,
                    lora_adapter=lora_adapter,
                    hf_repo=hf_repo,
                    hf_token=hf_token,
                    system_message=system_message,
                    temperature=0.7,
                    max_tokens=200,
                    stream=False
                )
                
                # ì‘ë‹µ ì „ì²´ ë¡œê¹…
                logger.info(f"ğŸ” RunPod ì‘ë‹µ ì „ì²´: {json.dumps(result, indent=2, ensure_ascii=False)}")
                
                # RunPod ì‘ë‹µ ì²˜ë¦¬ (ê°„ì†Œí™”ëœ í˜•ì‹)
                if result.get("status") == "completed":
                    # ìƒˆë¡œìš´ í˜•ì‹: generated_textê°€ ì§ì ‘ ë°˜í™˜ë¨
                    response_text = result.get("generated_text", "")
                    if response_text:
                        logger.info(f"âœ… ìƒì„±ëœ í…ìŠ¤íŠ¸: {response_text[:100]}...")
                    else:
                        # ì´ì „ í˜•ì‹ í˜¸í™˜ì„±ì„ ìœ„í•œ ì²˜ë¦¬
                        output = result.get("output", {})
                        if isinstance(output, dict) and output.get("generated_text"):
                            response_text = output.get("generated_text", "")
                        else:
                            logger.warning(f"âš ï¸ ì‘ë‹µì— generated_textê°€ ì—†ìŒ: {result}")
                            response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                elif result.get("status") == "failed":
                    # ì‹¤íŒ¨í•œ ê²½ìš°
                    logger.error(f"âŒ RunPod ìš”ì²­ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                else:
                    # ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ í˜•ì‹
                    logger.warning(f"âš ï¸ ì˜ˆìƒí•˜ì§€ ëª»í•œ RunPod ì‘ë‹µ í˜•ì‹: {result}")
                    response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

                logger.info(f"âœ… RunPod ì‘ë‹µ ìƒì„± ì„±ê³µ: {influencer.influencer_name}")

        except Exception as e:
            logger.error(f"âŒ RunPod ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # RunPod ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì‚¬ìš©
            response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

        # ì„¸ì…˜ ID ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
        session_id = request.session_id or f"session_{datetime.now().timestamp()}"

        return ChatbotResponse(
            response=response_text,
            session_id=session_id,
            influencer_name=str(influencer.influencer_name),
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Chatbot error: {str(e)}",
        )


@router.post("/chatbot/user", response_model=ChatbotResponse)
async def chatbot_for_user(
    request: ChatbotWithInfluencerRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """
    JWT í† í°ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
    ì‚¬ìš©ìê°€ influencer_idë¥¼ ì§€ì •í•˜ì—¬ ì¸í”Œë£¨ì–¸ì„œì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    try:
        # ì¸í”Œë£¨ì–¸ì„œ ì¡°íšŒ
        influencer = (
            db.query(AIInfluencer)
            .filter(AIInfluencer.influencer_id == request.influencer_id)
            .first()
        )
        
        if not influencer:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Influencer not found"
            )
        
        # ì‚¬ìš©ìê°€ ì¸í”Œë£¨ì–¸ì„œì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸ (ê°™ì€ ê·¸ë£¹)
        if influencer.group_id != current_user.group_id:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to chat with this influencer"
            )
        
        # ì±—ë´‡ ì˜µì…˜ í™•ì¸
        if not influencer.chatbot_option:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="This influencer's chatbot is not enabled"
            )
        
        # í•™ìŠµ ìƒíƒœ í™•ì¸
        if influencer.learning_status != 1:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Influencer is not ready for chat"
            )
        
        logger.info(f"ğŸ” ì‚¬ìš©ì ì±—ë´‡ ìš”ì²­ - Influencer: id={influencer.influencer_id}, name={influencer.influencer_name}, model_repo={influencer.influencer_model_repo}")
        
        # RunPod ì„œë¹„ìŠ¤ í˜¸ì¶œ
        try:
            from app.services.runpod_manager import get_vllm_manager
            
            # vLLM ë§¤ë‹ˆì € ê°€ì ¸ì˜¤ê¸°
            vllm_manager = get_vllm_manager()

            # RunPod ì„œë²„ ìƒíƒœ í™•ì¸
            if not await vllm_manager.health_check():
                logger.warning("RunPod ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            else:
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                system_message = (
                    str(influencer.system_prompt)
                    if influencer.system_prompt is not None
                    else f"ë‹¹ì‹ ì€ {influencer.influencer_name}ì…ë‹ˆë‹¤. ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."
                )

                # RunPod ì„œë²„ì—ì„œ ì‘ë‹µ ìƒì„±
                lora_adapter = None
                hf_repo = None
                hf_token = None
                
                if influencer.influencer_id:
                    # LoRA ì–´ëŒ‘í„° ì´ë¦„ ì„¤ì • (ì¸í”Œë£¨ì–¸ì„œ ID ì‚¬ìš©)
                    lora_adapter = str(influencer.influencer_id)
                    
                    if influencer.influencer_model_repo:
                        # DBì— ì €ì¥ëœ HF ë ˆí¬ì§€í† ë¦¬ ê²½ë¡œ ì‚¬ìš©
                        hf_repo = str(influencer.influencer_model_repo)
                        logger.info(f"ğŸ”§ LoRA ì–´ëŒ‘í„° ì‚¬ìš©: {lora_adapter}, HF repo: {hf_repo}")
                    else:
                        logger.warning(f"âš ï¸ Influencer model_repoê°€ ì—†ìŒ: id={influencer.influencer_id}")
                        logger.warning(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ì— HuggingFace repository ê²½ë¡œë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤!")
                        # HF repo ì—†ì´ëŠ” ì‘ë™í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                        lora_adapter = None
                
                # HF í† í° ê°€ì ¸ì˜¤ê¸°
                if hf_repo:
                    try:
                        from app.services.hf_token_resolver import get_token_for_influencer
                        hf_token, hf_username = await get_token_for_influencer(influencer, db)
                        if hf_token:
                            logger.info(f"ğŸ”‘ HF í† í° ì‚¬ìš© (user: {hf_username})")
                    except Exception as e:
                        logger.warning(f"âš ï¸ HF í† í° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                
                # RunPod í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­
                result = await vllm_manager.generate_text(
                    prompt=request.message,
                    lora_adapter=lora_adapter,
                    hf_repo=hf_repo,
                    hf_token=hf_token,
                    system_message=system_message,
                    temperature=0.7,
                    max_tokens=200,
                    stream=False
                )
                
                # ì‘ë‹µ ì „ì²´ ë¡œê¹…
                logger.info(f"ğŸ” [User] RunPod ì‘ë‹µ ì „ì²´: {json.dumps(result, indent=2, ensure_ascii=False)}")
                
                # RunPod ì‘ë‹µ ì²˜ë¦¬ (ê°„ì†Œí™”ëœ í˜•ì‹)
                if result.get("status") == "completed":
                    # ìƒˆë¡œìš´ í˜•ì‹: generated_textê°€ ì§ì ‘ ë°˜í™˜ë¨
                    response_text = result.get("generated_text", "")
                    if response_text:
                        logger.info(f"âœ… ìƒì„±ëœ í…ìŠ¤íŠ¸: {response_text[:100]}...")
                    else:
                        # ì´ì „ í˜•ì‹ í˜¸í™˜ì„±ì„ ìœ„í•œ ì²˜ë¦¬
                        output = result.get("output", {})
                        if isinstance(output, dict) and output.get("generated_text"):
                            response_text = output.get("generated_text", "")
                        else:
                            logger.warning(f"âš ï¸ ì‘ë‹µì— generated_textê°€ ì—†ìŒ: {result}")
                            response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                elif result.get("status") == "failed":
                    # ì‹¤íŒ¨í•œ ê²½ìš°
                    logger.error(f"âŒ RunPod ìš”ì²­ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                else:
                    # ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ í˜•ì‹
                    logger.warning(f"âš ï¸ ì˜ˆìƒí•˜ì§€ ëª»í•œ RunPod ì‘ë‹µ í˜•ì‹: {result}")
                    response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

                logger.info(f"âœ… RunPod ì‘ë‹µ ìƒì„± ì„±ê³µ: {influencer.influencer_name}")

        except Exception as e:
            logger.error(f"âŒ RunPod ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            response_text = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

        # ì„¸ì…˜ ID ìƒì„±
        session_id = request.session_id or f"session_{datetime.now().timestamp()}"

        return ChatbotResponse(
            response=response_text,
            session_id=session_id,
            influencer_name=str(influencer.influencer_name),
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì±—ë´‡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Chatbot error: {str(e)}",
        )


# ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸ (ìƒˆë¡œ ì¶”ê°€)
@router.post("/chatbot/stream")
async def chatbot_chat_stream(
    request: ChatbotRequest,
    influencer: AIInfluencer = Depends(get_current_user_by_api_key),
    db: Session = Depends(get_db),
):
    """
    API í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
    ì¸í”Œë£¨ì–¸ì„œì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì‹¤ì‹œê°„ìœ¼ë¡œ í† í°ì„ ìŠ¤íŠ¸ë¦¬ë°)
    """
    try:
        # API ì‚¬ìš©ëŸ‰ ì¶”ì 
        await track_api_usage(db, str(influencer.influencer_id))

        async def generate_stream():
            try:
                # RunPod ì„œë¹„ìŠ¤ í˜¸ì¶œ
                from app.services.runpod_manager import get_vllm_manager
                
                # vLLM ë§¤ë‹ˆì € ê°€ì ¸ì˜¤ê¸°
                vllm_manager = get_vllm_manager()

                # RunPod ì„œë²„ ìƒíƒœ í™•ì¸
                if not await vllm_manager.health_check():
                    logger.warning("RunPod ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    error_response = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                    yield f"data: {json.dumps({'text': error_response})}\n\n"
                    yield f"data: {json.dumps({'done': True})}\n\n"
                    return

                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                system_message = (
                    str(influencer.system_prompt)
                    if influencer.system_prompt is not None
                    else f"ë‹¹ì‹ ì€ {influencer.influencer_name}ì…ë‹ˆë‹¤. ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."
                )

                # RunPod ì„œë²„ì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                lora_adapter = None
                hf_repo = None
                hf_token = None
                
                logger.info(f"ğŸ” [Stream] Influencer ì •ë³´: id={influencer.influencer_id}, model_repo={influencer.influencer_model_repo}")
                
                if influencer.influencer_id:
                    # LoRA ì–´ëŒ‘í„° ì´ë¦„ ì„¤ì • (ì¸í”Œë£¨ì–¸ì„œ ID ì‚¬ìš©)
                    lora_adapter = str(influencer.influencer_id)
                    
                    if influencer.influencer_model_repo:
                        # DBì— ì €ì¥ëœ HF ë ˆí¬ì§€í† ë¦¬ ê²½ë¡œ ì‚¬ìš©
                        hf_repo = str(influencer.influencer_model_repo)
                        logger.info(f"ğŸ”§ LoRA ì–´ëŒ‘í„° ì‚¬ìš©: {lora_adapter}, HF repo: {hf_repo}")
                    else:
                        # model_repoê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ íŒ¨í„´ ì‚¬ìš© (ì„ì‹œ)
                        logger.warning(f"âš ï¸ [Stream] Influencer model_repoê°€ ì—†ìŒ: id={influencer.influencer_id}")
                        logger.warning(f"âš ï¸ [Stream] ë°ì´í„°ë² ì´ìŠ¤ì— HuggingFace repository ê²½ë¡œë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤!")
                        # HF repo ì—†ì´ëŠ” ì‘ë™í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                        lora_adapter = None
                
                # HF í† í° ê°€ì ¸ì˜¤ê¸°
                if hf_repo:
                    try:
                        from app.services.hf_token_resolver import get_token_for_influencer
                        hf_token, hf_username = await get_token_for_influencer(influencer, db)
                        if hf_token:
                            logger.info(f"ğŸ”‘ HF í† í° ì‚¬ìš© (user: {hf_username})")
                    except Exception as e:
                        logger.warning(f"âš ï¸ HF í† í° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                token_count = 0
                async for token in vllm_manager.generate_text_stream(
                    prompt=request.message,
                    lora_adapter=lora_adapter,
                    hf_repo=hf_repo,
                    hf_token=hf_token,
                    system_message=system_message,
                    temperature=0.7,
                    max_tokens=200
                ):
                    # ê° í† í°ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
                    logger.debug(f"ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° í† í° ì „ì†¡: {repr(token)}")
                    yield f"data: {json.dumps({'text': token}, ensure_ascii=False)}\n\n"
                    token_count += 1
                    
                    # ë„ˆë¬´ ë§ì€ í† í°ì´ ì˜¤ë©´ ì¤‘ë‹¨ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
                    if token_count > 1000:
                        logger.warning(f"âš ï¸ í† í° ìˆ˜ê°€ ë„ˆë¬´ ë§ì•„ ì¤‘ë‹¨: {token_count}")
                        break
                
                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹ í˜¸
                yield f"data: {json.dumps({'done': True}, ensure_ascii=False)}\n\n"
                logger.info(f"âœ… RunPod ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì™„ë£Œ: {influencer.influencer_name}")

            except Exception as e:
                logger.error(f"âŒ RunPod ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
                # RunPod ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì‚¬ìš©
                error_response = f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {influencer.influencer_name}ì…ë‹ˆë‹¤. '{request.message}'ì— ëŒ€í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                yield f"data: {json.dumps({'text': error_response}, ensure_ascii=False)}\n\n"
                yield f"data: {json.dumps({'done': True}, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            generate_stream(),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/plain; charset=utf-8",
            }
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Chatbot streaming error: {str(e)}",
        )


async def track_api_usage(db: Session, influencer_id: str):
    """API ì‚¬ìš©ëŸ‰ ì¶”ì """
    try:
        logger.info(f"ğŸ“Š API ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹œì‘ - influencer_id: {influencer_id}")
        
        # API í‚¤ ì¡°íšŒ
        api_key = (
            db.query(InfluencerAPI)
            .filter(InfluencerAPI.influencer_id == influencer_id)
            .first()
        )
        
        if not api_key:
            logger.warning(f"âš ï¸ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - influencer_id: {influencer_id}")
            return
        
        logger.info(f"ğŸ”‘ API í‚¤ ì¡°íšŒ ì„±ê³µ - api_id: {api_key.api_id}")
        
        today = datetime.now().date()

        # ì˜¤ëŠ˜ ë‚ ì§œì˜ API í˜¸ì¶œ ì§‘ê³„ ì¡°íšŒ
        aggregation = (
            db.query(APICallAggregation)
            .filter(
                APICallAggregation.api_id == api_key.api_id,
                APICallAggregation.created_at >= today,
            )
            .first()
        )

        if aggregation:
            # ê¸°ì¡´ ì§‘ê³„ ì—…ë°ì´íŠ¸
            old_count = aggregation.daily_call_count
            aggregation.daily_call_count += 1
            aggregation.updated_at = datetime.now()
            logger.info(f"âœ… ê¸°ì¡´ ì§‘ê³„ ì—…ë°ì´íŠ¸ - api_id: {api_key.api_id}, ì´ì „: {old_count}, í˜„ì¬: {aggregation.daily_call_count}")
        else:
            # ìƒˆë¡œìš´ ì§‘ê³„ ìƒì„±
            aggregation = APICallAggregation(
                api_id=api_key.api_id,
                influencer_id=influencer_id,
                daily_call_count=1,
                created_at=datetime.now(),
                updated_at=datetime.now(),
            )
            db.add(aggregation)
            logger.info(f"ğŸ†• ìƒˆë¡œìš´ ì§‘ê³„ ìƒì„± - api_id: {api_key.api_id}, influencer_id: {influencer_id}")

        db.commit()
        logger.info(f"ğŸ’¾ API ì‚¬ìš©ëŸ‰ ì¶”ì  ì™„ë£Œ - influencer_id: {influencer_id}, api_id: {api_key.api_id}")

    except Exception as e:
        # API ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹¤íŒ¨ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
        logger.error(f"âŒ API usage tracking failed: {e}")
        db.rollback()


# ê¸°ì¡´ ì‚¬ìš©ì ì¸ì¦ ê¸°ë°˜ ì—”ë“œí¬ì¸íŠ¸ë“¤ (ê´€ë¦¬ìš©)
@router.get("", response_model=List[ChatMessageSchema])
async def get_chat_messages(
    influencer_id: str,
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=100),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """ì±„íŒ… ë©”ì‹œì§€ ëª©ë¡ ì¡°íšŒ"""
    # ì¸í”Œë£¨ì–¸ì„œ ì†Œìœ ê¶Œ í™•ì¸
    influencer = (
        db.query(AIInfluencer)
        .filter(
            AIInfluencer.influencer_id == influencer_id,
            AIInfluencer.user_id == current_user.user_id,
        )
        .first()
    )

    if influencer is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND, detail="Influencer not found"
        )

    messages = (
        db.query(ChatMessage)
        .filter(ChatMessage.influencer_id == influencer_id)
        .offset(skip)
        .limit(limit)
        .all()
    )

    return messages


@router.post("", response_model=ChatMessageSchema)
async def create_chat_message(
    message_data: ChatMessageCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """ìƒˆ ì±„íŒ… ë©”ì‹œì§€ ìƒì„±"""
    # ì¸í”Œë£¨ì–¸ì„œ ì†Œìœ ê¶Œ í™•ì¸
    influencer = (
        db.query(AIInfluencer)
        .filter(
            AIInfluencer.influencer_id == message_data.influencer_id,
            AIInfluencer.user_id == current_user.user_id,
        )
        .first()
    )

    if influencer is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND, detail="Influencer not found"
        )

    message = ChatMessage(
        chat_message_id=str(uuid.uuid4()),
        session_id=message_data.session_id if hasattr(message_data, 'session_id') else str(uuid.uuid4()),
        influencer_id=message_data.influencer_id,
        message_content=message_data.message_content,
        message_type=message_data.message_type,
        created_at=get_current_kst(),
        end_at=message_data.end_at,
    )

    db.add(message)
    db.commit()
    db.refresh(message)

    return message


@router.get("/{session_id}", response_model=ChatMessageSchema)
async def get_chat_message(
    session_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """íŠ¹ì • ì±„íŒ… ë©”ì‹œì§€ ì¡°íšŒ"""
    message = db.query(ChatMessage).filter(ChatMessage.session_id == session_id).first()

    if message is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND, detail="Chat message not found"
        )

    # ì¸í”Œë£¨ì–¸ì„œ ì†Œìœ ê¶Œ í™•ì¸
    influencer = (
        db.query(AIInfluencer)
        .filter(
            AIInfluencer.influencer_id == message.influencer_id,
            AIInfluencer.user_id == current_user.user_id,
        )
        .first()
    )

    if influencer is None:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not authorized to access this chat message",
        )

    return message
