import os
from typing import Optional, Dict, Any
from dataclasses import dataclass, field
from pathlib import Path
import json
import yaml
from enum import Enum


class ModelMode(Enum):
    """ëª¨ë¸ ì‹¤í–‰ ëª¨ë“œ"""
    LOCAL = "local"
    VLLM = "vllm"
    AUTO = "auto"  # ìë™ ê°ì§€


class LogLevel(Enum):
    """ë¡œê·¸ ë ˆë²¨"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"


@dataclass
class DatabaseConfig:
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
    # Milvus ì„¤ì •
    milvus_uri: str = "./rag_data/vectorstore.db"
    collection_name: str = "rag_documents"
    
    # SQLite ì„¤ì • (ë©”íƒ€ë°ì´í„°)
    sqlite_path: str = "./rag_data/metadata.db"
    
    # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    embedding_model: str = "BAAI/bge-m3"
    embedding_dimension: int = 1024
    embedding_device: str = "auto"  # auto, cpu, cuda


@dataclass
class VLLMConfig:
    """VLLM ì„œë²„ ì„¤ì •"""
    base_url: str = "http://localhost:8000"
    timeout: int = 30
    max_retries: int = 3
    health_check_interval: int = 60  # ì´ˆ
    
    # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
    base_model: str = "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct"
    default_adapter: str = "khj0816/EXAONE-Ian"
    
    # ìƒì„± ì„¤ì •
    max_tokens: int = 512
    temperature: float = 0.8
    top_p: float = 0.9
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€
    system_message: str = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
    influencer_name: str = "AI"


@dataclass
class LocalModelConfig:
    """ë¡œì»¬ ëª¨ë¸ ì„¤ì •"""
    base_model: str = "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct"
    lora_adapter: str = "khj0816/EXAONE-Ian"
    device_map: str = "auto"
    torch_dtype: str = "float16"
    trust_remote_code: bool = True
    use_cache: bool = True
    low_cpu_mem_usage: bool = True
    
    # ìƒì„± ì„¤ì •
    max_tokens: int = 512
    temperature: float = 0.8
    top_p: float = 0.9
    top_k: int = 50
    repetition_penalty: float = 1.1


@dataclass
class RAGConfig:
    """RAG ì‹œìŠ¤í…œ ì„¤ì •"""
    # ë¬¸ì„œ ì²˜ë¦¬
    min_paragraph_length: int = 30
    max_qa_pairs: int = 100
    
    # ê²€ìƒ‰ ì„¤ì •
    search_top_k: int = 3
    score_threshold: float = 0.7
    max_context_length: int = 2000
    
    # ì¬ë­í‚¹ ì„¤ì •
    use_reranking: bool = True
    duplicate_threshold: float = 0.9


@dataclass
class ServerConfig:
    """ì„œë²„ ì„¤ì •"""
    host: str = "0.0.0.0"
    port: int = 8001
    workers: int = 1
    reload: bool = False
    
    # API ì„¤ì •
    api_prefix: str = "/api/v1"
    docs_url: str = "/docs"
    openapi_url: str = "/openapi.json"
    
    # CORS ì„¤ì •
    allow_origins: list = field(default_factory=lambda: ["*"])
    allow_methods: list = field(default_factory=lambda: ["*"])
    allow_headers: list = field(default_factory=lambda: ["*"])


@dataclass
class SecurityConfig:
    """ë³´ì•ˆ ì„¤ì •"""
    # HuggingFace í† í°
    hf_token: Optional[str] = None
    hf_token_env: str = "HF_TOKEN"
    
    # API í‚¤ (í•„ìš”ì‹œ)
    api_key: Optional[str] = None
    api_key_env: str = "RAG_API_KEY"
    
    # JWT ì„¤ì • (í•„ìš”ì‹œ)
    secret_key: Optional[str] = None
    algorithm: str = "HS256"
    access_token_expire_minutes: int = 30


@dataclass
class RAGSystemConfig:
    """RAG ì‹œìŠ¤í…œ ì „ì²´ ì„¤ì •"""
    # ëª¨ë“œ ì„¤ì •
    model_mode: ModelMode = ModelMode.AUTO
    
    # ê²½ë¡œ ì„¤ì •
    data_dir: str = "./rag_data"
    logs_dir: str = "./logs"
    temp_dir: str = "./temp"
    
    # ë¡œê¹… ì„¤ì •
    log_level: LogLevel = LogLevel.INFO
    log_file: Optional[str] = None
    
    # í•˜ìœ„ ì„¤ì •ë“¤
    database: DatabaseConfig = field(default_factory=DatabaseConfig)
    vllm: VLLMConfig = field(default_factory=VLLMConfig)
    local_model: LocalModelConfig = field(default_factory=LocalModelConfig)
    rag: RAGConfig = field(default_factory=RAGConfig)
    server: ServerConfig = field(default_factory=ServerConfig)
    security: SecurityConfig = field(default_factory=SecurityConfig)
    
    def __post_init__(self):
        """ì´ˆê¸°í™” í›„ ì²˜ë¦¬"""
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self._ensure_directories()
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ í† í° ê°€ì ¸ì˜¤ê¸°
        self._load_tokens_from_env()
        
        # ëª¨ë¸ ëª¨ë“œ ìë™ ê°ì§€
        if self.model_mode == ModelMode.AUTO:
            self.model_mode = self._detect_model_mode()
    
    def _ensure_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ ìƒì„±"""
        directories = [
            self.data_dir,
            self.logs_dir,
            self.temp_dir,
            os.path.dirname(self.database.milvus_uri),
            os.path.dirname(self.database.sqlite_path)
        ]
        
        for directory in directories:
            if directory:
                Path(directory).mkdir(parents=True, exist_ok=True)
    
    def _load_tokens_from_env(self):
        """í™˜ê²½ ë³€ìˆ˜ì—ì„œ í† í° ë¡œë“œ"""
        if not self.security.hf_token:
            self.security.hf_token = os.getenv(self.security.hf_token_env)
        
        if not self.security.api_key:
            self.security.api_key = os.getenv(self.security.api_key_env)
    
    def _detect_model_mode(self) -> ModelMode:
        """ëª¨ë¸ ëª¨ë“œ ìë™ ê°ì§€"""
        # VLLM ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            import httpx
            response = httpx.get(f"{self.vllm.base_url}/health", timeout=5)
            if response.status_code == 200:
                return ModelMode.VLLM
        except:
            pass
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        try:
            import torch
            if torch.cuda.is_available():
                return ModelMode.LOCAL
        except:
            pass
        
        # ê¸°ë³¸ê°’ì€ VLLM (ì„œë²„ ê¸°ë°˜ì´ ê¶Œì¥)
        return ModelMode.VLLM
    
    @classmethod
    def from_file(cls, config_path: str) -> 'RAGSystemConfig':
        """íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
        config_path = Path(config_path)
        
        if not config_path.exists():
            raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë¡œë“œ ë°©ì‹ ê²°ì •
        if config_path.suffix.lower() == '.json':
            with open(config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        elif config_path.suffix.lower() in ['.yml', '.yaml']:
            with open(config_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„¤ì • íŒŒì¼ í˜•ì‹: {config_path.suffix}")
        
        return cls.from_dict(data)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'RAGSystemConfig':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ì„¤ì • ìƒì„±"""
        # ì¤‘ì²©ëœ ì„¤ì •ë“¤ ì²˜ë¦¬
        config_data = data.copy()
        
        # Enum ë³€í™˜
        if 'model_mode' in config_data:
            config_data['model_mode'] = ModelMode(config_data['model_mode'])
        if 'log_level' in config_data:
            config_data['log_level'] = LogLevel(config_data['log_level'])
        
        # í•˜ìœ„ ì„¤ì • ê°ì²´ ìƒì„±
        for field_name, field_type in cls.__dataclass_fields__.items():
            if field_name in config_data and hasattr(field_type.type, '__dataclass_fields__'):
                config_data[field_name] = field_type.type(**config_data[field_name])
        
        return cls(**config_data)
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        result = {}
        
        for field_name, field_value in self.__dict__.items():
            if hasattr(field_value, '__dataclass_fields__'):
                # ì¤‘ì²©ëœ dataclass
                result[field_name] = field_value.__dict__.copy()
            elif isinstance(field_value, Enum):
                # Enum íƒ€ì…
                result[field_name] = field_value.value
            else:
                result[field_name] = field_value
        
        return result
    
    def save(self, config_path: str, format: str = 'yaml'):
        """ì„¤ì •ì„ íŒŒì¼ë¡œ ì €ì¥"""
        config_path = Path(config_path)
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        data = self.to_dict()
        
        if format.lower() == 'json':
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        elif format.lower() in ['yml', 'yaml']:
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(data, f, default_flow_style=False, allow_unicode=True, indent=2)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")
    
    def get_vllm_generation_config(self) -> Dict[str, Any]:
        """VLLM ìƒì„± ì„¤ì • ë°˜í™˜"""
        return {
            "max_new_tokens": self.vllm.max_tokens,
            "temperature": self.vllm.temperature,
            "top_p": self.vllm.top_p,
            "system_message": self.vllm.system_message,
            "influencer_name": self.vllm.influencer_name,
            "model_id": self.vllm.default_adapter
        }
    
    def get_local_generation_config(self) -> Dict[str, Any]:
        """ë¡œì»¬ ëª¨ë¸ ìƒì„± ì„¤ì • ë°˜í™˜"""
        return {
            "max_new_tokens": self.local_model.max_tokens,
            "temperature": self.local_model.temperature,
            "top_p": self.local_model.top_p,
            "top_k": self.local_model.top_k,
            "repetition_penalty": self.local_model.repetition_penalty
        }
    
    def get_pipeline_config(self, pdf_path: str = "") -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ì„¤ì • ë°˜í™˜"""
        return {
            "pdf_path": pdf_path,
            "output_dir": self.data_dir,
            "min_paragraph_length": self.rag.min_paragraph_length,
            "max_qa_pairs": self.rag.max_qa_pairs,
            "search_top_k": self.rag.search_top_k,
            "search_threshold": self.rag.score_threshold,
            "response_max_tokens": self.vllm.max_tokens if self.model_mode == ModelMode.VLLM else self.local_model.max_tokens,
            "response_temperature": self.vllm.temperature if self.model_mode == ModelMode.VLLM else self.local_model.temperature,
            "use_vllm": self.model_mode == ModelMode.VLLM,
            "vllm_base_url": self.vllm.base_url,
            "system_message": self.vllm.system_message,
            "influencer_name": self.vllm.influencer_name,
            "save_intermediate": True,
            "verbose": self.log_level in [LogLevel.DEBUG, LogLevel.INFO]
        }


# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
_global_config: Optional[RAGSystemConfig] = None


def get_config() -> RAGSystemConfig:
    """ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_config
    if _global_config is None:
        _global_config = RAGSystemConfig()
    return _global_config


def load_config(config_path: Optional[str] = None) -> RAGSystemConfig:
    """ì„¤ì • ë¡œë“œ ë° ì „ì—­ ì„¤ì • ì—…ë°ì´íŠ¸"""
    global _global_config
    
    if config_path and Path(config_path).exists():
        _global_config = RAGSystemConfig.from_file(config_path)
    else:
        _global_config = RAGSystemConfig()
    
    return _global_config


def init_logging(config: Optional[RAGSystemConfig] = None):
    """ë¡œê¹… ì´ˆê¸°í™”"""
    if config is None:
        config = get_config()
    
    import logging
    
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì •
    log_level = getattr(logging, config.log_level.value)
    
    # ë¡œê·¸ í¬ë§· ì„¤ì •
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    logger = logging.getLogger()
    logger.setLevel(log_level)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(log_level)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì„¤ì •ëœ ê²½ìš°)
    if config.log_file:
        log_file_path = Path(config.logs_dir) / config.log_file
        log_file_path.parent.mkdir(parents=True, exist_ok=True)
        
        file_handler = logging.FileHandler(log_file_path, encoding='utf-8')
        file_handler.setLevel(log_level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)


# ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„± í•¨ìˆ˜
def create_default_config(config_path: str = "./config.yaml"):
    """ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
    config = RAGSystemConfig()
    config.save(config_path)
    print(f"âœ… ê¸°ë³¸ ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {config_path}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹œì‘
    config = RAGSystemConfig()
    
    # ì„¤ì • ì¶œë ¥
    print("ğŸ”§ RAG ì‹œìŠ¤í…œ ì„¤ì •:")
    print(f"  ëª¨ë¸ ëª¨ë“œ: {config.model_mode.value}")
    print(f"  ë°ì´í„° ë””ë ‰í† ë¦¬: {config.data_dir}")
    print(f"  VLLM URL: {config.vllm.base_url}")
    print(f"  HF í† í°: {'ìˆìŒ' if config.security.hf_token else 'ì—†ìŒ'}")
    
    # ì„¤ì • íŒŒì¼ë¡œ ì €ì¥
    config.save("./config_example.yaml")
    print("âœ… ì˜ˆì‹œ ì„¤ì • íŒŒì¼ ì €ì¥ ì™„ë£Œ: config_example.yaml")
    
    # ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ í…ŒìŠ¤íŠ¸
    try:
        loaded_config = RAGSystemConfig.from_file("./config_example.yaml")
        print("âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")